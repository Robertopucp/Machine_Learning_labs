{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Estimation of Heterogeneous Treatment Effects and Optimal Treatment Policies\n",
    "prepared for \"Machine Learning and Causal Inference\" class\n",
    "\n",
    "Authors : Susan Athey, Stefan Wager, Vitor Hadad, Sylvia Klosin, Nicolaj Muhelbach, Xinkun Nie, Matt Schaelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keywords: conditional average treatment effect; machine learning; econometrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abstract: \"In this tutorial, you will learn about machine learning (ML) methods for the estimation of heterogeneous treatment effects in randomized experiments and observational data, using  causal trees, causal forests and X-learners. Also, you will  be introduced to the problem of estimation of treatment policies. This tutorial also serves as a template for analyses using other datasets.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE, comment=NA)\n",
    "# Clear workspace\n",
    "rm(list = ls())\n",
    "# Set seed for reproducibility\n",
    "set.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This tutorial contains two parts.\n",
    "\n",
    "#### Part I: Heterogeneous treatment effects\n",
    "\n",
    "+ **Causal Tree (Athey and Imbens, 2016):** A data-driven approach to partition the data into subpopulations that differ in the magnitude of their treatment effects. The approach enables the construction of valid confidence intervals for treatment effects.\n",
    "\n",
    "+ **Causal Forests (Athey, Tibshrani and Wager, 2018) and the R-learner (Nie and Wager, 2017):** Causal forests is a specialization of the *generalized random forests* algorithm to estimate conditional average treatment effects, with its implementation motivated by the R-learner. The R-learner is a meta-algorithm used to combine different supervised learning algorithm to produce better estimates of conditional average treatment effects.\n",
    "\n",
    "+ **X-Learners (KÃ¼nzel et al, 2018):** Like the R-learner, X-learner is another meta-algorithm for estimating conditional average treatment effects.\n",
    "\n",
    "#### Part II: Estimating optimal policies\n",
    "\n",
    "An illustrative application of the **efficient policy learning** methods of Athey and Wager (2018).\n",
    "\n",
    "\n",
    "## Loading packages\n",
    "\n",
    "Before beginning the tutorial, let's make sure all necessary packages are installed. Try running the cell below and, if any issues arise, follow the instructions within it.\n",
    "\n",
    "**CRAN packages:** If any of these packages are not installed, write `install.packages(\"<name of package>\")`. For example, to install the package `fBasics`, use `install.packages(\"fBasics\")`. The number in parenthesis in the comments the package version that was used when this was tutorial was compiled. If you find yourself having issues, please consider upgrading or downgrading to the same package version.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "library(dplyr)       # Data manipulation (0.8.0.1)\n",
    "library(fBasics)     # Summary statistics (3042.89)\n",
    "library(corrplot)    # Correlations (0.84)\n",
    "library(psych)       # Correlation p-values (1.8.12)\n",
    "library(grf)         # Generalized random forests (0.10.2)\n",
    "library(rpart)       # Classification and regression trees, or CART (4.1-13)\n",
    "library(rpart.plot)  # Plotting trees (3.0.6)\n",
    "library(treeClust)   # Predicting leaf position for causal trees (1.1-7)\n",
    "library(car)         # linear hypothesis testing for causal tree (3.0-2)\n",
    "library(devtools)    # Install packages from github (2.0.1)\n",
    "library(readr)       # Reading csv files (1.3.1)\n",
    "library(tidyr)       # Database operations (0.8.3)\n",
    "library(tibble)      # Modern alternative to data frames (2.1.1)\n",
    "library(knitr)       # RMarkdown (1.21)\n",
    "library(kableExtra)  # Prettier RMarkdown (1.0.1)\n",
    "library(ggplot2)     # general plotting tool (3.1.0)\n",
    "library(haven)       # read stata files (2.0.0)\n",
    "library(aod)         # hypothesis testing (1.3.1)\n",
    "library(evtree)      # evolutionary learning of globally optimal trees (1.0-7)\n",
    "library(plyr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Non-CRAN packages:** The packages below have not yet been uploaded to CRAN or any other major package repository, but we can grab them from their authors' github webpages. If you don't have these packages installed already, uncomment the relevant line below to install it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For causal trees (Athey and Imbens, 2016)  version 0.0\n",
    "# install_github('susanathey/causalTree') # Uncomment this to install the causalTree package\n",
    "library(causalTree)\n",
    "\n",
    "# Uncomment this to install the causalToolbox package\n",
    "# install_github(\"soerenkuenzel/causalToolbox\")\n",
    "# (You may need to also run install.packages(\"BART\") to install the causalToolbox library)\n",
    "library(causalToolbox)  # X-learners (Kuenzel et al, 2017)  version 0.0.1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "We will be working with the `welfare` dataset, from \"Modeling Heterogeneous Treatment Effects in Survey Experiments with Baysian Additive Regression Trees\" (Green and Kern, 2012) ([link](https://watermark.silverchair.com/nfs036.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAAk4wggJKBgkqhkiG9w0BBwagggI7MIICNwIBADCCAjAGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQM3RX6a6U86Z6filpPAgEQgIICAQEBVSrcs9e_z1iPQ0uSsA7gloMFhd5tq_UAZCrZYkOcMvW4If8OcQxXmnK-dtZhKyRj4Q3nYGI8Nrih2iKFXEnxLBh3Eql6USdRHfWRzkV2zIe9SRGynC7aw7DNCaiBDwPVWUJ1ldaXa-WFglb9D0mllmV6SglZfi8mnm4GL42iTIC_gOG27Cj-rCKi83key5Egxpt8SYp_KpnFDH6v2uWrHneDE-YQ1UghZfM6jZVZFG0bSQGB_3QejgxiaL2Cey7oYAvpgs3D4cpXsUxp7cr7kFIU4hOVVz-lR6Aj2-BaRAa2y7aKigtOTFPWMTrZScUCoinnDsGA1RzLL5e5LxKV9gQ5z9cIX2kECJhV8lN5w5maiCq3ZOcZnhyCD5w_1NjmGdmZk4eVBTlhDwsipAAWCo2C3Eo3w1Jc3VvikcoOKn7I2ocWw9qRtB9XWr-qg5ex_gOdc7v7bDMd-vwbbYr5iOYdc7P9lWZK5ngfDWNH6oTwF9MDwbPj8-bMlDkUvmOMpkWBqneueLj1nDDBaL2iTGD8gCy8Mgl4Qzzp82vN4wsRa3ufMl-WDAcynTWgEn0-GLgds1dCQ81HP-CpM_9t6rZblZsVi9V2iapi57vSLabk5DHA_lGtY0fizUjAgwitDtZCWCeLZxPcSkilpcDbV9Dz-24gIpeOPQbkFFvdtQ)). However, by changing the dataset name below, you can see how the estimates would differ. You can select from the following list of datasets from our [github webpage](https://github.com/gsbDBI/ExperimentData/):\n",
    "\n",
    "+ `charitable`: from \"Does Price Matter in Charitable Giving?\" (Karlan and List, 2007)\n",
    "+ `secrecy`: from \"Ballot Secrecy Concerns and Voter Mobilization\" (Gerber, Hubers, Biggers, and Henry, 2014)\n",
    "+ `social`: from \"Social Pressure and Voter Turnout\" (Gerber, Green, and Larimer, 2008)\n",
    "+ `criteo`: A public benchmark dataset for measuring effect of digital advertising.\n",
    "+ `mobilization`: from \"Comparing Experimental and Matching Methods Using a Large-Scale Voter Mobilization Experiment\" (Arceneaux, Gerber, and Green, 2006)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick any data set from the list above for parts I and II of the tutorial\n",
    "dataset_name <- \"welfare\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load in the raw data and perform some data cleaning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code to download the datasets is a bit long and tedious, so we ommitted here from the HTML. Please check out RMarkdown source if you are interested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[1mRows: \u001b[1m\u001b[22m\u001b[34m\u001b[34m36501\u001b[34m\u001b[39m \u001b[1m\u001b[1mColumns: \u001b[1m\u001b[22m\u001b[34m\u001b[34m211\u001b[34m\u001b[39m\n",
      "\n",
      "\u001b[36m--\u001b[39m \u001b[1m\u001b[1mColumn specification\u001b[1m\u001b[22m \u001b[36m------------------------------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m   (5): racdif1, racdif2, racdif3, racdif4, _mergescore\n",
      "\u001b[32mdbl\u001b[39m (206): year, id, wrkstat, hrs1, hrs2, evwork, occ, prestige, wrkslf, wrk...\n",
      "\n",
      "\n",
      "\u001b[36mi\u001b[39m Use \u001b[30m\u001b[47m\u001b[30m\u001b[47m`spec()`\u001b[47m\u001b[30m\u001b[49m\u001b[39m to retrieve the full column specification for this data.\n",
      "\u001b[36mi\u001b[39m Specify the column types or set \u001b[30m\u001b[47m\u001b[30m\u001b[47m`show_col_types = FALSE`\u001b[47m\u001b[30m\u001b[49m\u001b[39m to quiet this message.\n",
      "\n",
      "Warning message:\n",
      "\"One or more parsing issues, see `problems()` for details\"\n"
     ]
    }
   ],
   "source": [
    "if (dataset_name == \"social\") {\n",
    "  # Load raw data\n",
    "  df <- readr::read_csv(file = \"https://raw.githubusercontent.com/gsbDBI/ExperimentData/master/Social/ProcessedData/socialpressnofact.csv\", na = character())\n",
    "\n",
    "  # Specify outcome, treatment, and covariate variable names to use\n",
    "  outcome_variable_name <- \"outcome_voted\"\n",
    "  treatment_variable_name <- \"treat_neighbors\"\n",
    "  covariate_names <-c(\"sex\", \"yob\", \"city\", \"hh_size\", \"totalpopulation_estimate\",\n",
    "                      \"percent_male\", \"median_age\", \"percent_62yearsandover\",\n",
    "                      \"percent_white\", \"percent_black\", \"percent_asian\", \"median_income\",\n",
    "                      \"employ_20to64\", \"highschool\", \"bach_orhigher\",\"percent_hispanicorlatino\")\n",
    "\n",
    "} else if (dataset_name == \"charitable\") {\n",
    "  # Load raw data\n",
    "  df <- readr::read_csv(file = \"https://raw.githubusercontent.com/gsbDBI/ExperimentData/master/Charitable/ProcessedData/charitable_withdummyvariables.csv\", na = character())\n",
    "\n",
    "  # Specify outcome, treatment, and covariate variable names to use\n",
    "  outcome_variable_name <- \"out_gavedum\"\n",
    "  treatment_variable_name <- \"treatment\"\n",
    "  covariate_names <- c(\"pwhite\", \"pblack\", \"ave_hh_sz\", \"median_hhincome\",  \"pop_propurban\", \"female\", \"couple\", \"red0\", \"redcty\")\n",
    "\n",
    "  # This dataset encodes missing values as -999. Let's change these to NA.\n",
    "  df[df == -999] <- NA\n",
    "\n",
    "} else if (dataset_name == \"mobilization\") {\n",
    "\n",
    "  # Create a temporary file and download the data to it.\n",
    "  temp <- tempfile()\n",
    "  download.file(\"https://raw.githubusercontent.com/gsbDBI/ExperimentData/master/Mobilization/ProcessedData/mobilization_with_unlisted.zip\", temp)\n",
    "\n",
    "  # # Load raw data\n",
    "  df <- readr::read_csv((unz(temp, \"mobilization_with_unlisted.csv\")), na = character())\n",
    "  unlink(temp)\n",
    "  df <- subset(df, treatment ==1 | treatment==0)\n",
    "\n",
    "  #  Specify outcome, treatment, and covariate variable names to use\n",
    "  outcome_variable_name <- \"vote02\"\n",
    "  treatment_variable_name <- \"treatment\"\n",
    "  covariate_names <- c(\"comp_ia\", \"age\", \"female\", \"vote98\", \"vote00\",\n",
    "                       # \"state\", \"newreg\", \"comp_mi\", # These covariates are commented out because\n",
    "                       \"county\",\"st_sen\",\"st_hse\")     # they are constant in the first 5000 rows.\n",
    "                                                       # Thus, they can be included if using the entire dataset.sfor\n",
    "\n",
    "\n",
    "} else if (dataset_name == \"secrecy\") {\n",
    "  # Load raw data\n",
    "  df <- readr::read_csv(file = \"https://raw.githubusercontent.com/gsbDBI/ExperimentData/master/Secrecy/ProcessedData/ct_ballotsecrecy_processed.csv\", na = character())\n",
    "\n",
    "  # Specify outcome, treatment, and covariate variable names to use\n",
    "  outcome_variable_name <- \"turnoutindex_12\"\n",
    "  treatment_variable_name <- \"anysecrecytreatment\"\n",
    "  covariate_names <- c(\"v_cong_general_10\", \"v_pres_primary_12\",\t\"v_cong_primary_12\",\"v_pres_general_12\",\n",
    "                       \"town1_block\",\t\"town2_block\", \"town3_block\",\"town4_block\", \"town5_block\",\n",
    "                       \"town6_block\",\t\"i_grp_addr_1\",\t\"i_grp_addr_2\",\t\"i_grp_addr_3\",\t\"i_grp_addr_4\",\n",
    "                       \"dem\",\t\"rep\",\t\"female\",\t\"age_md\",\t\"age_sq_md\")\n",
    "\n",
    "} else if (dataset_name == \"welfare\") {\n",
    "  # Load raw data\n",
    "  df <- readr::read_csv(file = \"https://raw.githubusercontent.com/gsbDBI/ExperimentData/master/Welfare/ProcessedData/welfarenolabel3.csv\", na = character())\n",
    "\n",
    "  # Specify outcome, treatment, and covariate variable names to use\n",
    "  outcome_variable_name <- \"y\"\n",
    "  treatment_variable_name <- \"w\"\n",
    "  covariate_names <- c(\"hrs1\", \"partyid\", \"income\", \"rincome\", \"wrkstat\", \"wrkslf\",\"age\", \"polviews\",\n",
    "                       \"educ\", \"earnrs\", \"race\",\"wrkslf\",\n",
    "                       \"marital\",\"sibs\",\"childs\", \"occ80\",  \"prestg80\", \"indus80\",\"res16\",\"reg16\",\"mobile16\", \"family16\", \"parborn\",\"maeduc\",\"degree\",\"sex\",\"race\",\"born\",\"hompop\",\"babies\",\"preteen\",\"teens\",\"adults\")\n",
    "  \n",
    "  # This dataset encodes missing values as -999. Let's change these to NA.\n",
    "  df[df == -999] <- NA\n",
    "\n",
    "} else if (dataset_name == \"advertising\") {\n",
    "\n",
    "   # Load raw data\n",
    "  current_directory <- getwd()\n",
    "\n",
    "  #  checking to see if the criteo data already exists in the directory. if not download the data\n",
    "  if (!(\"adcontentworth_qje.csv\" %in% list.files(current_directory))){\n",
    "    url <- 'https://raw.githubusercontent.com/gsbDBI/ExperimentData/master/Advertising/adcontentworth_qje.csv'\n",
    "    download.file(url, paste0(current_directory, \"/\", \"adcontentworth_qje.csv\"))\n",
    "  }\n",
    "\n",
    "   # Load raw data\n",
    "  df <- read.csv(file = \"adcontentworth_qje.csv\")\n",
    "\n",
    "  # Subsetting based on wave>1 yields the 53,194 observations used in paper\n",
    "  df <- df[df$wave > 1, ]\n",
    "\n",
    "  # Specify outcome, treatment, and covariate variable names to use\n",
    "  outcome_variable_name <- \"applied\" # alternatively, use \"tookup\"\n",
    "  treatment_variable_name <- \"speak_trt\" # alternatively, use \"oneln_trt\" or another\n",
    "  covariate_names <- c(\"offer4\", \"stripany\",  \"dphoto_black\", \"dphoto_female\", \"prize\", \"oneln_trt\", \"use_any\", \"intshown\", \"comploss_n\", \"comp_n\", \"risk\", \"waved3\", \"female\", \"race\", \"race_match\" , \"gender_match\")\n",
    "\n",
    "  # --- Content treatments from paper ---\n",
    "  # speak_trt, stripany, dphoto_none, dphoto_black, dphoto_female,\n",
    "  # gender_match, race_match, prize, oneln_trt, use_any, intshown, comploss_n ,comp_n\n",
    "  # -------------------------------------\n",
    "\n",
    "} else if (dataset_name == \"criteo\") {\n",
    "  # Load raw data\n",
    "  current_directory <- getwd()\n",
    "  #  checking to see if the criteo data already exists in the directory. if not download the data\n",
    "  if (!(\"criteo.csv.gz\" %in% list.files(current_directory))){\n",
    "    url <- 'https://s3.us-east-2.amazonaws.com/criteo-uplift-dataset/criteo-uplift.csv.gz'\n",
    "    download.file(url, paste0(current_directory, \"/\", \"criteo.csv.gz\"))\n",
    "  }\n",
    "\n",
    "  df <- readr::read_csv(\"criteo.csv.gz\", na = character())\n",
    "\n",
    "  # Specify outcome, treatment, and covariate variable names to use\n",
    "  outcome_variable_name <- \"visit\"\n",
    "  treatment_variable_name <- \"treatment\"\n",
    "  covariate_names <- c( \"f0\", \"f1\", \"f2\", \"f3\", \"f4\", \"f5\", \"f6\", \"f7\", \"f8\", \"f9\", \"f10\", \"f11\" )\n",
    "\n",
    "} else {\n",
    "  # Raise an error if the dataset is unknown\n",
    "  print(\"Incorrect dataset is specified. Change 'dataset_name' to one of {charitable, mobilization, secrecy, social, welfare, criteo }\")\n",
    "\n",
    "  # Exiting knitr\n",
    "  knitr::knit_exit()\n",
    "  print(\"Exiting knitr without completion\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data\n",
    "\n",
    "The datasets in our [github webpage](https://github.com/gsbDBI/ExperimentData/) have been prepared for analysis so they will not require a lot of cleaning and manipulation, but let's do some minimal housekeeping. First, we will drop the columns that aren't outcomes, treatments or (pre-treatment) covariates, since we won't be using those.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all names\n",
    "all_variables_names <- c(outcome_variable_name, treatment_variable_name, covariate_names)\n",
    "df <- df[, which(names(df) %in% all_variables_names)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's drop any row that has missing values in them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows containing missing values\n",
    "df <- na.omit(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, let's also change the names of the treatment and outcome variables. This is just to make our analysis code below simpler, because we won't have to care about variable names. The treatment will be denoted `W`, and the outcome will be denoted `Y` (we'll have more to say about notation in the next section).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename variables\n",
    "names(df)[names(df) == outcome_variable_name] <- \"Y\"\n",
    "names(df)[names(df) == treatment_variable_name] <- \"W\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of our methods below don't accept `factor` variables, so let's change their type to `numeric` here. **Note:** If you are modifying this tutorial for your own application, make sure this is a valid step!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting all columns to numerical\n",
    "df <- data.frame(lapply(df, function(x) as.numeric(as.character(x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's separate a portion of our dataset as a test set. Later we will use this subset to evaluate the performance of each method described below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fraction <- 0.80  # Use train_fraction % of the dataset to train our models\n",
    "n <- dim(df)[1]\n",
    "train_idx <- sample.int(n, replace=F, size=floor(n*train_fraction))\n",
    "df_train <- df[train_idx,]\n",
    "df_test <- df[-train_idx,]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notation\n",
    "\n",
    "Let's establish some common notation and definitions. Each unit in our data set will be represented by:\n",
    "\n",
    "+ $X_{i}$: is a $p$-dimensional vector of observable pre-treatment characteristics\n",
    "+ $W_{i} \\in \\{0, 1\\}$: is a binary variable indicating whether the individual was treated ($1$) or not ($0$)\n",
    "+ $Y_{i}^{obs} \\in \\mathbb{R}$: a real variable indicating the observed outcome for that individual\n",
    "\n",
    "Throughout our analysis, we will often be talking in terms of _counterfactuals_ questions, e.g. \"what _would have_ happened if we had assigned the treatment to certain control units?\" In order to express this mathematically, we will make use of the _potential outcome_ framework of Rubin (1974). Let's define the following random variables:\n",
    "\n",
    "+ $Y_{i}(1)$: the outcome unit $i$ would attain if they received the treatment\n",
    "+ $Y_{i}(0)$: the outcome unit $i$ would attain if they were part of the control group\n",
    "\n",
    "Naturally, we only ever get to observe one of these two for each unit, but it's convenient to define so that we can think about counterfactuals. In fact, we can think of much of causal inference as a \"missing value\" problem: there exists an underlying data process generating random variables $(X_{i}, Y_{i}(0), Y_{i}(1))$, but we can only observe the realization of $(X_{i}, Y_{i}(0))$ (for control units) or $(X_{i}, Y_{i}(1))$ (for treated units), with the remaining outcome being missing.\n",
    "\n",
    "| $X_{i}$ | $Y_{i}(0)$ | $Y_{i}(1)$\n",
    "|:----:|:----:|:----:|\n",
    "| $X_{1}$  | <font color=\"lightgray\">$Y_{1}(0)$</font> | $Y_{1}(1)$ |\n",
    "| $X_{2}$  | $Y_{2}(0)$                                | <font color=\"lightgray\">$Y_{2}(1)$</font> |\n",
    "| $X_{3}$  | <font color=\"lightgray\">$Y_{3}(0)$</font> | $Y_{3}(1)$ |\n",
    "| $\\cdots$ | $\\cdots$   | $\\cdots$ |\n",
    "| $X_{n}$  | <font color=\"lightgray\">$Y_{n}(0)$</font> | $Y_{n}(1)$ |\n",
    "\n",
    "Using the potential outcome notation above, the observed outcome can also be written as\n",
    "\n",
    "$$Y_{i}^{obs} = W_{i}Y_{i}(1) + (1-W_{i})Y_{i}(0)$$\n",
    "\n",
    "In order to avoid clutter, we'll from now own denote $Y_{i}^{obs}$ simply by $Y_{i}$.\n",
    "\n",
    "\n",
    "## Assumptions\n",
    "\n",
    "We will be making two identification assumptions that will allow us to use the methods below.\n",
    "\n",
    "\n",
    "#### Assumption 1: Unconfoundedness\n",
    "\n",
    "The _unconfoundedness_ assumption states that, once we condition on observable characteristics, the treatment assignment is independent to how each person would respond to the treatment. In other words, the rule that determines whether or not a person is treated is determined completely by their observable characteristics. This allows, for example, for experiments where people from different genders get treated with different probabilities, but it rules out experiments where people self-select into treatment due to some characteristic that is not observed in our data.\n",
    "\n",
    "$$Y_i(1), Y_i(0) \\perp W_i \\ | \\ X_i$$\n",
    "\n",
    "\n",
    "#### Assumption 2: Overlap\n",
    "\n",
    "In order to estimate the treatment effect for a person with particular characteristics $X_{i} = x$, we need to ensure that we are able to observe treated and untreated people with those same characteristics so that we can compare their outcomes. The _overlap_ assumption states that at every point of the covariate space we can always find treated and control individuals.\n",
    "\n",
    "$$\\forall \\ x \\in \\text{supp}\\ (X), \\qquad 0 < P\\ (W = 1 \\ | \\ X = x)  < 1$$\n",
    "\n",
    "\n",
    "*Note:* Some of the datasets the [github webpage](https://github.com/gsbDBI/ExperimentData/) are completely randomized experiments. This assumption holds for those as well.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Part I: HTE (binary treatment)\n",
    "\n",
    "Let's see how to analyze the data set selected above for heterogeneous treatment effects.\n",
    "\n",
    "\n",
    "## Descriptive statistics\n",
    "\n",
    "It's often useful to begin data analysis by simply looking at simple summary statistics. We use the function `basicStats` from the package `fBasics` to calculate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a data.frame containing summary statistics of interest\n",
    "summ_stats <- fBasics::basicStats(df)\n",
    "summ_stats <- as.data.frame(t(summ_stats))\n",
    "\n",
    "# Rename some of the columns for convenience\n",
    "summ_stats <- summ_stats[c(\"Mean\", \"Stdev\", \"Minimum\", \"1. Quartile\", \"Median\",  \"3. Quartile\", \"Maximum\")]\n",
    "colnames(summ_stats)[colnames(summ_stats) %in% c('1. Quartile', '3. Quartile')] <- c('Lower quartile', 'Upper quartile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table class=\"table table-striped table-hover table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n",
       " <thead>\n",
       "  <tr>\n",
       "   <th style=\"text-align:left;\">   </th>\n",
       "   <th style=\"text-align:right;\"> Mean </th>\n",
       "   <th style=\"text-align:right;\"> Stdev </th>\n",
       "   <th style=\"text-align:right;\"> Minimum </th>\n",
       "   <th style=\"text-align:right;\"> Lower quartile </th>\n",
       "   <th style=\"text-align:right;\"> Median </th>\n",
       "   <th style=\"text-align:right;\"> Upper quartile </th>\n",
       "   <th style=\"text-align:right;\"> Maximum </th>\n",
       "  </tr>\n",
       " </thead>\n",
       "<tbody>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> wrkstat </td>\n",
       "   <td style=\"text-align:right;\"> 1.16 </td>\n",
       "   <td style=\"text-align:right;\"> 0.36 </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 2 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> hrs1 </td>\n",
       "   <td style=\"text-align:right;\"> 42.26 </td>\n",
       "   <td style=\"text-align:right;\"> 14.01 </td>\n",
       "   <td style=\"text-align:right;\"> 0 </td>\n",
       "   <td style=\"text-align:right;\"> 38 </td>\n",
       "   <td style=\"text-align:right;\"> 40 </td>\n",
       "   <td style=\"text-align:right;\"> 50 </td>\n",
       "   <td style=\"text-align:right;\"> 89 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> wrkslf </td>\n",
       "   <td style=\"text-align:right;\"> 1.88 </td>\n",
       "   <td style=\"text-align:right;\"> 0.33 </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 2 </td>\n",
       "   <td style=\"text-align:right;\"> 2 </td>\n",
       "   <td style=\"text-align:right;\"> 2 </td>\n",
       "   <td style=\"text-align:right;\"> 2 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> occ80 </td>\n",
       "   <td style=\"text-align:right;\"> 334.44 </td>\n",
       "   <td style=\"text-align:right;\"> 243.39 </td>\n",
       "   <td style=\"text-align:right;\"> 4 </td>\n",
       "   <td style=\"text-align:right;\"> 156 </td>\n",
       "   <td style=\"text-align:right;\"> 308 </td>\n",
       "   <td style=\"text-align:right;\"> 458 </td>\n",
       "   <td style=\"text-align:right;\"> 889 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> prestg80 </td>\n",
       "   <td style=\"text-align:right;\"> 45.30 </td>\n",
       "   <td style=\"text-align:right;\"> 13.79 </td>\n",
       "   <td style=\"text-align:right;\"> 17 </td>\n",
       "   <td style=\"text-align:right;\"> 34 </td>\n",
       "   <td style=\"text-align:right;\"> 45 </td>\n",
       "   <td style=\"text-align:right;\"> 52 </td>\n",
       "   <td style=\"text-align:right;\"> 86 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> indus80 </td>\n",
       "   <td style=\"text-align:right;\"> 601.76 </td>\n",
       "   <td style=\"text-align:right;\"> 272.59 </td>\n",
       "   <td style=\"text-align:right;\"> 10 </td>\n",
       "   <td style=\"text-align:right;\"> 410 </td>\n",
       "   <td style=\"text-align:right;\"> 702 </td>\n",
       "   <td style=\"text-align:right;\"> 840 </td>\n",
       "   <td style=\"text-align:right;\"> 932 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> marital </td>\n",
       "   <td style=\"text-align:right;\"> 2.44 </td>\n",
       "   <td style=\"text-align:right;\"> 1.69 </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 4 </td>\n",
       "   <td style=\"text-align:right;\"> 5 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> sibs </td>\n",
       "   <td style=\"text-align:right;\"> 3.44 </td>\n",
       "   <td style=\"text-align:right;\"> 2.93 </td>\n",
       "   <td style=\"text-align:right;\"> 0 </td>\n",
       "   <td style=\"text-align:right;\"> 2 </td>\n",
       "   <td style=\"text-align:right;\"> 3 </td>\n",
       "   <td style=\"text-align:right;\"> 4 </td>\n",
       "   <td style=\"text-align:right;\"> 37 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> childs </td>\n",
       "   <td style=\"text-align:right;\"> 1.58 </td>\n",
       "   <td style=\"text-align:right;\"> 1.49 </td>\n",
       "   <td style=\"text-align:right;\"> 0 </td>\n",
       "   <td style=\"text-align:right;\"> 0 </td>\n",
       "   <td style=\"text-align:right;\"> 2 </td>\n",
       "   <td style=\"text-align:right;\"> 2 </td>\n",
       "   <td style=\"text-align:right;\"> 8 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> age </td>\n",
       "   <td style=\"text-align:right;\"> 40.54 </td>\n",
       "   <td style=\"text-align:right;\"> 12.19 </td>\n",
       "   <td style=\"text-align:right;\"> 18 </td>\n",
       "   <td style=\"text-align:right;\"> 31 </td>\n",
       "   <td style=\"text-align:right;\"> 39 </td>\n",
       "   <td style=\"text-align:right;\"> 49 </td>\n",
       "   <td style=\"text-align:right;\"> 88 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> educ </td>\n",
       "   <td style=\"text-align:right;\"> 13.98 </td>\n",
       "   <td style=\"text-align:right;\"> 2.75 </td>\n",
       "   <td style=\"text-align:right;\"> 0 </td>\n",
       "   <td style=\"text-align:right;\"> 12 </td>\n",
       "   <td style=\"text-align:right;\"> 14 </td>\n",
       "   <td style=\"text-align:right;\"> 16 </td>\n",
       "   <td style=\"text-align:right;\"> 20 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> maeduc </td>\n",
       "   <td style=\"text-align:right;\"> 11.71 </td>\n",
       "   <td style=\"text-align:right;\"> 3.34 </td>\n",
       "   <td style=\"text-align:right;\"> 0 </td>\n",
       "   <td style=\"text-align:right;\"> 11 </td>\n",
       "   <td style=\"text-align:right;\"> 12 </td>\n",
       "   <td style=\"text-align:right;\"> 13 </td>\n",
       "   <td style=\"text-align:right;\"> 20 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> degree </td>\n",
       "   <td style=\"text-align:right;\"> 1.74 </td>\n",
       "   <td style=\"text-align:right;\"> 1.18 </td>\n",
       "   <td style=\"text-align:right;\"> 0 </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 3 </td>\n",
       "   <td style=\"text-align:right;\"> 4 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> sex </td>\n",
       "   <td style=\"text-align:right;\"> 1.50 </td>\n",
       "   <td style=\"text-align:right;\"> 0.50 </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 2 </td>\n",
       "   <td style=\"text-align:right;\"> 2 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> race </td>\n",
       "   <td style=\"text-align:right;\"> 1.25 </td>\n",
       "   <td style=\"text-align:right;\"> 0.56 </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 3 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> res16 </td>\n",
       "   <td style=\"text-align:right;\"> 3.54 </td>\n",
       "   <td style=\"text-align:right;\"> 1.53 </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 3 </td>\n",
       "   <td style=\"text-align:right;\"> 3 </td>\n",
       "   <td style=\"text-align:right;\"> 5 </td>\n",
       "   <td style=\"text-align:right;\"> 6 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> reg16 </td>\n",
       "   <td style=\"text-align:right;\"> 4.41 </td>\n",
       "   <td style=\"text-align:right;\"> 2.63 </td>\n",
       "   <td style=\"text-align:right;\"> 0 </td>\n",
       "   <td style=\"text-align:right;\"> 2 </td>\n",
       "   <td style=\"text-align:right;\"> 4 </td>\n",
       "   <td style=\"text-align:right;\"> 7 </td>\n",
       "   <td style=\"text-align:right;\"> 9 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> mobile16 </td>\n",
       "   <td style=\"text-align:right;\"> 1.95 </td>\n",
       "   <td style=\"text-align:right;\"> 0.85 </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 2 </td>\n",
       "   <td style=\"text-align:right;\"> 3 </td>\n",
       "   <td style=\"text-align:right;\"> 3 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> family16 </td>\n",
       "   <td style=\"text-align:right;\"> 1.83 </td>\n",
       "   <td style=\"text-align:right;\"> 1.67 </td>\n",
       "   <td style=\"text-align:right;\"> 0 </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 8 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> born </td>\n",
       "   <td style=\"text-align:right;\"> 1.09 </td>\n",
       "   <td style=\"text-align:right;\"> 0.29 </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 2 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> parborn </td>\n",
       "   <td style=\"text-align:right;\"> 0.91 </td>\n",
       "   <td style=\"text-align:right;\"> 2.45 </td>\n",
       "   <td style=\"text-align:right;\"> 0 </td>\n",
       "   <td style=\"text-align:right;\"> 0 </td>\n",
       "   <td style=\"text-align:right;\"> 0 </td>\n",
       "   <td style=\"text-align:right;\"> 0 </td>\n",
       "   <td style=\"text-align:right;\"> 8 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> hompop </td>\n",
       "   <td style=\"text-align:right;\"> 2.65 </td>\n",
       "   <td style=\"text-align:right;\"> 1.40 </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 2 </td>\n",
       "   <td style=\"text-align:right;\"> 2 </td>\n",
       "   <td style=\"text-align:right;\"> 4 </td>\n",
       "   <td style=\"text-align:right;\"> 11 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> babies </td>\n",
       "   <td style=\"text-align:right;\"> 0.23 </td>\n",
       "   <td style=\"text-align:right;\"> 0.55 </td>\n",
       "   <td style=\"text-align:right;\"> 0 </td>\n",
       "   <td style=\"text-align:right;\"> 0 </td>\n",
       "   <td style=\"text-align:right;\"> 0 </td>\n",
       "   <td style=\"text-align:right;\"> 0 </td>\n",
       "   <td style=\"text-align:right;\"> 4 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> preteen </td>\n",
       "   <td style=\"text-align:right;\"> 0.31 </td>\n",
       "   <td style=\"text-align:right;\"> 0.66 </td>\n",
       "   <td style=\"text-align:right;\"> 0 </td>\n",
       "   <td style=\"text-align:right;\"> 0 </td>\n",
       "   <td style=\"text-align:right;\"> 0 </td>\n",
       "   <td style=\"text-align:right;\"> 0 </td>\n",
       "   <td style=\"text-align:right;\"> 5 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> teens </td>\n",
       "   <td style=\"text-align:right;\"> 0.22 </td>\n",
       "   <td style=\"text-align:right;\"> 0.53 </td>\n",
       "   <td style=\"text-align:right;\"> 0 </td>\n",
       "   <td style=\"text-align:right;\"> 0 </td>\n",
       "   <td style=\"text-align:right;\"> 0 </td>\n",
       "   <td style=\"text-align:right;\"> 0 </td>\n",
       "   <td style=\"text-align:right;\"> 4 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> adults </td>\n",
       "   <td style=\"text-align:right;\"> 1.89 </td>\n",
       "   <td style=\"text-align:right;\"> 0.77 </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 2 </td>\n",
       "   <td style=\"text-align:right;\"> 2 </td>\n",
       "   <td style=\"text-align:right;\"> 8 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> earnrs </td>\n",
       "   <td style=\"text-align:right;\"> 1.74 </td>\n",
       "   <td style=\"text-align:right;\"> 0.83 </td>\n",
       "   <td style=\"text-align:right;\"> 0 </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 2 </td>\n",
       "   <td style=\"text-align:right;\"> 2 </td>\n",
       "   <td style=\"text-align:right;\"> 8 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> income </td>\n",
       "   <td style=\"text-align:right;\"> 11.29 </td>\n",
       "   <td style=\"text-align:right;\"> 1.65 </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 11 </td>\n",
       "   <td style=\"text-align:right;\"> 12 </td>\n",
       "   <td style=\"text-align:right;\"> 12 </td>\n",
       "   <td style=\"text-align:right;\"> 12 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> rincome </td>\n",
       "   <td style=\"text-align:right;\"> 10.20 </td>\n",
       "   <td style=\"text-align:right;\"> 2.75 </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 9 </td>\n",
       "   <td style=\"text-align:right;\"> 12 </td>\n",
       "   <td style=\"text-align:right;\"> 12 </td>\n",
       "   <td style=\"text-align:right;\"> 12 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> partyid </td>\n",
       "   <td style=\"text-align:right;\"> 2.95 </td>\n",
       "   <td style=\"text-align:right;\"> 2.03 </td>\n",
       "   <td style=\"text-align:right;\"> 0 </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 3 </td>\n",
       "   <td style=\"text-align:right;\"> 5 </td>\n",
       "   <td style=\"text-align:right;\"> 7 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> polviews </td>\n",
       "   <td style=\"text-align:right;\"> 4.08 </td>\n",
       "   <td style=\"text-align:right;\"> 1.36 </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 3 </td>\n",
       "   <td style=\"text-align:right;\"> 4 </td>\n",
       "   <td style=\"text-align:right;\"> 5 </td>\n",
       "   <td style=\"text-align:right;\"> 7 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> W </td>\n",
       "   <td style=\"text-align:right;\"> 0.51 </td>\n",
       "   <td style=\"text-align:right;\"> 0.50 </td>\n",
       "   <td style=\"text-align:right;\"> 0 </td>\n",
       "   <td style=\"text-align:right;\"> 0 </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> Y </td>\n",
       "   <td style=\"text-align:right;\"> 0.29 </td>\n",
       "   <td style=\"text-align:right;\"> 0.45 </td>\n",
       "   <td style=\"text-align:right;\"> 0 </td>\n",
       "   <td style=\"text-align:right;\"> 0 </td>\n",
       "   <td style=\"text-align:right;\"> 0 </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "   <td style=\"text-align:right;\"> 1 </td>\n",
       "  </tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Pretty-printing in HTML\n",
    "summ_stats_table <- kable(summ_stats, \"html\", digits = 2)\n",
    "kable_styling(summ_stats_table,\n",
    "              bootstrap_options=c(\"striped\", \"hover\", \"condensed\", \"responsive\"),\n",
    "              full_width=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presenting pairwise correlations is easy with the `corrplot` function from the `corrplot` package. On the table below, if the (unadjusted) p-value for a pair of variables is less than 0.05, its square is not colored.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAACiFBMVEUAAAAFMGEGMmQHNWgJ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",
      "text/plain": [
       "Plot with title \"\""
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Note: if the plot looks too cramped, try increasing fig.width and fig.height in the line above\n",
    "pairwise_pvalues <- psych::corr.test(df, df)$p\n",
    "corrplot(cor(df),\n",
    "         type=\"upper\",\n",
    "         tl.col=\"black\",\n",
    "         order=\"hclust\",\n",
    "         tl.cex=1,\n",
    "         addgrid.col = \"black\",\n",
    "         p.mat=pairwise_pvalues,\n",
    "         sig.level=0.05,\n",
    "         number.font=10,\n",
    "         insig=\"blank\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Now we are ready to delve into modern methods in more detail. -->\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## HTE 1: Causal Trees\n",
    "\n",
    "**Reference:** [Athey and Imbens (PNAS, 2016)](https://www.pnas.org/content/pnas/113/27/7353.full.pdf)\n",
    "\n",
    "Detecting heterogeneous treatment effects, i.e., differential effects of an intervention for certain subgroups of the population, can be very valuable in many areas of research. In medicine, for example, researchers might be interested in finding which subgroup of patients benefits most from getting a certain drug. At the same time, one might be worried about finding spurious effects just by estimating many different specifications, and this is why many scientific fields require pre-analysis plans for publications. However, researchers may find these plans restrictive since they cannot publish results for subgroups they did not anticipate before running the experiment.\n",
    "\n",
    "Athey and Imbens (2016)'s **causal trees** provide a data-driven approach to partitioning the data into subgroups that differ by the magnitude of their treatment effects. Much like decision trees, which partition the covariate space by finding subgroups with similar *outcomes*, causal trees find subgroups with *similar treatment effects*. Moreover, even though this is an adaptive method, these subgroups do not need to be specified prior to the experiment.\n",
    "\n",
    "In order to ensure valid estimates of the treatment effect within each subgroup, Athey and Imbens propose a sample-splitting approach that they refer to as **honesty**: a method is honest if it uses one subset of the data to estimate the model parameters, and a different subset to produce estimates given these estimated parameters. In the context of causal trees, honesty implies that the asymptotic properties of treatment effect estimates within leaves are the same as if the tree partition had been exogenously given, and it is one of the assumptions required to produce unbiased and asymptotically normal estimates of the treatment effect.\n",
    "\n",
    "#### Step 1: Split the dataset\n",
    "\n",
    "As we just explained, honesty requires us to separate different subsets of our training data for model selection and prediction.\n",
    "\n",
    "+ `df_split`: the *splitting sample*, used to build the tree\n",
    "+ `df_est`: the *estimation sample*, used to compute the average treatment effect in each leaf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diving the data 40%-40%-20% into splitting, estimation and validation samples\n",
    "split_size <- floor(nrow(df_train) * 0.5)\n",
    "split_idx <- sample(nrow(df_train), replace=FALSE, size=split_size)\n",
    "\n",
    "# Make the splits\n",
    "df_split <- df_train[split_idx,]\n",
    "df_est <- df_train[-split_idx,]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Fit the tree\n",
    "\n",
    "Begin by defining a formula containing only the outcome and the covariates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmla_ct <- paste(\"factor(Y) ~\", paste(covariate_names, collapse = \" + \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use the `honest.causalTree` function from the `causalTree` package. To ensure that honesty is enabled, the parameters for splitting and cross-validation below should not be changed. However, if your tree is not splitting at all, try decreasing the parameter `minsize` that controls the minimum size of each leaf.\n",
    "\n",
    "For more details on other parameters, please take a look at this extended [documentation](https://github.com/susanathey/causalTree/blob/master/briefintro.pdf) for the `causalTree` paper.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 2\n",
      "[1] \"CT\"\n"
     ]
    }
   ],
   "source": [
    "ct_unpruned <- honest.causalTree(\n",
    "  formula=fmla_ct,            # Define the model\n",
    "  data=df_split,              # Subset used to create tree structure\n",
    "  est_data=df_est,            # Which data set to use to estimate effects\n",
    "\n",
    "  treatment=df_split$W,       # Splitting sample treatment variable\n",
    "  est_treatment=df_est$W,     # Estimation sample treatment variable\n",
    "\n",
    "  split.Rule=\"CT\",            # Define the splitting option\n",
    "  cv.option=\"TOT\",            # Cross validation options\n",
    "\n",
    "  split.Honest=TRUE,          # Use honesty when splitting\n",
    "  cv.Honest=TRUE,             # Use honesty when performing cross-validation\n",
    "\n",
    "  minsize=25,                 # Min. number of treatment and control cases in each leaf\n",
    "  HonestSampleSize=nrow(df_est)) # Num obs used in estimation after building the tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The resulting object will be `rpart` objects, so `rpart` methods for cross-validation and plotting can be used.\n",
    "\n",
    "#### Step 3: Cross-validate\n",
    "\n",
    "We must prune the tree by cross-validation to avoid overfitting. The honest cross-validation method selected above (and recommended) penalizes an estimate of the variance in the treatment effects estimates across leaves, and this estimate is computed using the estimation sample. The `cv.option` selected above ($TOT$) uses an unbiased estimate of the test mean-squared error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table of cross-validated values by tuning parameter.\n",
    "ct_cptable <- as.data.frame(ct_unpruned$cptable)\n",
    "\n",
    "# Obtain optimal complexity parameter to prune tree.\n",
    "selected_cp <- which.min(ct_cptable$xerror)\n",
    "optim_cp_ct <- ct_cptable[selected_cp, \"CP\"]\n",
    "\n",
    "# Prune the tree at optimal complexity parameter.\n",
    "ct_pruned <- prune(tree=ct_unpruned, cp=optim_cp_ct)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Step 4: Predict point estimates (on estimation sample)\n",
    "\n",
    "To predict the treatment effect on the estimation sample, use the function `predict` as below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "tauhat_ct_est <- predict(ct_pruned, newdata=df_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Step 5: Compute standard errors\n",
    "\n",
    "The `causalTree` package does not compute standard errors by default, but we can compute them using the following trick. First, define $L_{\\ell}$ to indicate assignment to leaf $\\ell$ and consider the following linear model.\n",
    "\n",
    "\\begin{align}\n",
    "Y = \\sum_{\\ell} L_{\\ell}\\alpha_{\\ell} + W \\cdot L_{\\ell} \\beta_{\\ell}\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a factor column 'leaf' indicating leaf assignment\n",
    "num_leaves <- length(unique(tauhat_ct_est))  # There are as many leaves as there are predictions\n",
    "df_est$leaf <- factor(tauhat_ct_est, labels = seq(num_leaves))\n",
    "\n",
    "# Run the regression\n",
    "ols_ct <- lm(as.formula(\"Y ~ 0 + leaf + W:leaf\"), data=df_est)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interaction coefficients in this regression recover the average treatment effects in each leaf, since\n",
    "\n",
    "\\begin{align}\n",
    " E[Y|W=1, L=1] - E[Y|W=0, L=1] = (\\alpha_{1} + \\beta_{1}) - (\\alpha_{1}) = \\beta_{1}\n",
    "\\end{align}\n",
    "\n",
    "Therefore, the standard error around the coefficients is also the standard error around the treatment effects. In the next subsection, we will also use these statistics to test hypothesis about leaf estimates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_ct_summary <- summary(ols_ct)\n",
    "te_summary <- coef(ols_ct_summary)[(num_leaves+1):(2*num_leaves), c(\"Estimate\", \"Std. Error\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table class=\"table table-striped table-hover table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n",
       "<caption>Average treatment effects per leaf</caption>\n",
       " <thead>\n",
       "  <tr>\n",
       "   <th style=\"text-align:left;\">   </th>\n",
       "   <th style=\"text-align:right;\"> Estimate </th>\n",
       "   <th style=\"text-align:right;\"> Std. Error </th>\n",
       "  </tr>\n",
       " </thead>\n",
       "<tbody>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> leaf1:W </td>\n",
       "   <td style=\"text-align:right;\"> -0.5369 </td>\n",
       "   <td style=\"text-align:right;\"> 0.0469 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> leaf2:W </td>\n",
       "   <td style=\"text-align:right;\"> -0.3933 </td>\n",
       "   <td style=\"text-align:right;\"> 0.0154 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> leaf3:W </td>\n",
       "   <td style=\"text-align:right;\"> -0.3466 </td>\n",
       "   <td style=\"text-align:right;\"> 0.0526 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> leaf4:W </td>\n",
       "   <td style=\"text-align:right;\"> -0.3150 </td>\n",
       "   <td style=\"text-align:right;\"> 0.0459 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> leaf5:W </td>\n",
       "   <td style=\"text-align:right;\"> -0.2697 </td>\n",
       "   <td style=\"text-align:right;\"> 0.0213 </td>\n",
       "  </tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kable_styling(kable(te_summary, \"html\", digits = 4, caption=\"Average treatment effects per leaf\"),\n",
    "                    bootstrap_options=c(\"striped\", \"hover\", \"condensed\", \"responsive\"),\n",
    "                    full_width=FALSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Step 6: Predict point estimates (on test set)\n",
    "\n",
    "To predict the treatment effect on a new, entirely unseen data, use the function `predict` as below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "tauhat_ct_test <- predict(ct_pruned, newdata=df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Assessing heterogeneity\n",
    "\n",
    "A natural place to begin is by ploting the (pruned) tree. We can use the `rpart.plot` function from the `rpart.plot` package.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAABEVBMVEUAAAAgNEErR1cwPUQ0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\nIBEiAINEiAAMEiECMEiECMAgESLA/wPnBzOcixuskwAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rpart.plot(\n",
    "  x=ct_pruned,        # Pruned tree\n",
    "  type=3,             # Draw separate split labels for the left and right directions\n",
    "  fallen=TRUE,        # Position the leaf nodes at the bottom of the graph\n",
    "  leaf.round=1,       # Rounding of the corners of the leaf node boxes\n",
    "  extra=100,          # Display the percentage of observations in the node\n",
    "  branch=.1,          # Shape of the branch lines\n",
    "  box.palette=\"RdBu\") # Palette for coloring the node\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Treatment effect heterogeneity\n",
    "\n",
    "We may want to test the treatment effect is different across leaves. That is, to test the null hypothesis that\n",
    "\n",
    "$$\n",
    " E[Y|W=1, L=1] - E[Y|W=0, L=1] =  E[Y|W=1, L=\\ell] - E[Y|W=0, L=\\ell] \\quad \\text{for all } \\ell > 1\n",
    "$$\n",
    "\n",
    "Following the linear model setup described in Step 5 in the previous subsection, we can use the function `linearHypothesis` from the `car` package to test this hypothesis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null hypothesis: all leaf values are the same\n",
    "hypothesis <- paste0(\"leaf1:W = leaf\", seq(2, num_leaves), \":W\")\n",
    "ftest <- linearHypothesis(ols_ct, hypothesis, test=\"F\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table class=\"table table-striped table-hover table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n",
       "<caption>Testing null hypothesis:<br> Average treatment effect is same across leaves</caption>\n",
       " <thead>\n",
       "  <tr>\n",
       "   <th style=\"text-align:left;\">   </th>\n",
       "   <th style=\"text-align:right;\"> Res.Df </th>\n",
       "   <th style=\"text-align:right;\"> RSS </th>\n",
       "   <th style=\"text-align:right;\"> Df </th>\n",
       "   <th style=\"text-align:right;\"> Sum of Sq </th>\n",
       "   <th style=\"text-align:right;\"> F </th>\n",
       "   <th style=\"text-align:right;\"> Pr(&gt;F) </th>\n",
       "  </tr>\n",
       " </thead>\n",
       "<tbody>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> 2 </td>\n",
       "   <td style=\"text-align:right;\"> 5269 </td>\n",
       "   <td style=\"text-align:right;\"> 901.4038 </td>\n",
       "   <td style=\"text-align:right;\"> 4 </td>\n",
       "   <td style=\"text-align:right;\"> 6.4919 </td>\n",
       "   <td style=\"text-align:right;\"> 9.4869 </td>\n",
       "   <td style=\"text-align:right;\"> 0 </td>\n",
       "  </tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kable_styling(kable(data.frame(ftest, check.names = FALSE, row.names = NULL)[2,],\n",
    "              \"html\", digits = 4,\n",
    "              caption=\"Testing null hypothesis:<br> Average treatment effect is same across leaves\"),\n",
    "              bootstrap_options=c(\"striped\", \"hover\", \"condensed\", \"responsive\"),\n",
    "              full_width=FALSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Next, we test if the average treatment effect is different between all two pairs of leaves. Note that here we are not performing any type of multiple hypothesis testing correction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null hypothesis: leaf i = leaf k for all i != k\n",
    "p_values_leaf_by_leaf <- matrix(nrow = num_leaves, ncol = num_leaves)\n",
    "differences_leaf_by_leaf <- matrix(nrow = num_leaves, ncol = num_leaves)\n",
    "stderror_leaf_by_leaf <- matrix(nrow = num_leaves, ncol = num_leaves)\n",
    "hypotheses_grid <- combn(1:num_leaves, 2)\n",
    "summ <- coef(summary(ols_ct))\n",
    "\n",
    "invisible(apply(hypotheses_grid, 2, function(x) {\n",
    "  leafi <- paste0(\"leaf\", x[1], \":W\")\n",
    "  leafj <- paste0(\"leaf\", x[2], \":W\")\n",
    "  hypothesis <- paste0(leafi, \" = \", leafj)\n",
    "\n",
    "  differences_leaf_by_leaf[x[2], x[1]] <<- summ[leafj, 1] - summ[leafi, 1]\n",
    "  stderror_leaf_by_leaf[x[2], x[1]] <<- sqrt(summ[leafj, 2]^2 + summ[leafi, 2]^2)\n",
    "  p_values_leaf_by_leaf[x[2], x[1]] <<- linearHypothesis(ols_ct, hypothesis)[2, \"Pr(>F)\"]\n",
    "}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table class=\"table table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;border-bottom: 0;\">\n",
       "<caption>Pairwise leaf differences:<br>\n",
       "Average treatment effect differences between leaf i and leaf j</caption>\n",
       " <thead>\n",
       "  <tr>\n",
       "   <th style=\"text-align:left;\"> rowname </th>\n",
       "   <th style=\"text-align:left;\"> leaf1 </th>\n",
       "   <th style=\"text-align:left;\"> leaf2 </th>\n",
       "   <th style=\"text-align:left;\"> leaf3 </th>\n",
       "   <th style=\"text-align:left;\"> leaf4 </th>\n",
       "   <th style=\"text-align:left;\"> leaf5 </th>\n",
       "  </tr>\n",
       " </thead>\n",
       "<tbody>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\"     color: gray !important;\">leaf1</span> </td>\n",
       "   <td style=\"text-align:left;\"> <span style=\"     color: white !important;\">NA</span> </td>\n",
       "   <td style=\"text-align:left;\"> <span style=\"     color: white !important;\">NA</span> </td>\n",
       "   <td style=\"text-align:left;\"> <span style=\"     color: white !important;\">NA</span> </td>\n",
       "   <td style=\"text-align:left;\"> <span style=\"     color: white !important;\">NA</span> </td>\n",
       "   <td style=\"text-align:left;\"> <span style=\"     color: white !important;\">NA</span> </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\"     color: gray !important;\">leaf2</span> </td>\n",
       "   <td style=\"text-align:left;\"> <span style=\"     color: gray !important;\"><span style=\"     color: white !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: gray !important;\">0.144</span> <br> (0.049)</span> </td>\n",
       "   <td style=\"text-align:left;\"> <span style=\"     color: white !important;\">NA</span> </td>\n",
       "   <td style=\"text-align:left;\"> <span style=\"     color: white !important;\">NA</span> </td>\n",
       "   <td style=\"text-align:left;\"> <span style=\"     color: white !important;\">NA</span> </td>\n",
       "   <td style=\"text-align:left;\"> <span style=\"     color: white !important;\">NA</span> </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\"     color: gray !important;\">leaf3</span> </td>\n",
       "   <td style=\"text-align:left;\"> <span style=\"     color: gray !important;\"><span style=\"     color: white !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: gray !important;\">0.19</span> <br> (0.071)</span> </td>\n",
       "   <td style=\"text-align:left;\"> <span style=\"     color: gray !important;\"><span style=\"     color: gray !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: white !important;\">0.047</span> <br> (0.055)</span> </td>\n",
       "   <td style=\"text-align:left;\"> <span style=\"     color: white !important;\">NA</span> </td>\n",
       "   <td style=\"text-align:left;\"> <span style=\"     color: white !important;\">NA</span> </td>\n",
       "   <td style=\"text-align:left;\"> <span style=\"     color: white !important;\">NA</span> </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\"     color: gray !important;\">leaf4</span> </td>\n",
       "   <td style=\"text-align:left;\"> <span style=\"     color: gray !important;\"><span style=\"     color: white !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: gray !important;\">0.222</span> <br> (0.066)</span> </td>\n",
       "   <td style=\"text-align:left;\"> <span style=\"     color: gray !important;\"><span style=\"     color: gray !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: white !important;\">0.078</span> <br> (0.048)</span> </td>\n",
       "   <td style=\"text-align:left;\"> <span style=\"     color: gray !important;\"><span style=\"     color: gray !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: white !important;\">0.032</span> <br> (0.07)</span> </td>\n",
       "   <td style=\"text-align:left;\"> <span style=\"     color: white !important;\">NA</span> </td>\n",
       "   <td style=\"text-align:left;\"> <span style=\"     color: white !important;\">NA</span> </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\"     color: gray !important;\">leaf5</span> </td>\n",
       "   <td style=\"text-align:left;\"> <span style=\"     color: gray !important;\"><span style=\"     color: white !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: gray !important;\">0.267</span> <br> (0.052)</span> </td>\n",
       "   <td style=\"text-align:left;\"> <span style=\"     color: gray !important;\"><span style=\"     color: white !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: gray !important;\">0.124</span> <br> (0.026)</span> </td>\n",
       "   <td style=\"text-align:left;\"> <span style=\"     color: gray !important;\"><span style=\"     color: gray !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: white !important;\">0.077</span> <br> (0.057)</span> </td>\n",
       "   <td style=\"text-align:left;\"> <span style=\"     color: gray !important;\"><span style=\"     color: gray !important;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: white !important;\">0.045</span> <br> (0.051)</span> </td>\n",
       "   <td style=\"text-align:left;\"> <span style=\"     color: white !important;\">NA</span> </td>\n",
       "  </tr>\n",
       "</tbody>\n",
       "<tfoot>\n",
       "<tr><td style=\"padding: 0; \" colspan=\"100%\"><span style=\"font-style: italic;\">Note: </span></td></tr>\n",
       "<tr><td style=\"padding: 0; \" colspan=\"100%\">\n",
       "<sup></sup> Standard errors in parenthesis. Significance (not adjusted for multiple testing):\n",
       "<ul>\n",
       "  <li>No background color: p = 0.1\n",
       "  </li>\n",
       "<li>\n",
       "<span style=\"color: white;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: gray;\">Gray</span> background: p &lt; 0.1\n",
       "  </li>\n",
       "<li>\n",
       "<span style=\"color: white;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: black;\">Black</span> background: p &lt; 0.05\n",
       "</li>\n",
       "</ul>\n",
       "</td></tr>\n",
       "</tfoot>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Little trick to display p-values under mean difference values in HTML\n",
    "diffs <- matrix(nrow = num_leaves, ncol = num_leaves)\n",
    "invisible(apply(hypotheses_grid, 2, function(x) {\n",
    "  d <- differences_leaf_by_leaf[x[2], x[1]]\n",
    "  s <- stderror_leaf_by_leaf[x[2], x[1]]\n",
    "  p <- p_values_leaf_by_leaf[x[2], x[1]]\n",
    "  top <- cell_spec(round(d, 3), \"html\",\n",
    "            background=ifelse(is.na(p) || (p > 0.1), \"white\", \"gray\"),\n",
    "            color=ifelse(is.na(p), \"white\", ifelse(p < 0.1, \"white\", \"gray\")))\n",
    "  value <- ifelse(is.na(p), \"\", paste0(top, \" <br> \", \"(\", round(s, 3), \")\"))\n",
    "  diffs[x[2], x[1]] <<- value\n",
    "}))\n",
    "\n",
    "diffs <- as.data.frame(diffs) %>% mutate_all(as.character)\n",
    "rownames(diffs) <- paste0(\"leaf\", 1:num_leaves)\n",
    "colnames(diffs) <- paste0(\"leaf\", 1:num_leaves)\n",
    "\n",
    "# Title of table\n",
    "caption <- \"Pairwise leaf differences:<br>\n",
    "Average treatment effect differences between leaf i and leaf j\"\n",
    "\n",
    "# Styling color and background\n",
    "color <-function(x) ifelse(is.na(x), \"white\", \"gray\")\n",
    "\n",
    "diffs %>%\n",
    "  rownames_to_column() %>%\n",
    "  mutate_all(function(x) cell_spec(x, \"html\", escape=FALSE, color=color(x))) %>%\n",
    "  kable(format=\"html\", caption=caption, escape = FALSE) %>%\n",
    "  kable_styling(bootstrap_options=c(\"condensed\", \"responsive\"), full_width=FALSE) %>%\n",
    "  footnote(general='Standard errors in parenthesis. Significance (not adjusted for multiple testing):\n",
    "<ul>\n",
    "  <li>No background color: p â¥ 0.1\n",
    "  <li><span style=\"color: white;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: gray;\">Gray</span> background: p < 0.1\n",
    "  <li><span style=\"color: white;border-radius: 4px; padding-right: 4px; padding-left: 4px; background-color: black;\">Black</span> background: p < 0.05\n",
    "</ul>\n",
    "', escape=F)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Covariate heterogeneity\n",
    "\n",
    "Another measure of heterogeneity is how much the average level of each covariate changes across leaves. The following code summarizes that.\n",
    "\n",
    "**Important remark** We should NOT conclude that a particular covariate is unrelated to treatment effects simply because the tree did not split on it.  There can be many different ways to pick out a subgroup of individuals with high or low treatment effects.  By comparing the average characteristics of individuals with high treatment effects to those with low treatment effects, we can get a fuller picture of the differences between these groups across all covariates.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null hypothesis: the mean is equal across all leaves\n",
    "hypothesis <- paste0(\"leaf1 = leaf\", seq(2, num_leaves))\n",
    "means_per_leaf <- matrix(nrow = num_leaves, ncol = num_leaves)\n",
    "significance <- matrix(nrow = 2, ncol=length(covariate_names))\n",
    "\n",
    "# Regress each covariate on leaf assignment to means p\n",
    "cov_means <- lapply(covariate_names, function(covariate) {\n",
    "  lm(paste0(covariate, ' ~ 0 + leaf'), data = df_est)\n",
    "})\n",
    "\n",
    "# Extract the mean and standard deviation of each covariate per leaf\n",
    "cov_table <- lapply(cov_means, function(cov_mean) {\n",
    "  as.data.frame(t(coef(summary(cov_mean))[,c(\"Estimate\", \"Std. Error\")]))\n",
    "})\n",
    "\n",
    "# Test if means are the same across leaves\n",
    "cov_ftests <- sapply(cov_means, function(cov_mean) {\n",
    "  # Sometimes the regression has no residual (SSE = 0), \n",
    "  # so we cannot perform an F-test\n",
    "  tryCatch({\n",
    "    linearHypothesis(cov_mean, hypothesis)[2, c(\"F\", \"Pr(>F)\")]\n",
    "  },\n",
    "    error = function(cond) {\n",
    "      message(paste0(\"Error message during F-test for`\", cov_mean$terms[[2]], \"`:\"))\n",
    "      message(cond)\n",
    "      return(c(\"F\" = NA, \"Pr(>F)\" = NA))\n",
    "    })\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table class=\"table table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n",
       "<caption>Average covariate values in each leaf</caption>\n",
       " <thead>\n",
       "  <tr>\n",
       "   <th style=\"text-align:left;\"> covariates </th>\n",
       "   <th style=\"text-align:left;\"> leaf1 </th>\n",
       "   <th style=\"text-align:left;\"> leaf2 </th>\n",
       "   <th style=\"text-align:left;\"> leaf3 </th>\n",
       "   <th style=\"text-align:left;\"> leaf4 </th>\n",
       "   <th style=\"text-align:left;\"> leaf5 </th>\n",
       "  </tr>\n",
       " </thead>\n",
       "<tbody>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">hrs1</span> </td>\n",
       "   <td style=\"text-align:left;\"> 43.09 </td>\n",
       "   <td style=\"text-align:left;\"> 42.68 </td>\n",
       "   <td style=\"text-align:left;\"> 41.97 </td>\n",
       "   <td style=\"text-align:left;\"> 41.2 </td>\n",
       "   <td style=\"text-align:left;\"> 41.92 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.801) </td>\n",
       "   <td style=\"text-align:left;\"> (0.263) </td>\n",
       "   <td style=\"text-align:left;\"> (0.897) </td>\n",
       "   <td style=\"text-align:left;\"> (0.781) </td>\n",
       "   <td style=\"text-align:left;\"> (0.363) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">partyid</span> </td>\n",
       "   <td style=\"text-align:left;\"> 5.026 </td>\n",
       "   <td style=\"text-align:left;\"> 3.427 </td>\n",
       "   <td style=\"text-align:left;\"> 2.722 </td>\n",
       "   <td style=\"text-align:left;\"> 1.621 </td>\n",
       "   <td style=\"text-align:left;\"> 1.974 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.103) </td>\n",
       "   <td style=\"text-align:left;\"> (0.034) </td>\n",
       "   <td style=\"text-align:left;\"> (0.116) </td>\n",
       "   <td style=\"text-align:left;\"> (0.101) </td>\n",
       "   <td style=\"text-align:left;\"> (0.047) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">income</span> </td>\n",
       "   <td style=\"text-align:left;\"> 11.56 </td>\n",
       "   <td style=\"text-align:left;\"> 11.25 </td>\n",
       "   <td style=\"text-align:left;\"> 11.28 </td>\n",
       "   <td style=\"text-align:left;\"> 11.44 </td>\n",
       "   <td style=\"text-align:left;\"> 11.24 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.096) </td>\n",
       "   <td style=\"text-align:left;\"> (0.031) </td>\n",
       "   <td style=\"text-align:left;\"> (0.107) </td>\n",
       "   <td style=\"text-align:left;\"> (0.093) </td>\n",
       "   <td style=\"text-align:left;\"> (0.043) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">rincome</span> </td>\n",
       "   <td style=\"text-align:left;\"> 10.71 </td>\n",
       "   <td style=\"text-align:left;\"> 10.21 </td>\n",
       "   <td style=\"text-align:left;\"> 10.1 </td>\n",
       "   <td style=\"text-align:left;\"> 10.17 </td>\n",
       "   <td style=\"text-align:left;\"> 10.2 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.155) </td>\n",
       "   <td style=\"text-align:left;\"> (0.051) </td>\n",
       "   <td style=\"text-align:left;\"> (0.173) </td>\n",
       "   <td style=\"text-align:left;\"> (0.151) </td>\n",
       "   <td style=\"text-align:left;\"> (0.07) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">wrkstat</span> </td>\n",
       "   <td style=\"text-align:left;\"> 1.138 </td>\n",
       "   <td style=\"text-align:left;\"> 1.146 </td>\n",
       "   <td style=\"text-align:left;\"> 1.153 </td>\n",
       "   <td style=\"text-align:left;\"> 1.187 </td>\n",
       "   <td style=\"text-align:left;\"> 1.164 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.02) </td>\n",
       "   <td style=\"text-align:left;\"> (0.007) </td>\n",
       "   <td style=\"text-align:left;\"> (0.023) </td>\n",
       "   <td style=\"text-align:left;\"> (0.02) </td>\n",
       "   <td style=\"text-align:left;\"> (0.009) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">wrkslf</span> </td>\n",
       "   <td style=\"text-align:left;\"> 1.855 </td>\n",
       "   <td style=\"text-align:left;\"> 1.863 </td>\n",
       "   <td style=\"text-align:left;\"> 1.883 </td>\n",
       "   <td style=\"text-align:left;\"> 1.893 </td>\n",
       "   <td style=\"text-align:left;\"> 1.884 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.019) </td>\n",
       "   <td style=\"text-align:left;\"> (0.006) </td>\n",
       "   <td style=\"text-align:left;\"> (0.021) </td>\n",
       "   <td style=\"text-align:left;\"> (0.018) </td>\n",
       "   <td style=\"text-align:left;\"> (0.009) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">age</span> </td>\n",
       "   <td style=\"text-align:left;\"> 42.35 </td>\n",
       "   <td style=\"text-align:left;\"> 40.77 </td>\n",
       "   <td style=\"text-align:left;\"> 40.46 </td>\n",
       "   <td style=\"text-align:left;\"> 41.27 </td>\n",
       "   <td style=\"text-align:left;\"> 39.56 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.691) </td>\n",
       "   <td style=\"text-align:left;\"> (0.227) </td>\n",
       "   <td style=\"text-align:left;\"> (0.774) </td>\n",
       "   <td style=\"text-align:left;\"> (0.674) </td>\n",
       "   <td style=\"text-align:left;\"> (0.313) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">polviews</span> </td>\n",
       "   <td style=\"text-align:left;\"> 4.944 </td>\n",
       "   <td style=\"text-align:left;\"> 4.789 </td>\n",
       "   <td style=\"text-align:left;\"> 4.631 </td>\n",
       "   <td style=\"text-align:left;\"> 4.349 </td>\n",
       "   <td style=\"text-align:left;\"> 2.383 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.047) </td>\n",
       "   <td style=\"text-align:left;\"> (0.015) </td>\n",
       "   <td style=\"text-align:left;\"> (0.053) </td>\n",
       "   <td style=\"text-align:left;\"> (0.046) </td>\n",
       "   <td style=\"text-align:left;\"> (0.021) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">educ</span> </td>\n",
       "   <td style=\"text-align:left;\"> 14.46 </td>\n",
       "   <td style=\"text-align:left;\"> 13.77 </td>\n",
       "   <td style=\"text-align:left;\"> 13.68 </td>\n",
       "   <td style=\"text-align:left;\"> 13.65 </td>\n",
       "   <td style=\"text-align:left;\"> 14.6 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.153) </td>\n",
       "   <td style=\"text-align:left;\"> (0.05) </td>\n",
       "   <td style=\"text-align:left;\"> (0.171) </td>\n",
       "   <td style=\"text-align:left;\"> (0.149) </td>\n",
       "   <td style=\"text-align:left;\"> (0.069) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">earnrs</span> </td>\n",
       "   <td style=\"text-align:left;\"> 1.762 </td>\n",
       "   <td style=\"text-align:left;\"> 1.755 </td>\n",
       "   <td style=\"text-align:left;\"> 1.831 </td>\n",
       "   <td style=\"text-align:left;\"> 1.786 </td>\n",
       "   <td style=\"text-align:left;\"> 1.667 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.047) </td>\n",
       "   <td style=\"text-align:left;\"> (0.016) </td>\n",
       "   <td style=\"text-align:left;\"> (0.053) </td>\n",
       "   <td style=\"text-align:left;\"> (0.046) </td>\n",
       "   <td style=\"text-align:left;\"> (0.021) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">race</span> </td>\n",
       "   <td style=\"text-align:left;\"> 1.055 </td>\n",
       "   <td style=\"text-align:left;\"> 1.202 </td>\n",
       "   <td style=\"text-align:left;\"> 1.948 </td>\n",
       "   <td style=\"text-align:left;\"> 1.208 </td>\n",
       "   <td style=\"text-align:left;\"> 1.289 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.031) </td>\n",
       "   <td style=\"text-align:left;\"> (0.01) </td>\n",
       "   <td style=\"text-align:left;\"> (0.035) </td>\n",
       "   <td style=\"text-align:left;\"> (0.03) </td>\n",
       "   <td style=\"text-align:left;\"> (0.014) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">wrkslf</span> </td>\n",
       "   <td style=\"text-align:left;\"> 1.855 </td>\n",
       "   <td style=\"text-align:left;\"> 1.863 </td>\n",
       "   <td style=\"text-align:left;\"> 1.883 </td>\n",
       "   <td style=\"text-align:left;\"> 1.893 </td>\n",
       "   <td style=\"text-align:left;\"> 1.884 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.019) </td>\n",
       "   <td style=\"text-align:left;\"> (0.006) </td>\n",
       "   <td style=\"text-align:left;\"> (0.021) </td>\n",
       "   <td style=\"text-align:left;\"> (0.018) </td>\n",
       "   <td style=\"text-align:left;\"> (0.009) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">marital</span> </td>\n",
       "   <td style=\"text-align:left;\"> 2.17 </td>\n",
       "   <td style=\"text-align:left;\"> 2.283 </td>\n",
       "   <td style=\"text-align:left;\"> 2.105 </td>\n",
       "   <td style=\"text-align:left;\"> 2.572 </td>\n",
       "   <td style=\"text-align:left;\"> 2.801 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.094) </td>\n",
       "   <td style=\"text-align:left;\"> (0.031) </td>\n",
       "   <td style=\"text-align:left;\"> (0.106) </td>\n",
       "   <td style=\"text-align:left;\"> (0.092) </td>\n",
       "   <td style=\"text-align:left;\"> (0.043) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">sibs</span> </td>\n",
       "   <td style=\"text-align:left;\"> 2.675 </td>\n",
       "   <td style=\"text-align:left;\"> 3.451 </td>\n",
       "   <td style=\"text-align:left;\"> 5.137 </td>\n",
       "   <td style=\"text-align:left;\"> 3.419 </td>\n",
       "   <td style=\"text-align:left;\"> 3.211 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.164) </td>\n",
       "   <td style=\"text-align:left;\"> (0.054) </td>\n",
       "   <td style=\"text-align:left;\"> (0.184) </td>\n",
       "   <td style=\"text-align:left;\"> (0.16) </td>\n",
       "   <td style=\"text-align:left;\"> (0.074) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">childs</span> </td>\n",
       "   <td style=\"text-align:left;\"> 1.592 </td>\n",
       "   <td style=\"text-align:left;\"> 1.692 </td>\n",
       "   <td style=\"text-align:left;\"> 1.722 </td>\n",
       "   <td style=\"text-align:left;\"> 1.566 </td>\n",
       "   <td style=\"text-align:left;\"> 1.304 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.082) </td>\n",
       "   <td style=\"text-align:left;\"> (0.027) </td>\n",
       "   <td style=\"text-align:left;\"> (0.092) </td>\n",
       "   <td style=\"text-align:left;\"> (0.08) </td>\n",
       "   <td style=\"text-align:left;\"> (0.037) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">occ80</span> </td>\n",
       "   <td style=\"text-align:left;\"> 287.1 </td>\n",
       "   <td style=\"text-align:left;\"> 342 </td>\n",
       "   <td style=\"text-align:left;\"> 348.5 </td>\n",
       "   <td style=\"text-align:left;\"> 349.7 </td>\n",
       "   <td style=\"text-align:left;\"> 310 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (13.76) </td>\n",
       "   <td style=\"text-align:left;\"> (4.523) </td>\n",
       "   <td style=\"text-align:left;\"> (15.41) </td>\n",
       "   <td style=\"text-align:left;\"> (13.42) </td>\n",
       "   <td style=\"text-align:left;\"> (6.238) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">prestg80</span> </td>\n",
       "   <td style=\"text-align:left;\"> 47.6 </td>\n",
       "   <td style=\"text-align:left;\"> 44.8 </td>\n",
       "   <td style=\"text-align:left;\"> 44.59 </td>\n",
       "   <td style=\"text-align:left;\"> 44.23 </td>\n",
       "   <td style=\"text-align:left;\"> 47.28 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.793) </td>\n",
       "   <td style=\"text-align:left;\"> (0.261) </td>\n",
       "   <td style=\"text-align:left;\"> (0.888) </td>\n",
       "   <td style=\"text-align:left;\"> (0.773) </td>\n",
       "   <td style=\"text-align:left;\"> (0.359) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">indus80</span> </td>\n",
       "   <td style=\"text-align:left;\"> 633.7 </td>\n",
       "   <td style=\"text-align:left;\"> 593.5 </td>\n",
       "   <td style=\"text-align:left;\"> 593.6 </td>\n",
       "   <td style=\"text-align:left;\"> 615.6 </td>\n",
       "   <td style=\"text-align:left;\"> 623.7 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (15.44) </td>\n",
       "   <td style=\"text-align:left;\"> (5.074) </td>\n",
       "   <td style=\"text-align:left;\"> (17.29) </td>\n",
       "   <td style=\"text-align:left;\"> (15.06) </td>\n",
       "   <td style=\"text-align:left;\"> (6.997) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">res16</span> </td>\n",
       "   <td style=\"text-align:left;\"> 3.572 </td>\n",
       "   <td style=\"text-align:left;\"> 3.345 </td>\n",
       "   <td style=\"text-align:left;\"> 3.754 </td>\n",
       "   <td style=\"text-align:left;\"> 3.813 </td>\n",
       "   <td style=\"text-align:left;\"> 3.742 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.085) </td>\n",
       "   <td style=\"text-align:left;\"> (0.028) </td>\n",
       "   <td style=\"text-align:left;\"> (0.096) </td>\n",
       "   <td style=\"text-align:left;\"> (0.083) </td>\n",
       "   <td style=\"text-align:left;\"> (0.039) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">reg16</span> </td>\n",
       "   <td style=\"text-align:left;\"> 1.756 </td>\n",
       "   <td style=\"text-align:left;\"> 5.457 </td>\n",
       "   <td style=\"text-align:left;\"> 0 </td>\n",
       "   <td style=\"text-align:left;\"> 1.755 </td>\n",
       "   <td style=\"text-align:left;\"> 4.262 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.12) </td>\n",
       "   <td style=\"text-align:left;\"> (0.039) </td>\n",
       "   <td style=\"text-align:left;\"> (0.134) </td>\n",
       "   <td style=\"text-align:left;\"> (0.117) </td>\n",
       "   <td style=\"text-align:left;\"> (0.054) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">mobile16</span> </td>\n",
       "   <td style=\"text-align:left;\"> 2.045 </td>\n",
       "   <td style=\"text-align:left;\"> 1.846 </td>\n",
       "   <td style=\"text-align:left;\"> 3 </td>\n",
       "   <td style=\"text-align:left;\"> 1.869 </td>\n",
       "   <td style=\"text-align:left;\"> 2.008 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.047) </td>\n",
       "   <td style=\"text-align:left;\"> (0.015) </td>\n",
       "   <td style=\"text-align:left;\"> (0.052) </td>\n",
       "   <td style=\"text-align:left;\"> (0.045) </td>\n",
       "   <td style=\"text-align:left;\"> (0.021) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">family16</span> </td>\n",
       "   <td style=\"text-align:left;\"> 1.531 </td>\n",
       "   <td style=\"text-align:left;\"> 1.838 </td>\n",
       "   <td style=\"text-align:left;\"> 1.734 </td>\n",
       "   <td style=\"text-align:left;\"> 2.067 </td>\n",
       "   <td style=\"text-align:left;\"> 1.856 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.095) </td>\n",
       "   <td style=\"text-align:left;\"> (0.031) </td>\n",
       "   <td style=\"text-align:left;\"> (0.106) </td>\n",
       "   <td style=\"text-align:left;\"> (0.093) </td>\n",
       "   <td style=\"text-align:left;\"> (0.043) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">parborn</span> </td>\n",
       "   <td style=\"text-align:left;\"> 0.624 </td>\n",
       "   <td style=\"text-align:left;\"> 0.355 </td>\n",
       "   <td style=\"text-align:left;\"> 7.101 </td>\n",
       "   <td style=\"text-align:left;\"> 0.804 </td>\n",
       "   <td style=\"text-align:left;\"> 1.024 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.113) </td>\n",
       "   <td style=\"text-align:left;\"> (0.037) </td>\n",
       "   <td style=\"text-align:left;\"> (0.127) </td>\n",
       "   <td style=\"text-align:left;\"> (0.11) </td>\n",
       "   <td style=\"text-align:left;\"> (0.051) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">maeduc</span> </td>\n",
       "   <td style=\"text-align:left;\"> 12.11 </td>\n",
       "   <td style=\"text-align:left;\"> 11.68 </td>\n",
       "   <td style=\"text-align:left;\"> 8.98 </td>\n",
       "   <td style=\"text-align:left;\"> 11.59 </td>\n",
       "   <td style=\"text-align:left;\"> 12.09 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.19) </td>\n",
       "   <td style=\"text-align:left;\"> (0.062) </td>\n",
       "   <td style=\"text-align:left;\"> (0.212) </td>\n",
       "   <td style=\"text-align:left;\"> (0.185) </td>\n",
       "   <td style=\"text-align:left;\"> (0.086) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">degree</span> </td>\n",
       "   <td style=\"text-align:left;\"> 2.051 </td>\n",
       "   <td style=\"text-align:left;\"> 1.629 </td>\n",
       "   <td style=\"text-align:left;\"> 1.944 </td>\n",
       "   <td style=\"text-align:left;\"> 1.596 </td>\n",
       "   <td style=\"text-align:left;\"> 1.978 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.066) </td>\n",
       "   <td style=\"text-align:left;\"> (0.022) </td>\n",
       "   <td style=\"text-align:left;\"> (0.074) </td>\n",
       "   <td style=\"text-align:left;\"> (0.064) </td>\n",
       "   <td style=\"text-align:left;\"> (0.03) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">sex</span> </td>\n",
       "   <td style=\"text-align:left;\"> 1.431 </td>\n",
       "   <td style=\"text-align:left;\"> 1.476 </td>\n",
       "   <td style=\"text-align:left;\"> 1.496 </td>\n",
       "   <td style=\"text-align:left;\"> 1.544 </td>\n",
       "   <td style=\"text-align:left;\"> 1.544 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.028) </td>\n",
       "   <td style=\"text-align:left;\"> (0.009) </td>\n",
       "   <td style=\"text-align:left;\"> (0.032) </td>\n",
       "   <td style=\"text-align:left;\"> (0.028) </td>\n",
       "   <td style=\"text-align:left;\"> (0.013) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">race</span> </td>\n",
       "   <td style=\"text-align:left;\"> 1.055 </td>\n",
       "   <td style=\"text-align:left;\"> 1.202 </td>\n",
       "   <td style=\"text-align:left;\"> 1.948 </td>\n",
       "   <td style=\"text-align:left;\"> 1.208 </td>\n",
       "   <td style=\"text-align:left;\"> 1.289 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.031) </td>\n",
       "   <td style=\"text-align:left;\"> (0.01) </td>\n",
       "   <td style=\"text-align:left;\"> (0.035) </td>\n",
       "   <td style=\"text-align:left;\"> (0.03) </td>\n",
       "   <td style=\"text-align:left;\"> (0.014) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">born</span> </td>\n",
       "   <td style=\"text-align:left;\"> 1.032 </td>\n",
       "   <td style=\"text-align:left;\"> 1.028 </td>\n",
       "   <td style=\"text-align:left;\"> 1.919 </td>\n",
       "   <td style=\"text-align:left;\"> 1.034 </td>\n",
       "   <td style=\"text-align:left;\"> 1.104 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.013) </td>\n",
       "   <td style=\"text-align:left;\"> (0.004) </td>\n",
       "   <td style=\"text-align:left;\"> (0.014) </td>\n",
       "   <td style=\"text-align:left;\"> (0.012) </td>\n",
       "   <td style=\"text-align:left;\"> (0.006) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">hompop</span> </td>\n",
       "   <td style=\"text-align:left;\"> 2.797 </td>\n",
       "   <td style=\"text-align:left;\"> 2.696 </td>\n",
       "   <td style=\"text-align:left;\"> 3.093 </td>\n",
       "   <td style=\"text-align:left;\"> 2.746 </td>\n",
       "   <td style=\"text-align:left;\"> 2.483 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.08) </td>\n",
       "   <td style=\"text-align:left;\"> (0.026) </td>\n",
       "   <td style=\"text-align:left;\"> (0.089) </td>\n",
       "   <td style=\"text-align:left;\"> (0.078) </td>\n",
       "   <td style=\"text-align:left;\"> (0.036) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">babies</span> </td>\n",
       "   <td style=\"text-align:left;\"> 0.235 </td>\n",
       "   <td style=\"text-align:left;\"> 0.238 </td>\n",
       "   <td style=\"text-align:left;\"> 0.294 </td>\n",
       "   <td style=\"text-align:left;\"> 0.254 </td>\n",
       "   <td style=\"text-align:left;\"> 0.2 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.031) </td>\n",
       "   <td style=\"text-align:left;\"> (0.01) </td>\n",
       "   <td style=\"text-align:left;\"> (0.035) </td>\n",
       "   <td style=\"text-align:left;\"> (0.031) </td>\n",
       "   <td style=\"text-align:left;\"> (0.014) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">preteen</span> </td>\n",
       "   <td style=\"text-align:left;\"> 0.354 </td>\n",
       "   <td style=\"text-align:left;\"> 0.327 </td>\n",
       "   <td style=\"text-align:left;\"> 0.335 </td>\n",
       "   <td style=\"text-align:left;\"> 0.37 </td>\n",
       "   <td style=\"text-align:left;\"> 0.256 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.038) </td>\n",
       "   <td style=\"text-align:left;\"> (0.012) </td>\n",
       "   <td style=\"text-align:left;\"> (0.042) </td>\n",
       "   <td style=\"text-align:left;\"> (0.037) </td>\n",
       "   <td style=\"text-align:left;\"> (0.017) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">teens</span> </td>\n",
       "   <td style=\"text-align:left;\"> 0.264 </td>\n",
       "   <td style=\"text-align:left;\"> 0.228 </td>\n",
       "   <td style=\"text-align:left;\"> 0.25 </td>\n",
       "   <td style=\"text-align:left;\"> 0.22 </td>\n",
       "   <td style=\"text-align:left;\"> 0.168 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.029) </td>\n",
       "   <td style=\"text-align:left;\"> (0.01) </td>\n",
       "   <td style=\"text-align:left;\"> (0.033) </td>\n",
       "   <td style=\"text-align:left;\"> (0.029) </td>\n",
       "   <td style=\"text-align:left;\"> (0.013) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">adults</span> </td>\n",
       "   <td style=\"text-align:left;\"> 1.932 </td>\n",
       "   <td style=\"text-align:left;\"> 1.898 </td>\n",
       "   <td style=\"text-align:left;\"> 2.206 </td>\n",
       "   <td style=\"text-align:left;\"> 1.902 </td>\n",
       "   <td style=\"text-align:left;\"> 1.855 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.045) </td>\n",
       "   <td style=\"text-align:left;\"> (0.015) </td>\n",
       "   <td style=\"text-align:left;\"> (0.05) </td>\n",
       "   <td style=\"text-align:left;\"> (0.044) </td>\n",
       "   <td style=\"text-align:left;\"> (0.02) </td>\n",
       "  </tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Little trick to display the standard errors\n",
    "table <- lapply(seq_along(covariate_names), function(j) {\n",
    "  m <- round(signif(cov_table[[j]], digits=4), 3)\n",
    "  m[\"Estimate\",] <- as.character(m[\"Estimate\",])\n",
    "  m[\"Std. Error\",] <- paste0(\"(\", m[\"Std. Error\",], \")\")\n",
    "  m\n",
    "})\n",
    "table <- do.call(rbind, table)\n",
    "\n",
    "# Covariate names\n",
    "covnames <- rep(\"\", nrow(table))\n",
    "covnames[seq(1, length(covnames), 2)] <-\n",
    "  cell_spec(covariate_names, format = \"html\", escape = F, color = \"black\", bold = T)\n",
    "\n",
    "table <- cbind(covariates=covnames, table)\n",
    "\n",
    "# Title of table\n",
    "caption <- \"Average covariate values in each leaf\"\n",
    "\n",
    "table %>%\n",
    "  kable(format=\"html\", digits=2, caption=caption, escape = FALSE, row.names = FALSE) %>%\n",
    "  kable_styling(bootstrap_options=c(\"condensed\", \"responsive\"), full_width=FALSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also estimate the following normalized measure of variation across leaves. A higher number indicates that there is higher variation in across leaf averages.\n",
    "\n",
    "$$\n",
    "\\frac{Var \\left( E[X_{i} | L_{i}] \\right)}{Var(X_{i})}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a factor column turns all columns into character\n",
    "df_est <- as.data.frame(apply(df_est, 2, as.numeric))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariate_means_per_leaf <- aggregate(. ~ leaf, df_est, mean)[,covariate_names]\n",
    "covariate_means <- apply(df_est, 2, mean)[covariate_names]\n",
    "leaf_weights <- table(df_est$leaf) / dim(df_est)[1] \n",
    "deviations <- t(apply(covariate_means_per_leaf, 1, function(x) x - covariate_means))\n",
    "covariate_means_weighted_var <- apply(deviations, 2, function(x) sum(leaf_weights * x^2))\n",
    "covariate_var <- apply(df_est, 2, var)[covariate_names]\n",
    "cov_variation <- covariate_means_weighted_var / covariate_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table class=\"table table-striped table-hover table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n",
       "<caption>Covariate variation across leaves</caption>\n",
       "<tbody>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> polviews </td>\n",
       "   <td style=\"text-align:right;\"> 0.6277 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> born </td>\n",
       "   <td style=\"text-align:right;\"> 0.4149 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> reg16 </td>\n",
       "   <td style=\"text-align:right;\"> 0.3468 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> parborn </td>\n",
       "   <td style=\"text-align:right;\"> 0.3316 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> partyid </td>\n",
       "   <td style=\"text-align:right;\"> 0.1868 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> race </td>\n",
       "   <td style=\"text-align:right;\"> 0.0828 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> race.1 </td>\n",
       "   <td style=\"text-align:right;\"> 0.0828 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> mobile16 </td>\n",
       "   <td style=\"text-align:right;\"> 0.0812 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> maeduc </td>\n",
       "   <td style=\"text-align:right;\"> 0.0348 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> degree </td>\n",
       "   <td style=\"text-align:right;\"> 0.0224 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> marital </td>\n",
       "   <td style=\"text-align:right;\"> 0.0217 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> sibs </td>\n",
       "   <td style=\"text-align:right;\"> 0.0216 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> educ </td>\n",
       "   <td style=\"text-align:right;\"> 0.0208 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> res16 </td>\n",
       "   <td style=\"text-align:right;\"> 0.0170 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> childs </td>\n",
       "   <td style=\"text-align:right;\"> 0.0139 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> hompop </td>\n",
       "   <td style=\"text-align:right;\"> 0.0100 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> adults </td>\n",
       "   <td style=\"text-align:right;\"> 0.0079 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> prestg80 </td>\n",
       "   <td style=\"text-align:right;\"> 0.0079 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> occ80 </td>\n",
       "   <td style=\"text-align:right;\"> 0.0058 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> sex </td>\n",
       "   <td style=\"text-align:right;\"> 0.0051 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> age </td>\n",
       "   <td style=\"text-align:right;\"> 0.0036 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> teens </td>\n",
       "   <td style=\"text-align:right;\"> 0.0034 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> family16 </td>\n",
       "   <td style=\"text-align:right;\"> 0.0033 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> indus80 </td>\n",
       "   <td style=\"text-align:right;\"> 0.0031 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> earnrs </td>\n",
       "   <td style=\"text-align:right;\"> 0.0031 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> preteen </td>\n",
       "   <td style=\"text-align:right;\"> 0.0030 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> income </td>\n",
       "   <td style=\"text-align:right;\"> 0.0025 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> rincome </td>\n",
       "   <td style=\"text-align:right;\"> 0.0021 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> babies </td>\n",
       "   <td style=\"text-align:right;\"> 0.0017 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> wrkslf </td>\n",
       "   <td style=\"text-align:right;\"> 0.0012 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> wrkslf.1 </td>\n",
       "   <td style=\"text-align:right;\"> 0.0012 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> hrs1 </td>\n",
       "   <td style=\"text-align:right;\"> 0.0012 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> wrkstat </td>\n",
       "   <td style=\"text-align:right;\"> 0.0011 </td>\n",
       "  </tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "sorted_cov_variation <- sort(cov_variation, decreasing = TRUE)\n",
    "table <- as.data.frame(sorted_cov_variation)\n",
    "colnames(table) <- NULL\n",
    "\n",
    "kable_styling(kable(table,  \"html\", digits = 4, row.names=TRUE,\n",
    "                    caption=\"Covariate variation across leaves\"),\n",
    "              bootstrap_options=c(\"striped\", \"hover\", \"condensed\", \"responsive\"),\n",
    "              full_width=FALSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "\n",
    "\n",
    "## HTE 2: Causal Forests and the R-Learner\n",
    "\n",
    "**Reference:** [Athey, Tibshrani and Wager (Annals of Statistics, 2019)](https://projecteuclid.org/download/pdfview_1/euclid.aos/1547197251)\n",
    ", [Nie and Wager,  2017](https://arxiv.org/abs/1712.04912)\n",
    "\n",
    "*Generalized random forests* are a flexible, computationally efficient adaptive method for estimating parameters that can be defined by local moment conditions. One important example of such parameters is the conditional average treatment effect (CATE). The specific application of this algorithm to estimate CATE is what the authors call *causal forests*.\n",
    "\n",
    "The paper makes two important points. First, it casts forests as a type of locally weighted estimator, meaning that when estimating the treatment effect at a target value $X_{i} = x$, we will give more weight to \"close\" observations in the data during estimates. This makes the algorithm akin to kernel-based estimations such as $k$-nearest neighbors. The novelty comes in replacing the kernel weighting function with *forest-based weights* in which a observation is said to be \"close\" to the point $x$ if it often falls in the same leaf as the target value across the trees in the forest.\n",
    "\n",
    "The benefit of using forest-based weighting is that it is more effective in choosing which dimensions are important in determining closeness. Meanwhile, in methods like $k$-nearest neighbors every dimension is given equal importance. This becomes crucial for mitigating the **curse of dimensionality** in high-dimensional cases, since if much of the variation in treatment effects is found among only a few dimensions, $k$-nn will do a poor job at giving more weight to important observations.\n",
    "\n",
    "The second point made in the paper is that, if each individual tree in the forest is estimated using **honesty**, then (under some more subtle assumptions regarding the size of the subsample used to grow each tree) causal forest estimates will be unbiased and have valid confidence intervals.\n",
    "\n",
    "Causal forest as implemented by the `grf` package can be seen as a forest-based method motivated by the R-learner. First, we describe the R-Learner in its general form. Let\n",
    "\n",
    "$$e(x) = P[W=1| X=x] \\qquad \\text{and} \\qquad m(x) = E[Y|X=x]$$\n",
    "\n",
    "Then the R-learner consists of the following two steps:\n",
    "\n",
    "1. Use any method to estimate separate response functions $\\hat{e}(x)$ and $\\hat{m}(x)$.\n",
    "\n",
    "2. Minimize the squared loss motivated by Robinson (1988) using cross-fitting for the nuisance components $\\hat{e}(x)$ and $\\hat{m}(x)$,\n",
    "\n",
    "$$\\hat{\\tau}(\\cdot) = argmin_\\tau \\sum_{i = 1}^n ((Y_i - \\hat{m}^{(-i)}(X_i)) - \\tau(X_i)(W_i - \\hat{e}^{(-i)}(X_i)))^2 + \\Lambda_n(\\tau(\\cdot))$$\n",
    "where $\\Lambda_n$ is some regularizer. We call the above the R-loss in recognition of Robinson and the role of residualization in the loss function.\n",
    "\n",
    "Robinson (1988) shows that when $\\tau(x) = \\tau$ is constant, running OLS to minimize the above loss achieves semiparametric efficiency when $\\hat{e}$ and $\\hat{m}$ are estimated at the 4-th root rate. Nie and Wager (2017) extends this result to nonparametric $\\tau(\\cdot)$ to estimate heterogeneous treatment effects. In general, we can plug in any black-box supervised learning software for learning both of the nuisance components and minimizing the R-loss above.\n",
    "\n",
    "Before we move on to explain how the R-learner is used in Causal Forests as in the implementation of `grf`, we would like to point out that the R-loss defined above can also be used for cross-validation and stacking given different off-the-shelf HTE estimators. For example, you could first compute an HTE estimate from a Causal Forest, and another HTE estimate from BART (Bayesian Additive Regression Trees; see [Hill 2011](https://www.tandfonline.com/doi/pdf/10.1198/jcgs.2010.08162), and the `BART` package is also available on CRAN), which is another popular method widely used in the community, and then stack the two estimates to form a new estimate that combines the two. Details see Section 2.2 in [Nie and Wager (2017)](https://arxiv.org/pdf/1712.04912.pdf).\n",
    "\n",
    "Causal forest as implemented by `grf` is motivated by the R-learner.\n",
    "Concretely, the `grf` implementation of causal forests starts by fitting two separate regression\n",
    "forests to estimate $\\hat{m}(\\cdot)$ and $\\hat{e}(\\cdot)$. It then makes out-of-bag\n",
    "predictions -- meaning that predictions are average outputs from trees whose training data did *not* include the $i^{th}$ observation -- using these two first-stage forests, and uses them to grow a causal forest via\n",
    "\n",
    "$$\n",
    "\\hat{\\tau}(x) = \\frac{\\sum_{i = 1}^n \\alpha_i(x) \\left(Y_i - \\hat{m}^{(-i)}(X_i) \\right)\\left(W_i - \\hat{e}^{(-i)}(X_i) \\right)}{\\sum_{i = 1}^n \\alpha_i(x) \\left(W_i - \\hat{e}^{(-i)}(X_i)\\right)^2}\n",
    "$$\n",
    "\n",
    "where $\\alpha_i(x) =  \\frac{1}{B} \\sum_{b = 1}^B  \\frac{1(\\{X_i \\in L_b(x), \\, i \\in B\\})}{|\\{i : X_i \\in L_b(x), \\, i \\in B\\}|}$ is the learned adaptive weights using random forests, with $B$ the total number of trees in the forest, $L_b(x)$ is the leaf where $x$ falls into in tree $b$.\n",
    "Causal forests have several tuning parameters (e.g., minimum node size for individual trees), and\n",
    "`grf` choose those tuning parameters by cross-validation on the R-loss, i.e., we train causal forests with different values of the tuning parameters, and choose the ones that make out-of-bag estimates of the objective minimized in R-loss as small as possible.\n",
    "\n",
    "\n",
    "#### Step 1: Fit the forest\n",
    "\n",
    "Use the command `causal_forest` from the `grf` package to fit the forest. The default parameters tend to provide reasonable performance, but the user can select several tuning parameters for more accuracy. For more information, please check out this extended [reference](https://github.com/grf-labs/grf/blob/master/REFERENCE.md) for the grf algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf <- causal_forest(\n",
    "  X = as.matrix(df_train[,covariate_names]),\n",
    "  Y = df_train$Y,\n",
    "  W = df_train$W,\n",
    "  num.trees=200) # This is just for speed. In a real application, remember increase this number!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Step 2(a): Predict point estimates and standard errors (training set, out-of-bag)\n",
    "\n",
    "To predict on the training set, follow the code below. Note that we are not passing the training set again -- this signals to the causal forest that we should be use out-of-bag predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "oob_pred <- predict(cf, estimate.variance=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first few rows of the output look like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table class=\"table table-striped table-hover table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n",
       " <thead>\n",
       "  <tr>\n",
       "   <th style=\"text-align:right;\"> predictions </th>\n",
       "   <th style=\"text-align:right;\"> variance.estimates </th>\n",
       "   <th style=\"text-align:right;\"> debiased.error </th>\n",
       "   <th style=\"text-align:right;\"> excess.error </th>\n",
       "  </tr>\n",
       " </thead>\n",
       "<tbody>\n",
       "  <tr>\n",
       "   <td style=\"text-align:right;\"> -0.4224 </td>\n",
       "   <td style=\"text-align:right;\"> 0.0024 </td>\n",
       "   <td style=\"text-align:right;\"> 0.2473 </td>\n",
       "   <td style=\"text-align:right;\"> 3e-04 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:right;\"> -0.3267 </td>\n",
       "   <td style=\"text-align:right;\"> 0.0092 </td>\n",
       "   <td style=\"text-align:right;\"> 0.1683 </td>\n",
       "   <td style=\"text-align:right;\"> 4e-04 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:right;\"> -0.3400 </td>\n",
       "   <td style=\"text-align:right;\"> 0.0086 </td>\n",
       "   <td style=\"text-align:right;\"> 0.3918 </td>\n",
       "   <td style=\"text-align:right;\"> 3e-04 </td>\n",
       "  </tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kable_styling(kable(head(oob_pred, 3), \"html\", digits = 4),\n",
    "              bootstrap_options=c(\"striped\", \"hover\", \"condensed\", \"responsive\"),\n",
    "              full_width=FALSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column `predictions` and `variance.estimates` contains estimates of the CATE and its variance for each observation. In addition, when using out-of-bag predictions, the column `debiased.error` contains estimates of what the error on the CATE predictions. The word *debiased* here indicates that the error is only due to sample variability in the data, and the variability due to randomness in the construction of the random forest has been removed. In other words, `debiased.error` represents the error we should expect if we grew a forest containing an infinite number of trees.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "oob_tauhat_cf <- oob_pred$predictions\n",
    "oob_tauhat_cf_se <- sqrt(oob_pred$variance.estimates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2(b): Predict point estimates and standard errors (test set)\n",
    "\n",
    "To predict on a test set, pass it using the `newdata` argument.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred <- predict(cf, newdata=as.matrix(df_test[covariate_names]), estimate.variance=TRUE)\n",
    "tauhat_cf_test <- test_pred$predictions\n",
    "tauhat_cf_test_se <- sqrt(test_pred$variance.estimates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, `test_pred` will not contain `debiased.error`, since we are not using out-of-bag estimates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table class=\"table table-striped table-hover table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n",
       " <thead>\n",
       "  <tr>\n",
       "   <th style=\"text-align:right;\"> predictions </th>\n",
       "   <th style=\"text-align:right;\"> variance.estimates </th>\n",
       "  </tr>\n",
       " </thead>\n",
       "<tbody>\n",
       "  <tr>\n",
       "   <td style=\"text-align:right;\"> -0.2854 </td>\n",
       "   <td style=\"text-align:right;\"> 0.0018 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:right;\"> -0.3781 </td>\n",
       "   <td style=\"text-align:right;\"> 0.0024 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:right;\"> -0.3385 </td>\n",
       "   <td style=\"text-align:right;\"> 0.0020 </td>\n",
       "  </tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kable_styling(kable(head(test_pred, 3), \"html\", digits = 4),\n",
    "                          bootstrap_options=c(\"striped\", \"hover\", \"condensed\", \"responsive\"),\n",
    "                          full_width=FALSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Note:** In experiments where we have additional information about the outcome model $E[Y|X]$ or the assignment model $E[W|X]$, we can pass them directly to the algorithm. For example, if we knew that the propensity score were constant and approximately equal to $\\bar{W}$, we could fit the forest as follows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_known_prop <- grf::causal_forest(\n",
    "  X = as.matrix(df_train[covariate_names]),\n",
    "  Y = df_train$Y,\n",
    "  W = df_train$W,\n",
    "  W.hat = rep(mean(df_train$W), times=nrow(df_train)))  # Passing the known (approximate) propensity score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can similarly pass our own estimates of the outcome model using the argument `Y.hat`.\n",
    "\n",
    "\n",
    "### Assessing heterogeneity\n",
    "\n",
    "A good reference for this kind of analysis is [Athey and Wager (ArXiv, 2019)](https://arxiv.org/pdf/1902.07409.pdf)\n",
    "\n",
    "Assessing systematic variation in treatment effect heterogeneity is a difficult task. Let's begin by looking at some popular measures and see how they may lead to subtle pitfalls.\n",
    "\n",
    "First, having fit a causal forest, a researcher may like to start by looking at the distribution of its predictions. We should the histogram of (out-of-bag) CATE estimates for the `r dataset_name` dataset below. However, the histogram is not recommended as a definitive way to assess heterogeneity. One might be tempted to think: \"if the histogram is concentrated at a point, then there is no heterogeneity; if the histogram is spread out, then our estimator has found interesting heterogeneity\". In fact, both of these assertions may be false! Indeed, if the histogram is concentrated at a point, then the forests were not able to _detect_ any heterogeneity, but it may be that we are simply underpowered. On the other hand, if the histogram is spread out, it may be that the forests are simply overfitting and producing very noisy estimates. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAM1BMVEUAAABNTU1oaGh8fHyM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\nBRAJQIH/AQgZJsINf7pzAAAAAElFTkSuQmCC",
      "text/plain": [
       "Plot with title \"Causal forests: out-of-bag CATE\""
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist(oob_tauhat_cf, main=\"Causal forests: out-of-bag CATE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the `grf` package also produces a measure of variable importance that indicates how often a variable was used in a tree split.  Again, much like the histogram aboove, this can be a rough diagnostic, but it should **not** be interpreted as indicating that, for example, variable with low importance is not related to heterogeneity.  The reasoning is the same as the one presented in the causal trees section: if two covariates are highly correlated, the trees might split on one covariate but not the other.  However, if one was removed, the trees might split on the one remaining, and the leaf definitions might be unchanged.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_imp <- c(variable_importance(cf))\n",
    "names(var_imp) <- covariate_names\n",
    "sorted_var_imp <- sort(var_imp, decreasing=TRUE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in data.row.names(row.names, rowsi, i):\n",
      "\"some row.names duplicated: 19,31 --> row.names NOT used\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<table class=\"table table-striped table-hover table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n",
       " <thead>\n",
       "  <tr>\n",
       "   <th style=\"text-align:left;\">   </th>\n",
       "   <th style=\"text-align:right;\"> sorted_var_imp </th>\n",
       "  </tr>\n",
       " </thead>\n",
       "<tbody>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> polviews </td>\n",
       "   <td style=\"text-align:right;\"> 0.3992 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> partyid </td>\n",
       "   <td style=\"text-align:right;\"> 0.0957 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> educ </td>\n",
       "   <td style=\"text-align:right;\"> 0.0755 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> hrs1 </td>\n",
       "   <td style=\"text-align:right;\"> 0.0667 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> indus80 </td>\n",
       "   <td style=\"text-align:right;\"> 0.0610 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> degree </td>\n",
       "   <td style=\"text-align:right;\"> 0.0493 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> maeduc </td>\n",
       "   <td style=\"text-align:right;\"> 0.0358 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> marital </td>\n",
       "   <td style=\"text-align:right;\"> 0.0275 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> prestg80 </td>\n",
       "   <td style=\"text-align:right;\"> 0.0223 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> rincome </td>\n",
       "   <td style=\"text-align:right;\"> 0.0221 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> occ80 </td>\n",
       "   <td style=\"text-align:right;\"> 0.0219 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> family16 </td>\n",
       "   <td style=\"text-align:right;\"> 0.0182 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> age </td>\n",
       "   <td style=\"text-align:right;\"> 0.0163 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> reg16 </td>\n",
       "   <td style=\"text-align:right;\"> 0.0161 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> income </td>\n",
       "   <td style=\"text-align:right;\"> 0.0151 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> sibs </td>\n",
       "   <td style=\"text-align:right;\"> 0.0077 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> race </td>\n",
       "   <td style=\"text-align:right;\"> 0.0075 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> res16 </td>\n",
       "   <td style=\"text-align:right;\"> 0.0072 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> race </td>\n",
       "   <td style=\"text-align:right;\"> 0.0053 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> wrkstat </td>\n",
       "   <td style=\"text-align:right;\"> 0.0045 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> hompop </td>\n",
       "   <td style=\"text-align:right;\"> 0.0037 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> sex </td>\n",
       "   <td style=\"text-align:right;\"> 0.0037 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> childs </td>\n",
       "   <td style=\"text-align:right;\"> 0.0034 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> earnrs </td>\n",
       "   <td style=\"text-align:right;\"> 0.0032 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> adults </td>\n",
       "   <td style=\"text-align:right;\"> 0.0025 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> parborn </td>\n",
       "   <td style=\"text-align:right;\"> 0.0016 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> mobile16 </td>\n",
       "   <td style=\"text-align:right;\"> 0.0014 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> born </td>\n",
       "   <td style=\"text-align:right;\"> 0.0013 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> teens </td>\n",
       "   <td style=\"text-align:right;\"> 0.0011 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> wrkslf </td>\n",
       "   <td style=\"text-align:right;\"> 0.0009 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> wrkslf </td>\n",
       "   <td style=\"text-align:right;\"> 0.0009 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> preteen </td>\n",
       "   <td style=\"text-align:right;\"> 0.0008 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> babies </td>\n",
       "   <td style=\"text-align:right;\"> 0.0005 </td>\n",
       "  </tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "as.data.frame(sorted_var_imp, row.names = names(sorted_var_imp)) %>%\n",
    "  kable(\"html\", digits = 4, row.names = T) %>%\n",
    "  kable_styling(bootstrap_options=c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width=FALSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we discuss some preferred ways to assess and test hypotheses about heterogeneity.\n",
    "\n",
    "#### Heterogeneity across subgroups\n",
    "\n",
    "One way to summarize the output of complex algorithms like causal forests is to create subpopulations based on predicted treatment effect strength. Here, we split the training data into groups based on n-tiles of the predicted treatment effect.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually creating subgroups\n",
    "num_tiles <- 4  # ntiles = CATE is above / below the median\n",
    "df_train$cate <- oob_tauhat_cf\n",
    "df_train$ntile <- factor(ntile(oob_tauhat_cf, n=num_tiles))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##### Average treatment effects within subgroups\n",
    "\n",
    "Next, we compute the average treatment effect within each subgroup. We will show two ways of doing this. First, by taking the average difference between \"raw\" outcomes for treated and control groups. Then, by constructing and average doubly robust scores for the treatment effect.\n",
    "\n",
    "A note of caution: in randomized control trials, both of these methods will yield unbiased estimates of the group-specific treatment effect. However, when dealing with *observational* data, only the second method is guaranteed to produce unbiased and efficient estimates.\n",
    "\n",
    "**Sample Average Treatment Effect:** Define $I_{q}$ to be the set of observations whose predicted treatment effect is in the $q^{th}$ n-tile. Then this estimator is simply a difference of the average outcome for treated and control observations within the subgroup.\n",
    "\n",
    "$$\\frac{1}{|I_{1,q}|}\\sum_{i \\in I_{1,q}} Y_{i} - \\frac{1}{|I_{0,q}|}\\sum_{i \\in I_{0,q}} Y_{i} \\qquad \\quad I_{w,q} := \\{i \\ |\\  i \\in W_{i}, \\ i \\in I_{q} \\}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_sample_ate <- lm(\"Y ~ ntile + ntile:W\", data=df_train)\n",
    "estimated_sample_ate <- coef(summary(ols_sample_ate))[(num_tiles+1):(2*num_tiles), c(\"Estimate\", \"Std. Error\")]\n",
    "hypothesis_sample_ate <- paste0(\"ntile1:W = \", paste0(\"ntile\", seq(2, num_tiles), \":W\"))\n",
    "ftest_pvalue_sample_ate <- linearHypothesis(ols_sample_ate, hypothesis_sample_ate)[2,\"Pr(>F)\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Augmented Inverse-Propensity Weighted (AIPW) Average Treatment Effect:** This is the recommended way to compute average treatment effects in observational data. It consists of averaging the doubly robust scores, where $\\hat{\\tau}^{-i}(X_i)$ and $\\hat{e}^{-i}(X_i)$ are out-of-bag estimates.\n",
    "\n",
    "$$\\frac{1}{|I_{q}|} \\sum_{i \\in I_{q}} \\hat{\\tau}^{-i}(X_{i}) + \\frac{W_{i} - \\hat{e}^{-i}(X_{i})}{\\hat{e}^{-i}(X_{i})\\left(1 - \\hat{e}^{-i}(X_{i})\\right)}\\left( Y_{i} - \\hat{\\mu}_{W_{i}}(X_{i}) \\right)$$\n",
    "\n",
    "The `grf` function `average_treatment_effect` computes the statistic above and its standard error. We can also test null hypothesis that the average CATE is the same across n-tiles using a Wald test via the function `wald.test` from the `aod` package.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_aipw_ate <- lapply(\n",
    "  seq(num_tiles), function(w) {\n",
    "  ate <- average_treatment_effect(cf, subset = df_train$ntile == w)\n",
    "})\n",
    "estimated_aipw_ate <- data.frame(do.call(rbind, estimated_aipw_ate))\n",
    "\n",
    "# Testing for equality using Wald test\n",
    "waldtest_pvalue_aipw_ate <- wald.test(Sigma = diag(estimated_aipw_ate$std.err^2),\n",
    "                                      b = estimated_aipw_ate$estimate,\n",
    "                                      Terms = 1:num_tiles)$result$chi2[3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For your convenience, we display the sample ATE and AIPW ATE estimates side-by-side below in both a table and graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table class=\"table table-striped table-hover table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;border-bottom: 0;\">\n",
       " <thead>\n",
       "  <tr>\n",
       "   <th style=\"text-align:left;\">   </th>\n",
       "   <th style=\"text-align:left;\"> Sample ATE </th>\n",
       "   <th style=\"text-align:left;\"> AIPW ATE </th>\n",
       "  </tr>\n",
       " </thead>\n",
       "<tbody>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">ntile1</span> </td>\n",
       "   <td style=\"text-align:left;\"> -0.443250748684868 </td>\n",
       "   <td style=\"text-align:left;\"> -0.427552302367286 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.0159) </td>\n",
       "   <td style=\"text-align:left;\"> (0.0174) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">ntile2</span> </td>\n",
       "   <td style=\"text-align:left;\"> -0.410835271513836 </td>\n",
       "   <td style=\"text-align:left;\"> -0.405058598535242 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.0159) </td>\n",
       "   <td style=\"text-align:left;\"> (0.0169) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">ntile3</span> </td>\n",
       "   <td style=\"text-align:left;\"> -0.37964095185338 </td>\n",
       "   <td style=\"text-align:left;\"> -0.366773750970117 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.0159) </td>\n",
       "   <td style=\"text-align:left;\"> (0.0164) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">ntile4</span> </td>\n",
       "   <td style=\"text-align:left;\"> -0.24485679152217 </td>\n",
       "   <td style=\"text-align:left;\"> -0.239529495267606 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.0159) </td>\n",
       "   <td style=\"text-align:left;\"> (0.0147) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">P-Value</span> </td>\n",
       "   <td style=\"text-align:left;\"> 0 </td>\n",
       "   <td style=\"text-align:left;\"> 0 </td>\n",
       "  </tr>\n",
       "</tbody>\n",
       "<tfoot>\n",
       "<tr><td style=\"padding: 0; \" colspan=\"100%\"><span style=\"font-style: italic;\">Note: </span></td></tr>\n",
       "<tr><td style=\"padding: 0; \" colspan=\"100%\">\n",
       "<sup></sup> Average treatment effects per subgroup defined by out-of-bag CATE.<br>\n",
       "           P-value is testing <i>H<sub>0</sub>: ATE is constant across ntiles</i>.<br>\n",
       "           Sample ATE uses an F-test and AIPW uses a Wald test;<br>\n",
       "           see the code above for more details.</td></tr>\n",
       "</tfoot>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Round the estimates and standard errors before displaying them\n",
    "estimated_sample_ate_rounded <- round(signif(estimated_sample_ate, digits = 5), 4)\n",
    "estimated_aipw_ate_rounded <- round(signif(estimated_aipw_ate, digits = 5), 4)\n",
    "\n",
    "# Format Table: Parenthesis, row/column names\n",
    "sample_ate_w_se <- c(rbind(estimated_sample_ate[,\"Estimate\"], paste0(\"(\", estimated_sample_ate_rounded[,\"Std. Error\"], \")\")))\n",
    "aipw_ate_w_se <- c(rbind(estimated_aipw_ate[,\"estimate\"], paste0(\"(\", estimated_aipw_ate_rounded[,\"std.err\"], \")\")))\n",
    "table <- cbind(\"Sample ATE\" = sample_ate_w_se, \"AIPW ATE\" = aipw_ate_w_se)\n",
    "table <- rbind(table, round(signif(c(ftest_pvalue_sample_ate, waldtest_pvalue_aipw_ate), digits = 5), 4)) # add p-value to table\n",
    "left_column <- rep('', nrow(table))\n",
    "left_column[seq(1, nrow(table), 2)] <-\n",
    "    cell_spec(c(paste0(\"ntile\", seq(num_tiles)), \"P-Value\"),\n",
    "              format = \"html\", escape = FALSE, color = \"black\", bold = TRUE)\n",
    "table <- cbind(\" \" = left_column, table)\n",
    "\n",
    "# Output table\n",
    "table %>%\n",
    "  kable(\"html\", escape = FALSE, row.names = FALSE) %>%\n",
    "  kable_styling(bootstrap_options=c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width=FALSE) %>%\n",
    "  footnote(general = \"Average treatment effects per subgroup defined by out-of-bag CATE.<br>\n",
    "           P-value is testing <i>H<sub>0</sub>: ATE is constant across ntiles</i>.<br>\n",
    "           Sample ATE uses an F-test and AIPW uses a Wald test;<br>\n",
    "           see the code above for more details.\",\n",
    "           escape=FALSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAAAAv8RNTU1oaGh8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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Transform to data tables with relevant columns\n",
    "estimated_sample_ate <- as.data.frame(estimated_sample_ate)\n",
    "estimated_sample_ate$Method <- \"Sample ATE\"\n",
    "estimated_sample_ate$Ntile <- as.numeric(sub(\".*([0-9]+).*\", \"\\\\1\", rownames(estimated_sample_ate)))\n",
    "\n",
    "estimated_aipw_ate <- as.data.frame(estimated_aipw_ate)\n",
    "estimated_aipw_ate$Method <- \"AIPW ATE\"\n",
    "estimated_aipw_ate$Ntile <- as.numeric(rownames(estimated_aipw_ate))\n",
    "\n",
    "# unify column names and combine\n",
    "colnames(estimated_sample_ate) <- c(\"Estimate\", \"SE\", \"Method\", \"Ntile\")\n",
    "colnames(estimated_aipw_ate) <- c(\"Estimate\", \"SE\", \"Method\", \"Ntile\")\n",
    "combined_ate_estimates <- rbind(estimated_sample_ate, estimated_aipw_ate)\n",
    "\n",
    "# plot\n",
    "ggplot(combined_ate_estimates) +\n",
    "  geom_pointrange(aes(x = Ntile, y = Estimate, ymax = Estimate + 1.96 * SE, ymin = Estimate - 1.96 * SE, color = Method), \n",
    "                  size = 0.5,\n",
    "                  position = position_dodge(width = .5)) +\n",
    "  geom_errorbar(aes(x = Ntile, ymax = Estimate + 1.96 * SE, ymin = Estimate - 1.96 * SE, color = Method), \n",
    "                width = 0.4,\n",
    "                size = 0.75,\n",
    "                position = position_dodge(width = .5)) +\n",
    "  theme_linedraw() +\n",
    "  labs(x = \"N-tile\", y = \"ATE Estimate\", title = \"ATE within N-tiles (as defined by predicted CATE)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Note that the average estimates of the treatment effect that is obtained by averaging doubly-robust scores may not be monotonic. That is, the average estimate for group $I_{4}$ may end up being _smaller_ than the one for $I_{3}$. Asymptotically, these differences should disappear, but this is a common occurrence in small samples.\n",
    "\n",
    "\n",
    "\n",
    "#### Heterogeneity across covariates\n",
    "\n",
    "We can also check if different groups have different average covariate levels across n-tiles of estimated conditional treatment effects. The code here follows very closely what we did in the causal trees section.  Recalling the warning against using variable importance measures, it is possible that one covariate is not \"important\" in splitting, but yet it varies strongly with treatment effects.  The approach of comparing all covariates across n-tiles of treatment effects presents a fuller picture of how high-treatment-effect individuals differ fom low-treatment-effect individuals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regress each covariate on ntile assignment to means p\n",
    "cov_means <- lapply(covariate_names, function(covariate) {\n",
    "  lm(paste0(covariate, ' ~ 0 + ntile'), data = df_train)\n",
    "})\n",
    "\n",
    "# Extract the mean and standard deviation of each covariate per ntile\n",
    "cov_table <- lapply(cov_means, function(cov_mean) {\n",
    "  as.data.frame(t(coef(summary(cov_mean))[,c(\"Estimate\", \"Std. Error\")]))\n",
    "})\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table class=\"table table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n",
       "<caption>Average covariate values in each n-tile</caption>\n",
       " <thead>\n",
       "  <tr>\n",
       "   <th style=\"text-align:left;\"> covariates </th>\n",
       "   <th style=\"text-align:left;\"> ntile1 </th>\n",
       "   <th style=\"text-align:left;\"> ntile2 </th>\n",
       "   <th style=\"text-align:left;\"> ntile3 </th>\n",
       "   <th style=\"text-align:left;\"> ntile4 </th>\n",
       "  </tr>\n",
       " </thead>\n",
       "<tbody>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">hrs1</span> </td>\n",
       "   <td style=\"text-align:left;\"> 46.27 </td>\n",
       "   <td style=\"text-align:left;\"> 42.9 </td>\n",
       "   <td style=\"text-align:left;\"> 40.28 </td>\n",
       "   <td style=\"text-align:left;\"> 39.51 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.268) </td>\n",
       "   <td style=\"text-align:left;\"> (0.268) </td>\n",
       "   <td style=\"text-align:left;\"> (0.268) </td>\n",
       "   <td style=\"text-align:left;\"> (0.268) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">partyid</span> </td>\n",
       "   <td style=\"text-align:left;\"> 4.107 </td>\n",
       "   <td style=\"text-align:left;\"> 3.283 </td>\n",
       "   <td style=\"text-align:left;\"> 2.59 </td>\n",
       "   <td style=\"text-align:left;\"> 1.829 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.036) </td>\n",
       "   <td style=\"text-align:left;\"> (0.036) </td>\n",
       "   <td style=\"text-align:left;\"> (0.036) </td>\n",
       "   <td style=\"text-align:left;\"> (0.036) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">income</span> </td>\n",
       "   <td style=\"text-align:left;\"> 11.78 </td>\n",
       "   <td style=\"text-align:left;\"> 11.45 </td>\n",
       "   <td style=\"text-align:left;\"> 11.05 </td>\n",
       "   <td style=\"text-align:left;\"> 10.9 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.031) </td>\n",
       "   <td style=\"text-align:left;\"> (0.031) </td>\n",
       "   <td style=\"text-align:left;\"> (0.031) </td>\n",
       "   <td style=\"text-align:left;\"> (0.031) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">rincome</span> </td>\n",
       "   <td style=\"text-align:left;\"> 10.8 </td>\n",
       "   <td style=\"text-align:left;\"> 10.34 </td>\n",
       "   <td style=\"text-align:left;\"> 9.86 </td>\n",
       "   <td style=\"text-align:left;\"> 9.816 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.053) </td>\n",
       "   <td style=\"text-align:left;\"> (0.053) </td>\n",
       "   <td style=\"text-align:left;\"> (0.053) </td>\n",
       "   <td style=\"text-align:left;\"> (0.053) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">wrkstat</span> </td>\n",
       "   <td style=\"text-align:left;\"> 1.094 </td>\n",
       "   <td style=\"text-align:left;\"> 1.131 </td>\n",
       "   <td style=\"text-align:left;\"> 1.18 </td>\n",
       "   <td style=\"text-align:left;\"> 1.228 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.007) </td>\n",
       "   <td style=\"text-align:left;\"> (0.007) </td>\n",
       "   <td style=\"text-align:left;\"> (0.007) </td>\n",
       "   <td style=\"text-align:left;\"> (0.007) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">wrkslf</span> </td>\n",
       "   <td style=\"text-align:left;\"> 1.841 </td>\n",
       "   <td style=\"text-align:left;\"> 1.866 </td>\n",
       "   <td style=\"text-align:left;\"> 1.899 </td>\n",
       "   <td style=\"text-align:left;\"> 1.888 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.006) </td>\n",
       "   <td style=\"text-align:left;\"> (0.006) </td>\n",
       "   <td style=\"text-align:left;\"> (0.006) </td>\n",
       "   <td style=\"text-align:left;\"> (0.006) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">age</span> </td>\n",
       "   <td style=\"text-align:left;\"> 41.89 </td>\n",
       "   <td style=\"text-align:left;\"> 42.14 </td>\n",
       "   <td style=\"text-align:left;\"> 39.77 </td>\n",
       "   <td style=\"text-align:left;\"> 38.63 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.235) </td>\n",
       "   <td style=\"text-align:left;\"> (0.235) </td>\n",
       "   <td style=\"text-align:left;\"> (0.235) </td>\n",
       "   <td style=\"text-align:left;\"> (0.235) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">polviews</span> </td>\n",
       "   <td style=\"text-align:left;\"> 5.013 </td>\n",
       "   <td style=\"text-align:left;\"> 4.63 </td>\n",
       "   <td style=\"text-align:left;\"> 3.917 </td>\n",
       "   <td style=\"text-align:left;\"> 2.752 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.021) </td>\n",
       "   <td style=\"text-align:left;\"> (0.021) </td>\n",
       "   <td style=\"text-align:left;\"> (0.021) </td>\n",
       "   <td style=\"text-align:left;\"> (0.021) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">educ</span> </td>\n",
       "   <td style=\"text-align:left;\"> 13.5 </td>\n",
       "   <td style=\"text-align:left;\"> 13.62 </td>\n",
       "   <td style=\"text-align:left;\"> 13.64 </td>\n",
       "   <td style=\"text-align:left;\"> 15.17 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.052) </td>\n",
       "   <td style=\"text-align:left;\"> (0.052) </td>\n",
       "   <td style=\"text-align:left;\"> (0.052) </td>\n",
       "   <td style=\"text-align:left;\"> (0.052) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">earnrs</span> </td>\n",
       "   <td style=\"text-align:left;\"> 1.89 </td>\n",
       "   <td style=\"text-align:left;\"> 1.788 </td>\n",
       "   <td style=\"text-align:left;\"> 1.687 </td>\n",
       "   <td style=\"text-align:left;\"> 1.607 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.016) </td>\n",
       "   <td style=\"text-align:left;\"> (0.016) </td>\n",
       "   <td style=\"text-align:left;\"> (0.016) </td>\n",
       "   <td style=\"text-align:left;\"> (0.016) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">race</span> </td>\n",
       "   <td style=\"text-align:left;\"> 1.059 </td>\n",
       "   <td style=\"text-align:left;\"> 1.209 </td>\n",
       "   <td style=\"text-align:left;\"> 1.372 </td>\n",
       "   <td style=\"text-align:left;\"> 1.367 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.011) </td>\n",
       "   <td style=\"text-align:left;\"> (0.011) </td>\n",
       "   <td style=\"text-align:left;\"> (0.011) </td>\n",
       "   <td style=\"text-align:left;\"> (0.011) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">wrkslf</span> </td>\n",
       "   <td style=\"text-align:left;\"> 1.841 </td>\n",
       "   <td style=\"text-align:left;\"> 1.866 </td>\n",
       "   <td style=\"text-align:left;\"> 1.899 </td>\n",
       "   <td style=\"text-align:left;\"> 1.888 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.006) </td>\n",
       "   <td style=\"text-align:left;\"> (0.006) </td>\n",
       "   <td style=\"text-align:left;\"> (0.006) </td>\n",
       "   <td style=\"text-align:left;\"> (0.006) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">marital</span> </td>\n",
       "   <td style=\"text-align:left;\"> 1.75 </td>\n",
       "   <td style=\"text-align:left;\"> 2.131 </td>\n",
       "   <td style=\"text-align:left;\"> 2.773 </td>\n",
       "   <td style=\"text-align:left;\"> 3.116 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.031) </td>\n",
       "   <td style=\"text-align:left;\"> (0.031) </td>\n",
       "   <td style=\"text-align:left;\"> (0.031) </td>\n",
       "   <td style=\"text-align:left;\"> (0.031) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">sibs</span> </td>\n",
       "   <td style=\"text-align:left;\"> 3.194 </td>\n",
       "   <td style=\"text-align:left;\"> 3.536 </td>\n",
       "   <td style=\"text-align:left;\"> 3.681 </td>\n",
       "   <td style=\"text-align:left;\"> 3.333 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.057) </td>\n",
       "   <td style=\"text-align:left;\"> (0.057) </td>\n",
       "   <td style=\"text-align:left;\"> (0.057) </td>\n",
       "   <td style=\"text-align:left;\"> (0.057) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">childs</span> </td>\n",
       "   <td style=\"text-align:left;\"> 1.816 </td>\n",
       "   <td style=\"text-align:left;\"> 1.775 </td>\n",
       "   <td style=\"text-align:left;\"> 1.556 </td>\n",
       "   <td style=\"text-align:left;\"> 1.155 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.029) </td>\n",
       "   <td style=\"text-align:left;\"> (0.029) </td>\n",
       "   <td style=\"text-align:left;\"> (0.029) </td>\n",
       "   <td style=\"text-align:left;\"> (0.029) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">occ80</span> </td>\n",
       "   <td style=\"text-align:left;\"> 380.8 </td>\n",
       "   <td style=\"text-align:left;\"> 344.2 </td>\n",
       "   <td style=\"text-align:left;\"> 339.8 </td>\n",
       "   <td style=\"text-align:left;\"> 271.9 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (4.677) </td>\n",
       "   <td style=\"text-align:left;\"> (4.677) </td>\n",
       "   <td style=\"text-align:left;\"> (4.678) </td>\n",
       "   <td style=\"text-align:left;\"> (4.678) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">prestg80</span> </td>\n",
       "   <td style=\"text-align:left;\"> 44.49 </td>\n",
       "   <td style=\"text-align:left;\"> 44.6 </td>\n",
       "   <td style=\"text-align:left;\"> 44.43 </td>\n",
       "   <td style=\"text-align:left;\"> 47.87 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.268) </td>\n",
       "   <td style=\"text-align:left;\"> (0.268) </td>\n",
       "   <td style=\"text-align:left;\"> (0.268) </td>\n",
       "   <td style=\"text-align:left;\"> (0.268) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">indus80</span> </td>\n",
       "   <td style=\"text-align:left;\"> 511.8 </td>\n",
       "   <td style=\"text-align:left;\"> 604.8 </td>\n",
       "   <td style=\"text-align:left;\"> 616.3 </td>\n",
       "   <td style=\"text-align:left;\"> 675.2 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (5.179) </td>\n",
       "   <td style=\"text-align:left;\"> (5.179) </td>\n",
       "   <td style=\"text-align:left;\"> (5.18) </td>\n",
       "   <td style=\"text-align:left;\"> (5.18) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">res16</span> </td>\n",
       "   <td style=\"text-align:left;\"> 3.268 </td>\n",
       "   <td style=\"text-align:left;\"> 3.412 </td>\n",
       "   <td style=\"text-align:left;\"> 3.613 </td>\n",
       "   <td style=\"text-align:left;\"> 3.868 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.029) </td>\n",
       "   <td style=\"text-align:left;\"> (0.029) </td>\n",
       "   <td style=\"text-align:left;\"> (0.029) </td>\n",
       "   <td style=\"text-align:left;\"> (0.029) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">reg16</span> </td>\n",
       "   <td style=\"text-align:left;\"> 4.608 </td>\n",
       "   <td style=\"text-align:left;\"> 4.619 </td>\n",
       "   <td style=\"text-align:left;\"> 4.333 </td>\n",
       "   <td style=\"text-align:left;\"> 4.128 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.051) </td>\n",
       "   <td style=\"text-align:left;\"> (0.051) </td>\n",
       "   <td style=\"text-align:left;\"> (0.051) </td>\n",
       "   <td style=\"text-align:left;\"> (0.051) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">mobile16</span> </td>\n",
       "   <td style=\"text-align:left;\"> 1.862 </td>\n",
       "   <td style=\"text-align:left;\"> 1.916 </td>\n",
       "   <td style=\"text-align:left;\"> 1.928 </td>\n",
       "   <td style=\"text-align:left;\"> 2.089 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.017) </td>\n",
       "   <td style=\"text-align:left;\"> (0.017) </td>\n",
       "   <td style=\"text-align:left;\"> (0.017) </td>\n",
       "   <td style=\"text-align:left;\"> (0.017) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">family16</span> </td>\n",
       "   <td style=\"text-align:left;\"> 1.55 </td>\n",
       "   <td style=\"text-align:left;\"> 1.73 </td>\n",
       "   <td style=\"text-align:left;\"> 1.928 </td>\n",
       "   <td style=\"text-align:left;\"> 2.081 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.032) </td>\n",
       "   <td style=\"text-align:left;\"> (0.032) </td>\n",
       "   <td style=\"text-align:left;\"> (0.032) </td>\n",
       "   <td style=\"text-align:left;\"> (0.032) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">parborn</span> </td>\n",
       "   <td style=\"text-align:left;\"> 0.402 </td>\n",
       "   <td style=\"text-align:left;\"> 0.686 </td>\n",
       "   <td style=\"text-align:left;\"> 1.283 </td>\n",
       "   <td style=\"text-align:left;\"> 1.279 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.047) </td>\n",
       "   <td style=\"text-align:left;\"> (0.047) </td>\n",
       "   <td style=\"text-align:left;\"> (0.047) </td>\n",
       "   <td style=\"text-align:left;\"> (0.047) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">maeduc</span> </td>\n",
       "   <td style=\"text-align:left;\"> 11.45 </td>\n",
       "   <td style=\"text-align:left;\"> 11.38 </td>\n",
       "   <td style=\"text-align:left;\"> 11.48 </td>\n",
       "   <td style=\"text-align:left;\"> 12.46 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.065) </td>\n",
       "   <td style=\"text-align:left;\"> (0.065) </td>\n",
       "   <td style=\"text-align:left;\"> (0.065) </td>\n",
       "   <td style=\"text-align:left;\"> (0.065) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">degree</span> </td>\n",
       "   <td style=\"text-align:left;\"> 1.509 </td>\n",
       "   <td style=\"text-align:left;\"> 1.583 </td>\n",
       "   <td style=\"text-align:left;\"> 1.589 </td>\n",
       "   <td style=\"text-align:left;\"> 2.273 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.022) </td>\n",
       "   <td style=\"text-align:left;\"> (0.022) </td>\n",
       "   <td style=\"text-align:left;\"> (0.022) </td>\n",
       "   <td style=\"text-align:left;\"> (0.022) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">sex</span> </td>\n",
       "   <td style=\"text-align:left;\"> 1.409 </td>\n",
       "   <td style=\"text-align:left;\"> 1.486 </td>\n",
       "   <td style=\"text-align:left;\"> 1.548 </td>\n",
       "   <td style=\"text-align:left;\"> 1.543 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.01) </td>\n",
       "   <td style=\"text-align:left;\"> (0.01) </td>\n",
       "   <td style=\"text-align:left;\"> (0.01) </td>\n",
       "   <td style=\"text-align:left;\"> (0.01) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">race</span> </td>\n",
       "   <td style=\"text-align:left;\"> 1.059 </td>\n",
       "   <td style=\"text-align:left;\"> 1.209 </td>\n",
       "   <td style=\"text-align:left;\"> 1.372 </td>\n",
       "   <td style=\"text-align:left;\"> 1.367 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.011) </td>\n",
       "   <td style=\"text-align:left;\"> (0.011) </td>\n",
       "   <td style=\"text-align:left;\"> (0.011) </td>\n",
       "   <td style=\"text-align:left;\"> (0.011) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">born</span> </td>\n",
       "   <td style=\"text-align:left;\"> 1.034 </td>\n",
       "   <td style=\"text-align:left;\"> 1.069 </td>\n",
       "   <td style=\"text-align:left;\"> 1.131 </td>\n",
       "   <td style=\"text-align:left;\"> 1.131 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.006) </td>\n",
       "   <td style=\"text-align:left;\"> (0.006) </td>\n",
       "   <td style=\"text-align:left;\"> (0.006) </td>\n",
       "   <td style=\"text-align:left;\"> (0.006) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">hompop</span> </td>\n",
       "   <td style=\"text-align:left;\"> 2.873 </td>\n",
       "   <td style=\"text-align:left;\"> 2.706 </td>\n",
       "   <td style=\"text-align:left;\"> 2.62 </td>\n",
       "   <td style=\"text-align:left;\"> 2.421 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.027) </td>\n",
       "   <td style=\"text-align:left;\"> (0.027) </td>\n",
       "   <td style=\"text-align:left;\"> (0.027) </td>\n",
       "   <td style=\"text-align:left;\"> (0.027) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">babies</span> </td>\n",
       "   <td style=\"text-align:left;\"> 0.261 </td>\n",
       "   <td style=\"text-align:left;\"> 0.228 </td>\n",
       "   <td style=\"text-align:left;\"> 0.219 </td>\n",
       "   <td style=\"text-align:left;\"> 0.2 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.011) </td>\n",
       "   <td style=\"text-align:left;\"> (0.011) </td>\n",
       "   <td style=\"text-align:left;\"> (0.011) </td>\n",
       "   <td style=\"text-align:left;\"> (0.011) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">preteen</span> </td>\n",
       "   <td style=\"text-align:left;\"> 0.401 </td>\n",
       "   <td style=\"text-align:left;\"> 0.314 </td>\n",
       "   <td style=\"text-align:left;\"> 0.276 </td>\n",
       "   <td style=\"text-align:left;\"> 0.244 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.013) </td>\n",
       "   <td style=\"text-align:left;\"> (0.013) </td>\n",
       "   <td style=\"text-align:left;\"> (0.013) </td>\n",
       "   <td style=\"text-align:left;\"> (0.013) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">teens</span> </td>\n",
       "   <td style=\"text-align:left;\"> 0.232 </td>\n",
       "   <td style=\"text-align:left;\"> 0.235 </td>\n",
       "   <td style=\"text-align:left;\"> 0.238 </td>\n",
       "   <td style=\"text-align:left;\"> 0.16 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.01) </td>\n",
       "   <td style=\"text-align:left;\"> (0.01) </td>\n",
       "   <td style=\"text-align:left;\"> (0.01) </td>\n",
       "   <td style=\"text-align:left;\"> (0.01) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">adults</span> </td>\n",
       "   <td style=\"text-align:left;\"> 1.971 </td>\n",
       "   <td style=\"text-align:left;\"> 1.923 </td>\n",
       "   <td style=\"text-align:left;\"> 1.883 </td>\n",
       "   <td style=\"text-align:left;\"> 1.813 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.015) </td>\n",
       "   <td style=\"text-align:left;\"> (0.015) </td>\n",
       "   <td style=\"text-align:left;\"> (0.015) </td>\n",
       "   <td style=\"text-align:left;\"> (0.015) </td>\n",
       "  </tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Little trick to display the standard errors\n",
    "table <- lapply(seq_along(covariate_names), function(j) {\n",
    "  m <- round(signif(cov_table[[j]], digits=4), 3)\n",
    "  m[\"Estimate\",] <- as.character(m[\"Estimate\",])\n",
    "  m[\"Std. Error\",] <- paste0(\"(\", m[\"Std. Error\",], \")\")\n",
    "  m\n",
    "})\n",
    "table <- do.call(rbind, table)\n",
    "\n",
    "# Covariate names\n",
    "covnames <- rep(\"\", nrow(table))\n",
    "covnames[seq(1, length(covnames), 2)] <-\n",
    "  cell_spec(covariate_names, format = \"html\", escape = F, color = \"black\", bold = T)\n",
    "\n",
    "table <- cbind(covariates=covnames, table)\n",
    "\n",
    "# Title of table\n",
    "caption <- \"Average covariate values in each n-tile\"\n",
    "\n",
    "table %>%\n",
    "  kable(format=\"html\", digits=2, caption=caption, escape = FALSE, row.names = FALSE) %>%\n",
    "  kable_styling(bootstrap_options=c(\"condensed\", \"responsive\"), full_width=FALSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in mean.default(newX[, i], ...):\n",
      "\"argument is not numeric or logical: returning NA\"\n",
      "Warning message in mean.default(newX[, i], ...):\n",
      "\"argument is not numeric or logical: returning NA\"\n",
      "Warning message in mean.default(newX[, i], ...):\n",
      "\"argument is not numeric or logical: returning NA\"\n",
      "Warning message in mean.default(newX[, i], ...):\n",
      "\"argument is not numeric or logical: returning NA\"\n",
      "Warning message in mean.default(newX[, i], ...):\n",
      "\"argument is not numeric or logical: returning NA\"\n",
      "Warning message in mean.default(newX[, i], ...):\n",
      "\"argument is not numeric or logical: returning NA\"\n",
      "Warning message in mean.default(newX[, i], ...):\n",
      "\"argument is not numeric or logical: returning NA\"\n",
      "Warning message in mean.default(newX[, i], ...):\n",
      "\"argument is not numeric or logical: returning NA\"\n",
      "Warning message in mean.default(newX[, i], ...):\n",
      "\"argument is not numeric or logical: returning NA\"\n",
      "Warning message in mean.default(newX[, i], ...):\n",
      "\"argument is not numeric or logical: returning NA\"\n",
      "Warning message in mean.default(newX[, i], ...):\n",
      "\"argument is not numeric or logical: returning NA\"\n",
      "Warning message in mean.default(newX[, i], ...):\n",
      "\"argument is not numeric or logical: returning NA\"\n",
      "Warning message in mean.default(newX[, i], ...):\n",
      "\"argument is not numeric or logical: returning NA\"\n",
      "Warning message in mean.default(newX[, i], ...):\n",
      "\"argument is not numeric or logical: returning NA\"\n",
      "Warning message in mean.default(newX[, i], ...):\n",
      "\"argument is not numeric or logical: returning NA\"\n",
      "Warning message in mean.default(newX[, i], ...):\n",
      "\"argument is not numeric or logical: returning NA\"\n",
      "Warning message in mean.default(newX[, i], ...):\n",
      "\"argument is not numeric or logical: returning NA\"\n",
      "Warning message in mean.default(newX[, i], ...):\n",
      "\"argument is not numeric or logical: returning NA\"\n",
      "Warning message in mean.default(newX[, i], ...):\n",
      "\"argument is not numeric or logical: returning NA\"\n",
      "Warning message in mean.default(newX[, i], ...):\n",
      "\"argument is not numeric or logical: returning NA\"\n",
      "Warning message in mean.default(newX[, i], ...):\n",
      "\"argument is not numeric or logical: returning NA\"\n",
      "Warning message in mean.default(newX[, i], ...):\n",
      "\"argument is not numeric or logical: returning NA\"\n",
      "Warning message in mean.default(newX[, i], ...):\n",
      "\"argument is not numeric or logical: returning NA\"\n",
      "Warning message in mean.default(newX[, i], ...):\n",
      "\"argument is not numeric or logical: returning NA\"\n",
      "Warning message in mean.default(newX[, i], ...):\n",
      "\"argument is not numeric or logical: returning NA\"\n",
      "Warning message in mean.default(newX[, i], ...):\n",
      "\"argument is not numeric or logical: returning NA\"\n",
      "Warning message in mean.default(newX[, i], ...):\n",
      "\"argument is not numeric or logical: returning NA\"\n",
      "Warning message in mean.default(newX[, i], ...):\n",
      "\"argument is not numeric or logical: returning NA\"\n",
      "Warning message in mean.default(newX[, i], ...):\n",
      "\"argument is not numeric or logical: returning NA\"\n",
      "Warning message in mean.default(newX[, i], ...):\n",
      "\"argument is not numeric or logical: returning NA\"\n",
      "Warning message in mean.default(newX[, i], ...):\n",
      "\"argument is not numeric or logical: returning NA\"\n",
      "Warning message in mean.default(newX[, i], ...):\n",
      "\"argument is not numeric or logical: returning NA\"\n",
      "Warning message in mean.default(newX[, i], ...):\n",
      "\"argument is not numeric or logical: returning NA\"\n",
      "Warning message in mean.default(newX[, i], ...):\n",
      "\"argument is not numeric or logical: returning NA\"\n",
      "Warning message in mean.default(newX[, i], ...):\n",
      "\"argument is not numeric or logical: returning NA\"\n"
     ]
    }
   ],
   "source": [
    "covariate_means_per_ntile <- aggregate(. ~ ntile, df_train, mean)[,covariate_names]\n",
    "covariate_means <- apply(df_train, 2, mean)[covariate_names]\n",
    "ntile_weights <- table(df_train$ntile) / dim(df_train)[1] \n",
    "deviations <- t(apply(covariate_means_per_ntile, 1, function(x) x - covariate_means))\n",
    "covariate_means_weighted_var <- apply(deviations, 2, function(x) sum(ntile_weights * x^2))\n",
    "covariate_var <- apply(df_train, 2, var)[covariate_names]\n",
    "cov_variation <- covariate_means_weighted_var / covariate_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table class=\"table table-striped table-hover table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n",
       "<caption>Covariate variation across n-tiles</caption>\n",
       "<tbody>\n",
       "  <tr>\n",
       "\n",
       "  </tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sorted_cov_variation <- sort(cov_variation, decreasing = TRUE)\n",
    "table <- as.data.frame(sorted_cov_variation)\n",
    "colnames(table) <- NULL\n",
    "\n",
    "kable_styling(kable(table,  \"html\", digits = 4, row.names=TRUE,\n",
    "                    caption=\"Covariate variation across n-tiles\"),\n",
    "              bootstrap_options=c(\"striped\", \"hover\", \"condensed\", \"responsive\"),\n",
    "              full_width=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Partial dependence plots\n",
    "\n",
    "It may also be interesting to examine how our CATE estimates behave when we change a single covariate, while keeping all the other covariates at a some fixed value. In the plot below we evaluate a variable of interest across quantiles, while keeping all other covariates at their median (see the RMarkdown source for code).  \n",
    "\n",
    "\n",
    "**Note:** It is important to recognize that in the following plots and tables, we may be evaluating the CATE at $x$ values in regions where there are few or no data points. Also, it may be the case that varying some particular variable while keeping others fixed may just not be very interesting. For example, in the _welfare_ dataset, we will not see a lot difference when we change `partyid` if we keep `polviews` fixed at their median value. It might be instructive to re-run this tutorial without using the variable `partyid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (dataset_name == \"welfare\") {\n",
    "  var_of_interest = \"polviews\"\n",
    "  vars_of_interest = c(\"income\", \"polviews\")\n",
    "} else {\n",
    "  # Selecting a continuous variable, if available, to make for a more interesting graph\n",
    "  continuous_variables <- sapply(covariate_names, function(x) length(unique(df_train[, x])) > 5)\n",
    "  \n",
    "  # Select variable for single variable plot\n",
    "  var_of_interest <- ifelse(sum(continuous_variables) > 0,\n",
    "                            covariate_names[continuous_variables][1],\n",
    "                            covariate_names[1])\n",
    "  \n",
    "  # Select variables for two variable plot\n",
    "  vars_of_interest <- c(var_of_interest,\n",
    "                        ifelse(sum(continuous_variables) > 1,\n",
    "                               covariate_names[continuous_variables][2],\n",
    "                               covariate_names[covariate_names != var_of_interest][1]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a grid of values: if continuous, quantiles; else, plot the actual values\n",
    "is_continuous <- (length(unique(df_train[,var_of_interest])) > 5) # crude rule for determining continuity\n",
    "if(is_continuous) {\n",
    "  x_grid <- quantile(df_train[,var_of_interest], probs = seq(0, 1, length.out = 5))\n",
    "} else {\n",
    "  x_grid <- sort(unique(df_train[,var_of_interest]))\n",
    "}\n",
    "df_grid <- setNames(data.frame(x_grid), var_of_interest)\n",
    "\n",
    "# For the other variables, keep them at their median\n",
    "other_covariates <- covariate_names[which(covariate_names != var_of_interest)]\n",
    "df_median <- data.frame(lapply(df_train[,other_covariates], median))\n",
    "df_eval <- crossing(df_median, df_grid)\n",
    "\n",
    "# Predict the treatment effect\n",
    "pred <- predict(cf, newdata=df_eval[,covariate_names], estimate.variance=TRUE)\n",
    "df_eval$tauhat <- pred$predictions\n",
    "df_eval$se <- sqrt(pred$variance.estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAM1BMVEUAAAAAAP9NTU1oaGh8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\npAEYkjSA//YA4OaybAv9AAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Change to factor so the plotted values are evenly spaced\n",
    "df_eval[, var_of_interest] <- as.factor(round(df_eval[, var_of_interest], digits = 4))\n",
    "\n",
    "# Descriptive labeling\n",
    "label_description <- ifelse(is_continuous, '\\n(Evaluated at quintiles)', '')\n",
    "\n",
    "# Plot\n",
    "df_eval %>%\n",
    "  mutate(ymin_val = tauhat-1.96*se) %>%\n",
    "  mutate(ymax_val = tauhat+1.96*se) %>%\n",
    "  ggplot() +\n",
    "    geom_line(aes_string(x=var_of_interest, y=\"tauhat\", group = 1), color=\"red\") +\n",
    "    geom_errorbar(aes_string(x=var_of_interest,ymin=\"ymin_val\", ymax=\"ymax_val\", width=.2),color=\"blue\") +\n",
    "    xlab(paste0(\"Effect of \", var_of_interest, label_description)) +\n",
    "    ylab(\"Predicted Treatment Effect\") +\n",
    "    theme_linedraw() +\n",
    "    theme(axis.ticks = element_blank())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may then repeat this for all covariates. Here, we display the results in a table below for selected values. If the variable is binary, we do the same but just evaluate the variable at 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split up continuous and binary variables\n",
    "binary_covariates <- sapply(covariate_names,\n",
    "                            function(x) length(unique(df_train[, x])) <= 2)\n",
    "\n",
    "evaluate_partial_dependency <- function(var_of_interest, is_binary) {\n",
    "  if(is_binary){\n",
    "    # Get two unique values for the variable\n",
    "    x_grid <- sort(unique(df_train[,var_of_interest]))\n",
    "  } else {\n",
    "    # Get quartile values for the variable\n",
    "    x_grid <- quantile(df_train[,var_of_interest], probs = seq(0, 1, length.out = 5))\n",
    "  }\n",
    "  df_grid <- setNames(data.frame(x_grid), var_of_interest)\n",
    "\n",
    "  # For the other variables, keep them at their median\n",
    "  other_covariates <- covariate_names[which(covariate_names != var_of_interest)]\n",
    "  df_median <- data.frame(lapply(df_train[,other_covariates], median))\n",
    "  df_eval1 <- crossing(df_median, df_grid)\n",
    "\n",
    "  # Predict the treatment effect\n",
    "  pred <- predict(cf, newdata=df_eval1[,covariate_names], estimate.variance=TRUE)\n",
    "  rbind('Tau Hat' = pred$predictions,\n",
    "        'Std. Error' = sqrt(pred$variance.estimates))\n",
    "}\n",
    "\n",
    "# Make the table for non-binary variables\n",
    "nonbinary_partial_dependency_tauhats <- lapply(covariate_names[!binary_covariates],\n",
    "                                               function(variable) evaluate_partial_dependency(variable, FALSE))\n",
    "\n",
    "# Make the table for binary variables\n",
    "binary_partial_dependency_tauhats <- lapply(covariate_names[binary_covariates],\n",
    "                                            function(variable) evaluate_partial_dependency(variable, TRUE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table class=\"table table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n",
       "<caption>The CATE function's value varying each non-binary covariate across its indicated percentile values, holding all other covariates at their medians.</caption>\n",
       " <thead>\n",
       "  <tr>\n",
       "   <th style=\"text-align:left;\"> covariates </th>\n",
       "   <th style=\"text-align:left;\"> Q=0% </th>\n",
       "   <th style=\"text-align:left;\"> Q=25% </th>\n",
       "   <th style=\"text-align:left;\"> Q=50% </th>\n",
       "   <th style=\"text-align:left;\"> Q=75% </th>\n",
       "   <th style=\"text-align:left;\"> Q=100% </th>\n",
       "  </tr>\n",
       " </thead>\n",
       "<tbody>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">hrs1</span> </td>\n",
       "   <td style=\"text-align:left;\"> -0.391 </td>\n",
       "   <td style=\"text-align:left;\"> -0.399 </td>\n",
       "   <td style=\"text-align:left;\"> -0.401 </td>\n",
       "   <td style=\"text-align:left;\"> -0.396 </td>\n",
       "   <td style=\"text-align:left;\"> -0.408 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.066) </td>\n",
       "   <td style=\"text-align:left;\"> (0.041) </td>\n",
       "   <td style=\"text-align:left;\"> (0.042) </td>\n",
       "   <td style=\"text-align:left;\"> (0.061) </td>\n",
       "   <td style=\"text-align:left;\"> (0.078) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">partyid</span> </td>\n",
       "   <td style=\"text-align:left;\"> -0.398 </td>\n",
       "   <td style=\"text-align:left;\"> -0.399 </td>\n",
       "   <td style=\"text-align:left;\"> -0.401 </td>\n",
       "   <td style=\"text-align:left;\"> -0.411 </td>\n",
       "   <td style=\"text-align:left;\"> -0.411 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.039) </td>\n",
       "   <td style=\"text-align:left;\"> (0.044) </td>\n",
       "   <td style=\"text-align:left;\"> (0.042) </td>\n",
       "   <td style=\"text-align:left;\"> (0.044) </td>\n",
       "   <td style=\"text-align:left;\"> (0.046) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">income</span> </td>\n",
       "   <td style=\"text-align:left;\"> -0.397 </td>\n",
       "   <td style=\"text-align:left;\"> -0.396 </td>\n",
       "   <td style=\"text-align:left;\"> -0.401 </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.037) </td>\n",
       "   <td style=\"text-align:left;\"> (0.043) </td>\n",
       "   <td style=\"text-align:left;\"> (0.042) </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">rincome</span> </td>\n",
       "   <td style=\"text-align:left;\"> -0.386 </td>\n",
       "   <td style=\"text-align:left;\"> -0.388 </td>\n",
       "   <td style=\"text-align:left;\"> -0.401 </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.044) </td>\n",
       "   <td style=\"text-align:left;\"> (0.038) </td>\n",
       "   <td style=\"text-align:left;\"> (0.042) </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">age</span> </td>\n",
       "   <td style=\"text-align:left;\"> -0.384 </td>\n",
       "   <td style=\"text-align:left;\"> -0.394 </td>\n",
       "   <td style=\"text-align:left;\"> -0.401 </td>\n",
       "   <td style=\"text-align:left;\"> -0.399 </td>\n",
       "   <td style=\"text-align:left;\"> -0.385 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.086) </td>\n",
       "   <td style=\"text-align:left;\"> (0.091) </td>\n",
       "   <td style=\"text-align:left;\"> (0.042) </td>\n",
       "   <td style=\"text-align:left;\"> (0.043) </td>\n",
       "   <td style=\"text-align:left;\"> (0.046) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">polviews</span> </td>\n",
       "   <td style=\"text-align:left;\"> -0.34 </td>\n",
       "   <td style=\"text-align:left;\"> -0.346 </td>\n",
       "   <td style=\"text-align:left;\"> -0.401 </td>\n",
       "   <td style=\"text-align:left;\"> -0.402 </td>\n",
       "   <td style=\"text-align:left;\"> -0.397 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.09) </td>\n",
       "   <td style=\"text-align:left;\"> (0.076) </td>\n",
       "   <td style=\"text-align:left;\"> (0.042) </td>\n",
       "   <td style=\"text-align:left;\"> (0.039) </td>\n",
       "   <td style=\"text-align:left;\"> (0.041) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">educ</span> </td>\n",
       "   <td style=\"text-align:left;\"> -0.393 </td>\n",
       "   <td style=\"text-align:left;\"> -0.403 </td>\n",
       "   <td style=\"text-align:left;\"> -0.401 </td>\n",
       "   <td style=\"text-align:left;\"> -0.379 </td>\n",
       "   <td style=\"text-align:left;\"> -0.382 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.048) </td>\n",
       "   <td style=\"text-align:left;\"> (0.042) </td>\n",
       "   <td style=\"text-align:left;\"> (0.042) </td>\n",
       "   <td style=\"text-align:left;\"> (0.038) </td>\n",
       "   <td style=\"text-align:left;\"> (0.034) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">earnrs</span> </td>\n",
       "   <td style=\"text-align:left;\"> -0.402 </td>\n",
       "   <td style=\"text-align:left;\"> -0.402 </td>\n",
       "   <td style=\"text-align:left;\"> -0.401 </td>\n",
       "   <td style=\"text-align:left;\"> -0.411 </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.052) </td>\n",
       "   <td style=\"text-align:left;\"> (0.052) </td>\n",
       "   <td style=\"text-align:left;\"> (0.042) </td>\n",
       "   <td style=\"text-align:left;\"> (0.049) </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">race</span> </td>\n",
       "   <td style=\"text-align:left;\"> -0.401 </td>\n",
       "   <td style=\"text-align:left;\"> -0.36 </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.042) </td>\n",
       "   <td style=\"text-align:left;\"> (0.04) </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">marital</span> </td>\n",
       "   <td style=\"text-align:left;\"> -0.401 </td>\n",
       "   <td style=\"text-align:left;\"> -0.368 </td>\n",
       "   <td style=\"text-align:left;\"> -0.362 </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.042) </td>\n",
       "   <td style=\"text-align:left;\"> (0.064) </td>\n",
       "   <td style=\"text-align:left;\"> (0.067) </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">sibs</span> </td>\n",
       "   <td style=\"text-align:left;\"> -0.397 </td>\n",
       "   <td style=\"text-align:left;\"> -0.396 </td>\n",
       "   <td style=\"text-align:left;\"> -0.401 </td>\n",
       "   <td style=\"text-align:left;\"> -0.411 </td>\n",
       "   <td style=\"text-align:left;\"> -0.394 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.042) </td>\n",
       "   <td style=\"text-align:left;\"> (0.04) </td>\n",
       "   <td style=\"text-align:left;\"> (0.042) </td>\n",
       "   <td style=\"text-align:left;\"> (0.056) </td>\n",
       "   <td style=\"text-align:left;\"> (0.061) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">childs</span> </td>\n",
       "   <td style=\"text-align:left;\"> -0.405 </td>\n",
       "   <td style=\"text-align:left;\"> -0.401 </td>\n",
       "   <td style=\"text-align:left;\"> -0.415 </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.05) </td>\n",
       "   <td style=\"text-align:left;\"> (0.042) </td>\n",
       "   <td style=\"text-align:left;\"> (0.041) </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">occ80</span> </td>\n",
       "   <td style=\"text-align:left;\"> -0.381 </td>\n",
       "   <td style=\"text-align:left;\"> -0.377 </td>\n",
       "   <td style=\"text-align:left;\"> -0.401 </td>\n",
       "   <td style=\"text-align:left;\"> -0.395 </td>\n",
       "   <td style=\"text-align:left;\"> -0.39 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.06) </td>\n",
       "   <td style=\"text-align:left;\"> (0.038) </td>\n",
       "   <td style=\"text-align:left;\"> (0.042) </td>\n",
       "   <td style=\"text-align:left;\"> (0.041) </td>\n",
       "   <td style=\"text-align:left;\"> (0.042) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">prestg80</span> </td>\n",
       "   <td style=\"text-align:left;\"> -0.4 </td>\n",
       "   <td style=\"text-align:left;\"> -0.406 </td>\n",
       "   <td style=\"text-align:left;\"> -0.401 </td>\n",
       "   <td style=\"text-align:left;\"> -0.379 </td>\n",
       "   <td style=\"text-align:left;\"> -0.352 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.082) </td>\n",
       "   <td style=\"text-align:left;\"> (0.084) </td>\n",
       "   <td style=\"text-align:left;\"> (0.042) </td>\n",
       "   <td style=\"text-align:left;\"> (0.052) </td>\n",
       "   <td style=\"text-align:left;\"> (0.044) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">indus80</span> </td>\n",
       "   <td style=\"text-align:left;\"> -0.412 </td>\n",
       "   <td style=\"text-align:left;\"> -0.414 </td>\n",
       "   <td style=\"text-align:left;\"> -0.401 </td>\n",
       "   <td style=\"text-align:left;\"> -0.431 </td>\n",
       "   <td style=\"text-align:left;\"> -0.44 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.053) </td>\n",
       "   <td style=\"text-align:left;\"> (0.042) </td>\n",
       "   <td style=\"text-align:left;\"> (0.042) </td>\n",
       "   <td style=\"text-align:left;\"> (0.048) </td>\n",
       "   <td style=\"text-align:left;\"> (0.059) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">res16</span> </td>\n",
       "   <td style=\"text-align:left;\"> -0.409 </td>\n",
       "   <td style=\"text-align:left;\"> -0.401 </td>\n",
       "   <td style=\"text-align:left;\"> -0.4 </td>\n",
       "   <td style=\"text-align:left;\"> -0.392 </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.056) </td>\n",
       "   <td style=\"text-align:left;\"> (0.042) </td>\n",
       "   <td style=\"text-align:left;\"> (0.039) </td>\n",
       "   <td style=\"text-align:left;\"> (0.042) </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">reg16</span> </td>\n",
       "   <td style=\"text-align:left;\"> -0.391 </td>\n",
       "   <td style=\"text-align:left;\"> -0.402 </td>\n",
       "   <td style=\"text-align:left;\"> -0.401 </td>\n",
       "   <td style=\"text-align:left;\"> -0.414 </td>\n",
       "   <td style=\"text-align:left;\"> -0.422 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.057) </td>\n",
       "   <td style=\"text-align:left;\"> (0.04) </td>\n",
       "   <td style=\"text-align:left;\"> (0.042) </td>\n",
       "   <td style=\"text-align:left;\"> (0.041) </td>\n",
       "   <td style=\"text-align:left;\"> (0.039) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">mobile16</span> </td>\n",
       "   <td style=\"text-align:left;\"> -0.391 </td>\n",
       "   <td style=\"text-align:left;\"> -0.401 </td>\n",
       "   <td style=\"text-align:left;\"> -0.394 </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.04) </td>\n",
       "   <td style=\"text-align:left;\"> (0.042) </td>\n",
       "   <td style=\"text-align:left;\"> (0.069) </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">family16</span> </td>\n",
       "   <td style=\"text-align:left;\"> -0.401 </td>\n",
       "   <td style=\"text-align:left;\"> -0.401 </td>\n",
       "   <td style=\"text-align:left;\"> -0.38 </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.042) </td>\n",
       "   <td style=\"text-align:left;\"> (0.042) </td>\n",
       "   <td style=\"text-align:left;\"> (0.09) </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">parborn</span> </td>\n",
       "   <td style=\"text-align:left;\"> -0.401 </td>\n",
       "   <td style=\"text-align:left;\"> -0.398 </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.042) </td>\n",
       "   <td style=\"text-align:left;\"> (0.044) </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">maeduc</span> </td>\n",
       "   <td style=\"text-align:left;\"> -0.397 </td>\n",
       "   <td style=\"text-align:left;\"> -0.399 </td>\n",
       "   <td style=\"text-align:left;\"> -0.401 </td>\n",
       "   <td style=\"text-align:left;\"> -0.397 </td>\n",
       "   <td style=\"text-align:left;\"> -0.378 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.042) </td>\n",
       "   <td style=\"text-align:left;\"> (0.05) </td>\n",
       "   <td style=\"text-align:left;\"> (0.042) </td>\n",
       "   <td style=\"text-align:left;\"> (0.04) </td>\n",
       "   <td style=\"text-align:left;\"> (0.056) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">degree</span> </td>\n",
       "   <td style=\"text-align:left;\"> -0.404 </td>\n",
       "   <td style=\"text-align:left;\"> -0.401 </td>\n",
       "   <td style=\"text-align:left;\"> -0.373 </td>\n",
       "   <td style=\"text-align:left;\"> -0.37 </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.046) </td>\n",
       "   <td style=\"text-align:left;\"> (0.042) </td>\n",
       "   <td style=\"text-align:left;\"> (0.057) </td>\n",
       "   <td style=\"text-align:left;\"> (0.06) </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">race</span> </td>\n",
       "   <td style=\"text-align:left;\"> -0.401 </td>\n",
       "   <td style=\"text-align:left;\"> -0.36 </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.042) </td>\n",
       "   <td style=\"text-align:left;\"> (0.04) </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">hompop</span> </td>\n",
       "   <td style=\"text-align:left;\"> -0.4 </td>\n",
       "   <td style=\"text-align:left;\"> -0.401 </td>\n",
       "   <td style=\"text-align:left;\"> -0.402 </td>\n",
       "   <td style=\"text-align:left;\"> -0.397 </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.041) </td>\n",
       "   <td style=\"text-align:left;\"> (0.042) </td>\n",
       "   <td style=\"text-align:left;\"> (0.044) </td>\n",
       "   <td style=\"text-align:left;\"> (0.041) </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">babies</span> </td>\n",
       "   <td style=\"text-align:left;\"> -0.401 </td>\n",
       "   <td style=\"text-align:left;\"> -0.396 </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.042) </td>\n",
       "   <td style=\"text-align:left;\"> (0.045) </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">preteen</span> </td>\n",
       "   <td style=\"text-align:left;\"> -0.401 </td>\n",
       "   <td style=\"text-align:left;\"> -0.398 </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.042) </td>\n",
       "   <td style=\"text-align:left;\"> (0.045) </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">teens</span> </td>\n",
       "   <td style=\"text-align:left;\"> -0.401 </td>\n",
       "   <td style=\"text-align:left;\"> -0.412 </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.042) </td>\n",
       "   <td style=\"text-align:left;\"> (0.045) </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">adults</span> </td>\n",
       "   <td style=\"text-align:left;\"> -0.396 </td>\n",
       "   <td style=\"text-align:left;\"> -0.401 </td>\n",
       "   <td style=\"text-align:left;\"> -0.386 </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.043) </td>\n",
       "   <td style=\"text-align:left;\"> (0.042) </td>\n",
       "   <td style=\"text-align:left;\"> (0.042) </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "   <td style=\"text-align:left;\"> NA </td>\n",
       "  </tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if(sum(!binary_covariates) > 0) {\n",
    "  # Little trick to display the standard errors\n",
    "  table <- lapply(seq_along(covariate_names[!binary_covariates]), function(j) {\n",
    "    m <- round(signif(nonbinary_partial_dependency_tauhats[[j]], digits=4), 3)\n",
    "    m[\"Tau Hat\",] <- as.character(m[\"Tau Hat\",])\n",
    "    m[\"Std. Error\",] <- paste0(\"(\", m[\"Std. Error\",], \")\")\n",
    "    m\n",
    "  })\n",
    "  table <- rbind.fill.matrix(table)\n",
    "  colnames(table) <- paste0('Q=', names(quantile(NULL, probs = seq(0, 1, length.out = 5))))\n",
    "\n",
    "  # Covariate names\n",
    "  covnames <- rep(\"\", nrow(table))\n",
    "  covnames[seq(1, length(covnames), 2)] <-\n",
    "    cell_spec(covariate_names[!binary_covariates], format = \"html\", escape = F, color = \"black\", bold = T)\n",
    "\n",
    "  table <- cbind(covariates=covnames, table)\n",
    "\n",
    "  # Title of table\n",
    "  caption <- \"The CATE function's value varying each non-binary covariate across its indicated percentile values, holding all other covariates at their medians.\"\n",
    "\n",
    "  table %>%\n",
    "    kable(format=\"html\", digits=2, caption=caption, escape = FALSE, row.names = FALSE) %>%\n",
    "    kable_styling(bootstrap_options=c(\"condensed\", \"responsive\"), full_width=FALSE)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(sum(binary_covariates) > 0) {\n",
    "  # Little trick to display the standard errors\n",
    "  table <- lapply(seq_along(covariate_names[binary_covariates]), function(j) {\n",
    "    m <- round(signif(binary_partial_dependency_tauhats[[j]], digits=4), 3)\n",
    "    m[\"Tau Hat\",] <- as.character(m[\"Tau Hat\",])\n",
    "    m[\"Std. Error\",] <- paste0(\"(\", m[\"Std. Error\",], \")\")\n",
    "    m\n",
    "  })\n",
    "  table <- do.call(rbind, table)\n",
    "  colnames(table) <- paste0('X=',c('0', '1'))\n",
    "\n",
    "  # Covariate names\n",
    "  covnames <- rep(\"\", nrow(table))\n",
    "  covnames[seq(1, length(covnames), 2)] <-\n",
    "    cell_spec(covariate_names[binary_covariates], format = \"html\", escape = F, color = \"black\", bold = T)\n",
    "\n",
    "  table <- cbind(covariates=covnames, table)\n",
    "\n",
    "  # Title of table\n",
    "  caption <- \"The CATE function's value varying each binary covariate at 0 and 1, holding all other covariates at their medians.\"\n",
    "\n",
    "  table %>%\n",
    "    kable(format=\"html\", digits=2, caption=caption, escape = FALSE, row.names = FALSE) %>%\n",
    "    kable_styling(bootstrap_options=c(\"condensed\", \"responsive\"), full_width=FALSE)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we might be interested in the interaction of two variables and their relationship with the CATE. Here's an example where we look at how the CATE function varies in two dimensions, while holding other covariates fixed at their median values. The chosen variables here are `r vars_of_interest[1]` and  `r vars_of_interest[2]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a grid of values: if continuous, quantiles; else, plot the actual values\n",
    "x_grids <- list(NULL, NULL)\n",
    "is_continuous <- c(NULL, NULL)\n",
    "for(i in 1:2) {\n",
    "  is_continuous[i] <- (length(unique(df_train[,vars_of_interest[i]])) > 5) # crude rule for determining continuity\n",
    "  if(is_continuous[i]) {\n",
    "    x_grids[[i]] <- quantile(df_train[,vars_of_interest[i]], probs = seq(0, 1, length.out = 5))\n",
    "  } else {\n",
    "    x_grids[[i]] <- sort(unique(df_train[,vars_of_interest[i]]))\n",
    "  }\n",
    "}\n",
    "x_grids <- setNames(x_grids, vars_of_interest)\n",
    "df_grid <- do.call(expand.grid, x_grids)\n",
    "\n",
    "# For the other variables, keep them at their median\n",
    "other_covariates <- covariate_names[which(!covariate_names %in% vars_of_interest)]\n",
    "df_median <- data.frame(lapply(df_train[,other_covariates], median))\n",
    "df_eval <- crossing(df_median, df_grid)\n",
    "\n",
    "# Predict the treatment effect\n",
    "pred <- predict(cf, newdata=df_eval[,covariate_names], estimate.variance=TRUE)\n",
    "df_eval$tauhat <- pred$predictions\n",
    "df_eval$se <- sqrt(pred$variance.estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAB41BMVEUAAAAhZqwkaK0oa68t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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Change to factor so the plotted values are evenly spaced\n",
    "df_eval[, vars_of_interest[1]] <- as.factor(round(df_eval[, vars_of_interest[1]], digits = 4))\n",
    "df_eval[, vars_of_interest[2]] <- as.factor(round(df_eval[, vars_of_interest[2]], digits = 4))\n",
    "\n",
    "# Descriptive labeling\n",
    "label_description1 <- ifelse(is_continuous[1], '\\n(Evaluated at quintiles)', '')\n",
    "label_description2 <- ifelse(is_continuous[2], '\\n(Evaluated at quintiles)', '')\n",
    "\n",
    "# Plot\n",
    "df_eval %>%\n",
    "    ggplot() +\n",
    "      geom_tile(aes_string(x=vars_of_interest[1], y=vars_of_interest[2], fill=\"tauhat\")) +\n",
    "      theme_linedraw() +\n",
    "      scale_fill_distiller(direction = 1, palette = 'RdBu') +\n",
    "      xlab(paste0(\"Effect of \", vars_of_interest[1], label_description1)) +\n",
    "      ylab(paste0(\"Effect of \", vars_of_interest[2], label_description2)) +\n",
    "      theme(axis.ticks = element_blank())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we put a similar analysis into table form by evaluating the CATE at four values for a given pair of covariates $x_1$ and $x_2$:\n",
    "\n",
    "1. **LL**: $x_1$ and $x_2$ are equal to the 20th percentile of their respective empirical distribution;\n",
    "2. **HL**: $x_1$ is at the 80th percentile, and $x_2$ is at its 20th percentile;\n",
    "3. **LH**: $x_1$ is at the 20th percentile, and $x_2$ is at its 80th percentile;\n",
    "4. **HH**: both $x_1$ and $x_2$ are held at their 80th percentiles.\n",
    "\n",
    "As always, other covariates are fixed at their medians. If the variable is not continuous, then the 20th and 80th percentiles are replaced with 0 and 1, respectively. We use the top 5 variables from the causal forest variable importance measure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariate_subset <- names(sorted_var_imp)[1:5]\n",
    "all_pairs <- combn(covariate_subset, m = 2)\n",
    "\n",
    "evaluate_twoway_partial_dependency <- function(vars_of_interest) {\n",
    "  # Create a grid of values: if continuous, quantiles; else, plot the actual values\n",
    "  x_grids <- list(NULL, NULL)\n",
    "  for(i in 1:2) {\n",
    "    is_binary <- (length(unique(df_train[,vars_of_interest[i]])) <= 2)\n",
    "    if(is_binary) {\n",
    "      x_grids[[i]] <- sort(unique(df_train[,vars_of_interest[i]]))\n",
    "    } else {\n",
    "      x_grids[[i]] <- quantile(df_train[,vars_of_interest[i]], probs = c(0.2, 0.8))\n",
    "    }\n",
    "  }\n",
    "  x_grids <- setNames(x_grids, vars_of_interest)\n",
    "  df_grid <- do.call(expand.grid, x_grids)\n",
    "\n",
    "  # For the other variables, keep them at their median\n",
    "  other_covariates <- covariate_names[which(!covariate_names %in% vars_of_interest)]\n",
    "  df_median <- data.frame(lapply(df_train[,other_covariates], median))\n",
    "  df_eval <- crossing(df_median, df_grid)\n",
    "\n",
    "  # Predict the treatment effect\n",
    "  pred <- predict(cf, newdata=df_eval[,covariate_names], estimate.variance=TRUE)\n",
    "  rbind('Tau Hat' = pred$predictions,\n",
    "        'Std. Error' = sqrt(pred$variance.estimates))\n",
    "}\n",
    "\n",
    "twoway_partial_dependency_tauhats <- lapply(1:ncol(all_pairs),\n",
    "                                            function(j) evaluate_twoway_partial_dependency(all_pairs[, j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table class=\"table table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n",
       "<caption>The CATE function's value for x1 and x2 evaluated at combinations of 'high' and 'low' (e.g. HL is High-Low with x1 at its 80th percentile, x2 at its 20th percentile). All other covariates are fixed at their medians.</caption>\n",
       " <thead>\n",
       "  <tr>\n",
       "   <th style=\"text-align:left;\"> x1 </th>\n",
       "   <th style=\"text-align:left;\"> x2 </th>\n",
       "   <th style=\"text-align:left;\"> LL </th>\n",
       "   <th style=\"text-align:left;\"> HL </th>\n",
       "   <th style=\"text-align:left;\"> LH </th>\n",
       "   <th style=\"text-align:left;\"> HH </th>\n",
       "   <th style=\"text-align:left;\">  (HH-HL)<br>- (LH-LL) </th>\n",
       "  </tr>\n",
       " </thead>\n",
       "<tbody>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">polviews</span> </td>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">partyid</span> </td>\n",
       "   <td style=\"text-align:left;\"> -0.369 </td>\n",
       "   <td style=\"text-align:left;\"> -0.341 </td>\n",
       "   <td style=\"text-align:left;\"> -0.399 </td>\n",
       "   <td style=\"text-align:left;\"> -0.402 </td>\n",
       "   <td style=\"text-align:left;\"> -0.031 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.089) </td>\n",
       "   <td style=\"text-align:left;\"> (0.055) </td>\n",
       "   <td style=\"text-align:left;\"> (0.047) </td>\n",
       "   <td style=\"text-align:left;\"> (0.048) </td>\n",
       "   <td style=\"text-align:left;\"> (0.124) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">polviews</span> </td>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">educ</span> </td>\n",
       "   <td style=\"text-align:left;\"> -0.356 </td>\n",
       "   <td style=\"text-align:left;\"> -0.318 </td>\n",
       "   <td style=\"text-align:left;\"> -0.389 </td>\n",
       "   <td style=\"text-align:left;\"> -0.386 </td>\n",
       "   <td style=\"text-align:left;\"> -0.035 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.062) </td>\n",
       "   <td style=\"text-align:left;\"> (0.037) </td>\n",
       "   <td style=\"text-align:left;\"> (0.037) </td>\n",
       "   <td style=\"text-align:left;\"> (0.039) </td>\n",
       "   <td style=\"text-align:left;\"> (0.09) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">polviews</span> </td>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">hrs1</span> </td>\n",
       "   <td style=\"text-align:left;\"> -0.352 </td>\n",
       "   <td style=\"text-align:left;\"> -0.35 </td>\n",
       "   <td style=\"text-align:left;\"> -0.392 </td>\n",
       "   <td style=\"text-align:left;\"> -0.397 </td>\n",
       "   <td style=\"text-align:left;\"> -0.007 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.067) </td>\n",
       "   <td style=\"text-align:left;\"> (0.106) </td>\n",
       "   <td style=\"text-align:left;\"> (0.037) </td>\n",
       "   <td style=\"text-align:left;\"> (0.058) </td>\n",
       "   <td style=\"text-align:left;\"> (0.143) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">polviews</span> </td>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">indus80</span> </td>\n",
       "   <td style=\"text-align:left;\"> -0.339 </td>\n",
       "   <td style=\"text-align:left;\"> -0.362 </td>\n",
       "   <td style=\"text-align:left;\"> -0.435 </td>\n",
       "   <td style=\"text-align:left;\"> -0.417 </td>\n",
       "   <td style=\"text-align:left;\"> 0.041 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.053) </td>\n",
       "   <td style=\"text-align:left;\"> (0.055) </td>\n",
       "   <td style=\"text-align:left;\"> (0.064) </td>\n",
       "   <td style=\"text-align:left;\"> (0.046) </td>\n",
       "   <td style=\"text-align:left;\"> (0.11) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">partyid</span> </td>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">educ</span> </td>\n",
       "   <td style=\"text-align:left;\"> -0.41 </td>\n",
       "   <td style=\"text-align:left;\"> -0.385 </td>\n",
       "   <td style=\"text-align:left;\"> -0.408 </td>\n",
       "   <td style=\"text-align:left;\"> -0.398 </td>\n",
       "   <td style=\"text-align:left;\"> -0.015 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.045) </td>\n",
       "   <td style=\"text-align:left;\"> (0.036) </td>\n",
       "   <td style=\"text-align:left;\"> (0.046) </td>\n",
       "   <td style=\"text-align:left;\"> (0.034) </td>\n",
       "   <td style=\"text-align:left;\"> (0.081) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">partyid</span> </td>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">hrs1</span> </td>\n",
       "   <td style=\"text-align:left;\"> -0.393 </td>\n",
       "   <td style=\"text-align:left;\"> -0.397 </td>\n",
       "   <td style=\"text-align:left;\"> -0.39 </td>\n",
       "   <td style=\"text-align:left;\"> -0.403 </td>\n",
       "   <td style=\"text-align:left;\"> -0.009 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.047) </td>\n",
       "   <td style=\"text-align:left;\"> (0.067) </td>\n",
       "   <td style=\"text-align:left;\"> (0.041) </td>\n",
       "   <td style=\"text-align:left;\"> (0.055) </td>\n",
       "   <td style=\"text-align:left;\"> (0.107) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">partyid</span> </td>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">indus80</span> </td>\n",
       "   <td style=\"text-align:left;\"> -0.42 </td>\n",
       "   <td style=\"text-align:left;\"> -0.432 </td>\n",
       "   <td style=\"text-align:left;\"> -0.417 </td>\n",
       "   <td style=\"text-align:left;\"> -0.44 </td>\n",
       "   <td style=\"text-align:left;\"> -0.011 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.043) </td>\n",
       "   <td style=\"text-align:left;\"> (0.065) </td>\n",
       "   <td style=\"text-align:left;\"> (0.038) </td>\n",
       "   <td style=\"text-align:left;\"> (0.073) </td>\n",
       "   <td style=\"text-align:left;\"> (0.113) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">educ</span> </td>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">hrs1</span> </td>\n",
       "   <td style=\"text-align:left;\"> -0.391 </td>\n",
       "   <td style=\"text-align:left;\"> -0.421 </td>\n",
       "   <td style=\"text-align:left;\"> -0.368 </td>\n",
       "   <td style=\"text-align:left;\"> -0.38 </td>\n",
       "   <td style=\"text-align:left;\"> 0.018 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.041) </td>\n",
       "   <td style=\"text-align:left;\"> (0.064) </td>\n",
       "   <td style=\"text-align:left;\"> (0.037) </td>\n",
       "   <td style=\"text-align:left;\"> (0.046) </td>\n",
       "   <td style=\"text-align:left;\"> (0.096) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">educ</span> </td>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">indus80</span> </td>\n",
       "   <td style=\"text-align:left;\"> -0.421 </td>\n",
       "   <td style=\"text-align:left;\"> -0.439 </td>\n",
       "   <td style=\"text-align:left;\"> -0.397 </td>\n",
       "   <td style=\"text-align:left;\"> -0.399 </td>\n",
       "   <td style=\"text-align:left;\"> 0.016 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.067) </td>\n",
       "   <td style=\"text-align:left;\"> (0.048) </td>\n",
       "   <td style=\"text-align:left;\"> (0.052) </td>\n",
       "   <td style=\"text-align:left;\"> (0.083) </td>\n",
       "   <td style=\"text-align:left;\"> (0.128) </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">hrs1</span> </td>\n",
       "   <td style=\"text-align:left;\"> <span style=\" font-weight: bold;    color: black !important;\">indus80</span> </td>\n",
       "   <td style=\"text-align:left;\"> -0.402 </td>\n",
       "   <td style=\"text-align:left;\"> -0.418 </td>\n",
       "   <td style=\"text-align:left;\"> -0.415 </td>\n",
       "   <td style=\"text-align:left;\"> -0.433 </td>\n",
       "   <td style=\"text-align:left;\"> -0.002 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\">  </td>\n",
       "   <td style=\"text-align:left;\"> (0.047) </td>\n",
       "   <td style=\"text-align:left;\"> (0.054) </td>\n",
       "   <td style=\"text-align:left;\"> (0.055) </td>\n",
       "   <td style=\"text-align:left;\"> (0.039) </td>\n",
       "   <td style=\"text-align:left;\"> (0.098) </td>\n",
       "  </tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Little trick to display the standard errors\n",
    "table <- lapply(1:ncol(all_pairs), function(j) {\n",
    "  m <- round(signif(twoway_partial_dependency_tauhats[[j]], digits=4), 3)\n",
    "  diff_in_diff <- round(signif(m[\"Tau Hat\", 4] - m[\"Tau Hat\", 2] - (m[\"Tau Hat\", 3] - m[\"Tau Hat\", 1]), digits=4), 3)\n",
    "  diff_in_diff_se <- round(signif(sqrt(sum(m[\"Std. Error\", ]^2)), digits = 4), 3)\n",
    "  diff_in_diff_se <- paste0(\"(\", diff_in_diff_se, \")\")\n",
    "  m[\"Tau Hat\",] <- as.character(m[\"Tau Hat\",])\n",
    "  m[\"Std. Error\",] <- paste0(\"(\", m[\"Std. Error\",], \")\")\n",
    "  m <- cbind(m, c(diff_in_diff, diff_in_diff_se))\n",
    "  m\n",
    "})\n",
    "table <- do.call(rbind, table)\n",
    "colnames(table) <- c('LL', 'HL', 'LH', 'HH', ' (HH-HL)<br>- (LH-LL)')\n",
    "\n",
    "# Covariate names\n",
    "cov1names <- rep(\"\", nrow(table))\n",
    "cov1names[seq(1, length(cov1names), 2)] <-\n",
    "  cell_spec(all_pairs[1,], format = \"html\", escape = F, color = \"black\", bold = T)\n",
    "cov2names <- rep(\"\", nrow(table))\n",
    "cov2names[seq(1, length(cov2names), 2)] <-\n",
    "  cell_spec(all_pairs[2,], format = \"html\", escape = F, color = \"black\", bold = T)\n",
    "\n",
    "table <- cbind(x1 = cov1names, x2 = cov2names, table)\n",
    "\n",
    "# Title of table\n",
    "caption <- \"The CATE function's value for x1 and x2 evaluated at combinations of 'high' and 'low' (e.g. HL is High-Low with x1 at its 80th percentile, x2 at its 20th percentile). All other covariates are fixed at their medians.\"\n",
    "\n",
    "table %>%\n",
    "  kable(format=\"html\", digits=2, caption=caption, escape = FALSE, row.names = FALSE) %>%\n",
    "  kable_styling(bootstrap_options=c(\"condensed\", \"responsive\"), full_width=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### An omnibus test for heterogeneity (BLP)\n",
    "\n",
    "The function `test.calibration` from the `grf` package evaluates the quality of causal forest estimates using a method that was motivated by [Chernozhukov, Demirer, Duflo, and Fernandez-Val (2018)](https://arxiv.org/abs/1712.04802). The idea is to estimate the best linear predictor of CATE using out-of-bag predictions $\\hat{\\tau}^{-i}(\\cdot)$. In the grf package, the exact implementation seeks to fit the following linear model.\n",
    "\n",
    "$$Y_{i} - \\hat{m}^{-i}(X_{i}) = \\alpha\\bar{\\tau}\\left(W_{i} - \\hat{e}^{-i}(X_{i})\\right) + \\beta \\left(\\hat{\\tau}^{-i}(X_{i}) - \\bar{\\tau} \\right) \\left(W_{i} - \\hat{e}^{-i}(X_{i}) \\right) + \\epsilon  \\qquad \\quad \\bar{\\tau} := \\frac{1}{n}\\sum_{i=1}^{n} \\hat{\\tau}^{-i}(X_{i})$$\n",
    "\n",
    "The coefficients $\\alpha$ and $\\beta$ allow us to evaluate the performance of our estimates. If $\\alpha = 1$, then the average prediction produced by the forest is correct. Meanwhile, if $\\beta = 1$, then the forest predictions adequately capture the underlying heterogeneity.\n",
    "\n",
    "In addition, $\\beta$ is a measure of how the CATE predictions covary with true CATE. Therefore, the p-value on the estimate of coefficient also acts as an omnibus test for the presence of heterogeneity. If the coefficient is significantly greater than zero, then we can reject the null of no heterogeneity. However, coefficients smaller than 0 are not meaningful and show not be interpreted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table class=\"table table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n",
       "<caption>Best linear fit using forest predictions (on held-out data)\n",
       "                      as well as the mean forest prediction as regressors, along\n",
       "                      with heteroskedasticity-robust (HC3) SEs.</caption>\n",
       " <thead>\n",
       "  <tr>\n",
       "   <th style=\"text-align:right;\"> Estimate </th>\n",
       "   <th style=\"text-align:right;\"> Std. Error </th>\n",
       "   <th style=\"text-align:right;\"> t value </th>\n",
       "   <th style=\"text-align:right;\"> Pr(&gt;t) </th>\n",
       "  </tr>\n",
       " </thead>\n",
       "<tbody>\n",
       "  <tr>\n",
       "   <td style=\"text-align:right;\"> 1.000666 </td>\n",
       "   <td style=\"text-align:right;\"> 0.022079 </td>\n",
       "   <td style=\"text-align:right;\"> 45.321325 </td>\n",
       "   <td style=\"text-align:right;\"> 0 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:right;\"> 1.180380 </td>\n",
       "   <td style=\"text-align:right;\"> 0.121010 </td>\n",
       "   <td style=\"text-align:right;\"> 9.754383 </td>\n",
       "   <td style=\"text-align:right;\"> 0 </td>\n",
       "  </tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tc <- test_calibration(cf)\n",
    "\n",
    "caption <- \"Best linear fit using forest predictions (on held-out data)\n",
    "                      as well as the mean forest prediction as regressors, along\n",
    "                      with heteroskedasticity-robust (HC3) SEs.\"\n",
    "table <- as.data.frame(tc[,]) \n",
    "table %>%\n",
    "    kable(format=\"html\", digits=6, caption=caption, escape = FALSE, row.names = FALSE) %>%\n",
    "    kable_styling(bootstrap_options=c(\"condensed\", \"responsive\"), full_width=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## HTE 3: X-learners\n",
    "\n",
    "**Reference:** [Kunzel et al (PNAS, 2019)](https://www.pnas.org/content/pnas/116/10/4156.full.pdf)\n",
    "\n",
    "KÃ¼nzel et al (2018) propose a new meta-algorithm for CATE estimation. The authors begin by noting that many CATE algorithms either separately estimate *two* response functions\n",
    "\n",
    "$$\\mu_1(x) = E[Y| X=x, W=1] \\qquad \\text{and} \\qquad \\mu_0(x) = E[Y|X=x, W=0]$$\n",
    "\n",
    "or include the treatment variable along with the control variables and estimate a *single* function:\n",
    "\n",
    "$$\\mu(w, x) = E[Y(1) | W = w, X=x]$$\n",
    "\n",
    "They call the former class of methods *T-learners* (for \"two\") and the latter one *S-learners* (for \"single\"). Then, they propose an alternative *X-learner* that has the following procedure.\n",
    "\n",
    "1. Use any method to estimate separate response functions $\\hat{\\mu}_1(x)$ and $\\hat{\\mu}_0(x)$.\n",
    "\n",
    "2. Create *imputed individual treatment effects*:\n",
    "\\begin{align}\n",
    "&\\hat{D}_{i,0} = Y_i - \\hat{\\mu}_0(X_i) \\qquad \\text{for all observations in control group} \\\\\n",
    "&\\hat{D}_{i,1} = Y_i - \\hat{\\mu}_1(X_i) \\qquad \\text{for all observations in treatment group}\n",
    "\\end{align}\n",
    "\n",
    "3. Regress imputed treatment effects on covariates to obtain CATE estimates $\\hat{\\tau}_{0}(x)$ and $\\hat{\\tau}_1(x)$\n",
    "\n",
    "4. Take a weighted average of the CATE estimates\n",
    "$$\\hat{\\tau}(x) = \\hat{g}(x)\\hat{\\tau}_0(x) + [1-\\hat{g}(x)]\\hat{\\tau}_1(x)$$\n",
    "where $g$ is a function mapping to unit interval, typically chosen to be the propensity score.\n",
    "\n",
    "The motivation is that a  *S-learner* works well when one of the treatment groups is much larger than the other because it pools information about both groups. However, the *S-learner* might also choose to ignore information about the treatment, if the signal from the outcome model is overwhelmingly strong. For example, if we had fitted one regression forest on $(X, W)$, most trees might end up not splitting on $W$. This ends up biasing the CATE to zero since the resulting estimated function will be constant in $w$. In this case, a *T-learner* would do better. The authors claim that their meta-algorithm can ameliorate both of these disadvantages by the \"crossing\" technique (hence the name *X-learner*) shown in the second bullet point above.\n",
    "\n",
    "#### STEP 1: Fit the X-learner\n",
    "\n",
    "To fit an X-learner, we can use the `X_RF` function from the `causalToobox` package. The `_RF` represents the choice of  *random forests* as our base learner, but the package also contains an implementation that uses BARTs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl <- X_RF(\n",
    "  feat = as.data.frame(df_train[covariate_names]),\n",
    "  tr = df_train$W,\n",
    "  yobs = df_train$Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### STEP 2: Predict point estimates\n",
    "\n",
    "The function `EstimateCate` provides point estimates. To predict on a test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "tauhat_xl_test <- EstimateCate(xl, df_test[covariate_names])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### STEP 3: Compute confidence intervals\n",
    "\n",
    "Confidence intervals are computed via bootstrap. The parameter `B` controls the number of bootstrap samples. Here we will use a very low `B` for illustration, but in a real application this number should be appropriately high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commented out because it takes a long time to run\n",
    "# tauhat_xl_test_ci <- CateCI(xl, df_test[covariate_names], B=5)  # Increase B for more accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Comparing predictions\n",
    "\n",
    "We want to compare how well our methods performed regarding prediction error. However, we are immediately faced with the challenge that we do not observe the true treatment effects. However, let's define the following Transformed Outcome:\n",
    "\n",
    "\\begin{align}\n",
    "Y_i^{*} &:=\n",
    "\\begin{cases}\n",
    "\\frac{1}{p}Y_i \\qquad &\\text{if} \\qquad W_i = 1 \\\\\n",
    "\\frac{-1}{1-p}Y_i \\qquad &\\text{if} \\qquad W_i = 0\n",
    "\\end{cases} \\\\\n",
    "&= \\frac{W_i-p}{p(1-p)}Y_i\n",
    "\\end{align}\n",
    "\n",
    "where $p = P(W = 1)$. This is actually a high-variance unbiased estimator of the true individual treatment effect, since\n",
    "\n",
    "\\begin{align}\n",
    "E[Y_i^{*}] &= P(W=1)E[Y_i^{*}|W=1] + P(W=0)E[Y_i^{*}|W=0] \\\\\n",
    "&= pE\\left[\\frac{1}{p}Y_i|W=1 \\right] + (1-p)E \\left[\\frac{-1}{1-p}Y_i|W=0 \\right] \\\\\n",
    "&= pE\\left[\\frac{1}{p}Y_i(1) \\right] + (1-p) E \\left[\\frac{-1}{1-p}Y_i(0) \\right] \\\\\n",
    "&= E[Y_i(1) - Y_i(0)] \\\\\n",
    "&= E[\\tau_i]\n",
    "\\end{align}\n",
    "\n",
    "<font size=2>\n",
    "<b>Note</b> The third equality worked here because we are using a randomized experiment, but it would have worked out as well in a scenario with unconfoundedness provided that we used the propensity scores $p(x) = P(W = 1 | X= x)$ instead of $p$, provided they are bounded away from zero.\n",
    "</font>\n",
    "\n",
    "In expectation, the squared distance between $Y_i^*$ and our prediction $\\hat\\tau(X_i)$ can be used to compare our estimators' mean square error. This is because of the following.\n",
    "\n",
    "\\begin{align}\n",
    "E[(Y_i^{*} - \\hat{\\tau}(X_i))^2]\n",
    "&=   E[(Y_i^{*} - \\tau_i + \\tau_i - \\hat{\\tau}(X_i))^2] \\\\\n",
    "&=   E[(Y_i^{*} - \\tau_i)^2] + E[(\\tau_i - \\hat{\\tau}(X_i))^2]\n",
    "+ 2E[(Y_i^{*} - \\tau_i)(\\tau_i - \\hat{\\tau}(X_i))]\\\\\n",
    "&= const +  E[(\\tau_i - \\hat{\\tau}(X_i))^2]  + 0\n",
    "\\end{align}\n",
    "\n",
    "Where the first term in the last equality is a constant with respect to $\\hat{\\tau}$, so it gets canceled out when we take the difference between two estimators' performance measures. Consequently, we can compare the different methods by performing hypothesis testing on the MSE against $Y_i^{*}$. We include the traditional sample average treatment effect as a benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table class=\"table table-striped table-hover table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n",
       "<caption>Estimate loss: comparison across methods</caption>\n",
       " <thead>\n",
       "  <tr>\n",
       "   <th style=\"text-align:left;\">   </th>\n",
       "   <th style=\"text-align:right;\"> mean </th>\n",
       "   <th style=\"text-align:right;\"> se </th>\n",
       "  </tr>\n",
       " </thead>\n",
       "<tbody>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> Sample_ATE_Loss </td>\n",
       "   <td style=\"text-align:right;\"> 1.00599 </td>\n",
       "   <td style=\"text-align:right;\"> 0.02921 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> Causal_Tree_Loss </td>\n",
       "   <td style=\"text-align:right;\"> 1.00348 </td>\n",
       "   <td style=\"text-align:right;\"> 0.02948 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> Causal_Forest_Loss </td>\n",
       "   <td style=\"text-align:right;\"> 0.99822 </td>\n",
       "   <td style=\"text-align:right;\"> 0.02938 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> X_Learner_Loss </td>\n",
       "   <td style=\"text-align:right;\"> 0.99830 </td>\n",
       "   <td style=\"text-align:right;\"> 0.02954 </td>\n",
       "  </tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute Y-star\n",
    "p <- mean(df_test$W)\n",
    "Y_star <- ((df_test$W - p)/(p*(1-p)))*df_test$Y\n",
    "\n",
    "# Compute the sample average treatment effect to use as a baseline comparison\n",
    "tauhat_sample_ate <- with(df_train, mean(Y[W==1]) - mean(Y[W==0]))\n",
    "\n",
    "# Compute test mse for all methods\n",
    "mse <- data.frame(\n",
    "  Sample_ATE_Loss = (Y_star - tauhat_sample_ate)^2,\n",
    "  Causal_Tree_Loss = (Y_star - tauhat_ct_test)^2,\n",
    "  Causal_Forest_Loss = (Y_star - tauhat_cf_test)^2,\n",
    "  X_Learner_Loss = (Y_star - tauhat_xl_test)^2)\n",
    "\n",
    "mse_summary <- describe(mse)[, c('mean', 'se')]\n",
    "\n",
    "kable_styling(kable(mse_summary,  \"html\", digits = 5,\n",
    "                                       caption=\"Estimate loss: comparison across methods\"),\n",
    "                          bootstrap_options=c(\"striped\", \"hover\", \"condensed\", \"responsive\"),\n",
    "                          full_width=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, another way to compare models is via the R-loss. In particular, if $Y_i = m(X_i) + (W_i-e(X_i))\\tau(X_i) + \\epsilon_i$ where $E[\\epsilon_i^2]=\\sigma^2$ and $E[\\epsilon_i] =0$, then\n",
    "\\begin{align}\n",
    "E[(Y_i^{*} - m(X_i) - (W_i - e(X_i) \\hat{\\tau}(X_i))^2] &= E[(W_i-e(X_i))(\\tau(X_i) - \\hat{\\tau}(X_i))^2] + \\sigma^2 \\\\\n",
    "&= E[e(X_i)(1-e(X_i)) (\\tau(X_i) - \\hat{\\tau}(X_i))^2] + \\sigma^2\n",
    "\\end{align}\n",
    "where the last equality follows from conditioning on $X_i$.\n",
    "\n",
    "We see that using the R-loss for model comparison, we would be minimizing $E[e(X_i)(1-e(X_i)) (\\tau(X_i) - \\hat{\\tau}(X_i))^2]$, which is a weighted mean-squared error (MSE) on $\\hat{\\tau}(X_i)$. This weighted MSE gives higher weights to datapoints that have good overlap (e.g. $e(X_i)$ close to 0.5), which can be helpful when there is poor overlap in the data, or when the policymakers cares most about the treatment effect estimation on the population that is most on the boundary between receiving treatment and not receiving treatment. Compared to using the Transformed Outcome approach, using the R-loss is more stable since we do not need to divide by propensity weights, but gives a biased estimate of the overall MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table class=\"table table-striped table-hover table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n",
       "<caption>Estimate loss: comparison across methods</caption>\n",
       " <thead>\n",
       "  <tr>\n",
       "   <th style=\"text-align:left;\">   </th>\n",
       "   <th style=\"text-align:right;\"> mean </th>\n",
       "   <th style=\"text-align:right;\"> se </th>\n",
       "  </tr>\n",
       " </thead>\n",
       "<tbody>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> Sample_ATE_Loss </td>\n",
       "   <td style=\"text-align:right;\"> 0.16181 </td>\n",
       "   <td style=\"text-align:right;\"> 0.00358 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> Causal_Tree_Loss </td>\n",
       "   <td style=\"text-align:right;\"> 0.16164 </td>\n",
       "   <td style=\"text-align:right;\"> 0.00367 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> Causal_Forest_Loss </td>\n",
       "   <td style=\"text-align:right;\"> 0.16029 </td>\n",
       "   <td style=\"text-align:right;\"> 0.00365 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> X_Learner_Loss </td>\n",
       "   <td style=\"text-align:right;\"> 0.16057 </td>\n",
       "   <td style=\"text-align:right;\"> 0.00373 </td>\n",
       "  </tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y.forest.test = regression_forest(X = as.matrix(df_test[covariate_names]), Y = df_test$Y)\n",
    "Y.hat.test = predict(Y.forest.test)$predictions\n",
    "W.forest.test = regression_forest(X = as.matrix(df_test[covariate_names]), Y = df_test$W)\n",
    "W.hat.test = predict(W.forest.test)$predictions\n",
    "\n",
    "mse_rloss <- data.frame(\n",
    "  Sample_ATE_Loss = (df_test$Y - Y.hat.test - (df_test$W - W.hat.test) * tauhat_sample_ate)^2,\n",
    "  Causal_Tree_Loss = (df_test$Y - Y.hat.test - (df_test$W - W.hat.test) * tauhat_ct_test)^2,\n",
    "  Causal_Forest_Loss = (df_test$Y - Y.hat.test - (df_test$W - W.hat.test) * tauhat_cf_test)^2,\n",
    "  X_Learner_Loss = (df_test$Y - Y.hat.test - (df_test$W - W.hat.test) * tauhat_xl_test)^2)\n",
    "\n",
    "mse_rloss_summary <- describe(mse_rloss)[, c('mean', 'se')]\n",
    "\n",
    "kable_styling(kable(mse_rloss_summary,  \"html\", digits = 5,\n",
    "                                       caption=\"Estimate loss: comparison across methods\"),\n",
    "                          bootstrap_options=c(\"striped\", \"hover\", \"condensed\", \"responsive\"),\n",
    "                          full_width=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Policy evaluation and learning\n",
    "\n",
    "**Reference:** [Athey and Wager (2018, ArXiv)](https://arxiv.org/pdf/1702.02896.pdf)\n",
    "\n",
    "The reason we care about treatment effect heterogeneity is that we would like to assign the correct treatment to each individual or subpopulation. For example, a costly get-out-the-vote campaign should send mailings only to those most susceptible to it. Similarly, in the context of personalized medicine, a doctor would like to know whether to prescribe a treatment only if she expects it to improve her patient's condition. Or yet, in the advertising business, a company could save a lot of money by targeting users who are likely to purchase their product.\n",
    "\n",
    "More formally, we would like to select a function $\\pi$ that maps observed characteristics to an available treatment. Such a function is called a **policy**.\n",
    "$$\\pi : X_i \\mapsto W_i$$\n",
    "In this section, you will see how to evaluate binary policies $\\pi: X_i \\mapsto \\{0,1\\}$ (indicating treatment $(1)$ or no treatment $(0)$). Let's begin by defining the **value** of a policy $V(\\pi)$ as the benefit of applying it over treating no one.\n",
    "\n",
    "$$\n",
    "V(\\pi) = E[\\pi(X_{i})\\tau(X_{i})]\n",
    "$$\n",
    "\n",
    "For example, the value of the of policy that assigns everyone to treatment is $V(\\pi_{always-treat}) = E[\\tau(X_{i})]$. Similarly, the value of a *random* policy that assigns each person to treatment and non-treatment status with equal probability is\n",
    "\n",
    "$$V(\\pi_{random}) = \\frac{1}{2}E[\\tau(X_{i})] + \\frac{1}{2}0 =  \\frac{1}{2}E[\\tau(X_{i})]$$\n",
    "\n",
    "As we will see later, when evaluating arbitrary policies $\\pi$ it will be often convenient to work with the *improvement* over the random policy (scaled by two for convenience). The improvement $A(\\pi)$ can be written as\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "A(\\pi) &= 2\\big(V(\\pi) - V(\\pi_{random})\\big) \\\\ \n",
    "&= 2\\big(E[\\pi(X_i)\\tau(X_i)] - \\frac{1}{2}E[\\tau(X_i)]\\big)  \\\\\n",
    "&= 2E\\big[\\tau(X_i) | \\pi(X_i) = 1\\big] P\\big(\\pi(X_i) = 1\\big) - \\Big(E\\big[\\tau(X_i) | \\pi(X_i) = 1 \\big] P\\big(\\pi(X_i) = 1\\big) + E\\big[\\tau(X_i) | \\pi(X_i) = 0 \\big] P\\big(\\pi(X_i) = 0 \\big) \\\\\n",
    "&= E\\big[\\tau(X_i) | \\pi(X_i) = 1\\big] P\\big(\\pi(X_i) = 1\\big) - E\\big[\\tau(X_i) | \\pi(X_i) = 0 \\big] P\\big(\\pi(X_i) = 0 \\big) \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "We see that this is a weighted difference of the average treatment effect for those assigned treatment minus the ATE for those assigned no treatment. \n",
    "\n",
    "Often there is a fixed cost $C$ associated with treatment. In that case, the value of a policy is \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "V(\\pi)\n",
    "&=E[\\pi(X_{i})\\left( \\tau(X_{i}) - C \\right)] \\\\\n",
    "&=E[\\pi(X_{i}) \\tau(X_{i})] - P(\\pi(X_{i}) = 1)\\cdot C\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "And similarly the improvement over the random policy can be shown to be\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "A(\\pi) &=  E\\big[\\tau(X_i) | \\pi(X_i) = 1\\big] P\\big(\\pi(X_i) = 1\\big) - E\\big[\\tau(X_i) | \\pi(X_i) = 0 \\big] P\\big(\\pi(X_i) = 0 \\big) - \\left( 2P(\\pi(X_{1})=1) - 1 \\right) C\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Ultimately, our goal is to find policies of large value. If one had access to the true CATE functions, then the best policy would be the following.\n",
    "\n",
    "$$\n",
    "\\pi_{optimal}(X_{i}) =\n",
    "  \\begin{cases}\n",
    "  1 \\qquad \\text{if} \\quad \\tau(x) \\geq C \\\\\n",
    "  0 \\qquad \\text{otherwise}\n",
    "  \\end{cases}\n",
    "$$\n",
    "\n",
    "Having defined these population objects, in the next section we'll discuss how to estimate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "n <- dim(df)[1]\n",
    "random_idx <- sample.int(n, size=floor(n/2), replace=F)\n",
    "df_train <- df[random_idx,]\n",
    "df_test <- df[-random_idx,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating policies in randomized control trials\n",
    "\n",
    "As we have seen in the introduction above, the benefit of any policy $\\pi$ depends only on four quantities: the fraction of people who are assigned to treatment and control, and the average treatment effect in each of these subgroups.\n",
    "\n",
    "Let's see how to estimate each of these quantities in randomized control trials, for policies that do not depend on the data (i.e. they are either given to us, or were fitted using sample splitting). For convenience, let's define $G^{1}_{\\pi}$ and $G^{0}_{\\pi}$ the observations that would be treated or not under this policy (i.e., $G^{w}_{\\pi} = \\{i: \\pi(X_{i}) = w\\}$), and let $q_{\\pi}^w$ be the proportion of people in $G^w_\\pi$. Also, denote by $S^{1}$ and $S^{0}$ the set of observations that were assigned to treatment and control during the experiment (i.e., $S^{w} := \\{ i: W_{i}=w \\}$).\n",
    "\n",
    "Now, because the treatment assignment was completely at random, the estimate of the average treatment effect in a particular subgroup is $G^{w}_{\\pi}$ is simply a difference of sample averages.\n",
    "\n",
    "$$\\widehat{ATE}(G^{w}_{\\pi}) := \\frac{1}{|G^{w}_{\\pi} \\cap S^{1}|}\\sum_{i\\in G^{w}_{\\pi} \\cap S^{1}} Y_{i}  -  \\frac{1}{|G^{w}_{\\pi} \\cap S^{0}|}\\sum_{i\\in G^{w}_{\\pi} \\cap S^{0}} Y_{i} \\qquad \\text{for } w\\in \\{0, 1\\}$$\n",
    "\n",
    "Therefore, we can estimate the benefit of any honesty policy $\\pi$ via the following expression.\n",
    "\n",
    "$$\\hat{A}(\\pi) = q_{\\pi}^{1} \\times \\widehat{ATE}(G^{w}_{\\pi}) - q_{\\pi}^{0} \\times \\widehat{ATE}(G^{0}_{\\pi})$$\n",
    "Or, under a fixed treatment cost $C$,\n",
    "\n",
    "$$\\hat{A}(\\pi) = q_{\\pi}^{1} \\cdot \\widehat{ATE}(G^{w}_{\\pi}) - q_{\\pi}^{0} \\cdot \\widehat{ATE}(G^{0}_{\\pi}) - \n",
    "(2 \\cdot q_{\\pi}^{1} - 1) \\cdot C\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "Let's use this formula to evaluate a policy. In particular, we will be interested in evaluating the $\\pi_{optimal}$ policy discussed earlier. Naturally, we do not have access to the true CATE function $\\tau(x)$, but we estimate it using sample splitting, then we can form a **plug-in policy** as follows.\n",
    "\n",
    "$$\n",
    "\\hat{\\pi}_{plugin}(X_{i}) =\n",
    "  \\begin{cases}\n",
    "  1 \\qquad \\text{if} \\quad \\hat{\\tau}^{(-i)}(x) \\geq C \\\\\n",
    "  0 \\qquad \\text{otherwise}\n",
    "  \\end{cases}\n",
    "$$\n",
    "\n",
    "The superscript $-i$ is a reminder that the estimate for observation $i$ cannot have been fit using data from that observation. Because we are using causal forests below, this is achieved by using the *out-of-bag* estimates. Alternatively, if we were using a different model, we could also consider using cross-fitting.\n",
    "\n",
    "The following code snippet computes this quantity and its standard error for a plug-in policy estimated using causal forests. In a real-world application, we would subtract the true cost of the treatment $C$. Here, for illustration, we calibrate the cost to be equal to the median out-of-bag CATE estimates. This ensures that some part of the population should be treated and some should not, so the resulting policy is nontrivial. \n",
    "\n",
    "The code is similar if we are computing over the test set or for other policies, so we won't display repeated code here (please check the RMarkdown source for details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimating E[Y(1) - Y(0)|X=x] for plug in policy\n",
    "tau.forest <- causal_forest(X=df_train[,covariate_names], Y=df_train$Y, W=df_train$W)\n",
    "tau.hat.train <- predict(tau.forest)$predictions # OOB predictions!\n",
    "tau.hat.test <- predict(tau.forest, newdata=df_test[,covariate_names])$predictions\n",
    "\n",
    "# Define cost to be median OOB CATE\n",
    "cost <- median(tau.hat.train)\n",
    "\n",
    "# Compute plug-in policy considering costs\n",
    "df_train$pi.plugin <- as.numeric(tau.hat.train > cost)\n",
    "df_test$pi.plugin <- as.numeric(tau.hat.test > cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plugin policy, on the train set\n",
    "y_g1s1 <- df_train[(df_train$W == 1) & (df_train$pi.plugin == 1), \"Y\"]\n",
    "y_g1s0 <- df_train[(df_train$W == 0) & (df_train$pi.plugin == 1), \"Y\"]\n",
    "y_g0s1 <- df_train[(df_train$W == 1) & (df_train$pi.plugin == 0), \"Y\"]\n",
    "y_g0s0 <- df_train[(df_train$W == 0) & (df_train$pi.plugin == 0), \"Y\"]\n",
    "\n",
    "ate_g1 <- mean(y_g1s1) - mean(y_g1s0) \n",
    "ate_g0 <- mean(y_g0s1) - mean(y_g0s0)\n",
    "\n",
    "var_ate_g1 <- var(y_g1s1)/length(y_g1s1) + var(y_g1s0)/length(y_g1s0)\n",
    "var_ate_g0 <- var(y_g0s1)/length(y_g0s1) + var(y_g0s0)/length(y_g0s0)\n",
    "\n",
    "q1 <- mean(df_train$pi.plugin == 1)\n",
    "q0 <- mean(df_train$pi.plugin == 0)\n",
    "\n",
    "# Plugin policy vs random policy on training set\n",
    "value_train_plugin_vs_random_mean <- q1 * ate_g1 - q0 * ate_g0 - (2*q1 - 1)*cost\n",
    "value_train_plugin_vs_random_stderr <- sqrt(q1^2 * var_ate_g1 + q0^2 * var_ate_g0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plugin policy, on the test set\n",
    "y_g1s1 <- df_test[(df_test$W == 1) & (df_test$pi.plugin == 1), \"Y\"]\n",
    "y_g1s0 <- df_test[(df_test$W == 0) & (df_test$pi.plugin == 1), \"Y\"]\n",
    "y_g0s1 <- df_test[(df_test$W == 1) & (df_test$pi.plugin == 0), \"Y\"]\n",
    "y_g0s0 <- df_test[(df_test$W == 0) & (df_test$pi.plugin == 0), \"Y\"]\n",
    "\n",
    "ate_g1 <- mean(y_g1s1) - mean(y_g1s0) \n",
    "ate_g0 <- mean(y_g0s1) - mean(y_g0s0)\n",
    "\n",
    "var_ate_g1 <- var(y_g1s1)/length(y_g1s1) + var(y_g1s0)/length(y_g1s0)\n",
    "var_ate_g0 <- var(y_g0s1)/length(y_g0s1) + var(y_g0s0)/length(y_g0s0)\n",
    "\n",
    "q1 <- mean(df_test$pi.plugin == 1)\n",
    "q0 <- mean(df_test$pi.plugin == 0)\n",
    "\n",
    "# Plugin policy vs random policy on test set\n",
    "value_test_plugin_vs_random_mean <- q1 * ate_g1 - q0 * ate_g0 - (2*q1 - 1)*cost\n",
    "value_test_plugin_vs_random_stderr <- sqrt(q1^2 * var_ate_g1 + q0^2 * var_ate_g0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table class=\"table table-striped table-hover table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n",
       "<caption>Sample ATE estimated benefit of using plug-in policy vs random on training and test sets</caption>\n",
       " <thead>\n",
       "  <tr>\n",
       "   <th style=\"text-align:left;\">   </th>\n",
       "   <th style=\"text-align:right;\"> A.hat </th>\n",
       "   <th style=\"text-align:right;\"> se </th>\n",
       "  </tr>\n",
       " </thead>\n",
       "<tbody>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> plugin.perf.train </td>\n",
       "   <td style=\"text-align:right;\"> 0.05282 </td>\n",
       "   <td style=\"text-align:right;\"> 0.01014 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> plugin.perf.test </td>\n",
       "   <td style=\"text-align:right;\"> 0.05636 </td>\n",
       "   <td style=\"text-align:right;\"> 0.01026 </td>\n",
       "  </tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table <- data.frame(\n",
    "  A.hat = c(value_train_plugin_vs_random_mean, value_test_plugin_vs_random_mean),\n",
    "  se = c(value_train_plugin_vs_random_stderr, value_test_plugin_vs_random_stderr))\n",
    "rownames(table) <- c(\"plugin.perf.train\", \"plugin.perf.test\")\n",
    "table %>%\n",
    "  kable(format=\"html\", digits = 5, caption=\"Sample ATE estimated benefit of using plug-in policy vs random on training and test sets\") %>%\n",
    "  kable_styling(bootstrap_options=c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating policies via doubly robust scores\n",
    "\n",
    "In the last subsection, we saw how to estimate the value of policies in randomized control trials. Now, we will see an alternative estimate that is valid both RCTs and observational studies. Let's begin by noting that the improvement yielded by policy $\\pi$ over the random policy can also be written as\n",
    "\n",
    "$$\n",
    "A(\\pi) = 2V(\\pi) - 2V(\\pi_{random}) = E[2\\pi(X_i)\\tau(X_i)] - E[\\tau(X_{i})] = E[(2\\pi(X_{i}) - 1)\\tau(X_{i})]\n",
    "$$\n",
    "\n",
    "In Athey and Wager (2017), the authors show that, provided that the treatment assignment is unconfounded and the overlap assumption is satisfied, one can contruct the following estimate of the improvement\n",
    "\n",
    "$$\n",
    "\\hat{A}(\\pi) = \\frac{1}{n}\\sum_{i} \\left(2\\pi(X_{i}) - 1 \\right)\\hat{\\Gamma}_{i}\n",
    "$$\n",
    "where the $\\hat{\\Gamma}_{i}$ objects are **doubly robust scores** of the treatment effect\n",
    "\n",
    "\n",
    "$$\n",
    "  \\hat{\\Gamma}_{i} =\n",
    "  \\hat{\\tau}^{(-i)}(X_{i}) + \\frac{W_{i} -\n",
    "    \\hat{e}^{(-i)}(X_{i})}{\\hat{e}^{(-i)}(X_{i}) \\left(1 - \\hat{e}^{(-i)}(X_{i}) \\right)}\n",
    "    \\left( Y_{i} - \\hat{\\mu}^{(-i)}_{W_{i}}  \\right)\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "where $\\hat{\\tau}(\\cdot)$ are the pointwise estimates of the treatment effect, $\\hat{e}(\\cdot)$ are estimates of the propensity score $P(W_{i}=1|X_{i})$, and $\\hat{\\mu}_{0}, \\hat{\\mu}_{1}$ are estimates of $E[Y|X_{i},W_{i}=0]$ and $E[Y|X_{i},W_{i}=1]$. Again, the superscripts $-i$ indicate that the estimate for observation $i$ cannot have been fit using data from that observation (e.g. using *out-of-bag* estimates from causal and regression forests).\n",
    "\n",
    "The advantages of using doubly robust scores are technical and twofold. First, they provide a guarantee against model misspecification: if the outcome model $\\hat{\\mu}_{w}$ *or* the propensity score model $\\hat{e}$ is correctly specified, the average of the doubly-robust scores is a consistent estimation or the average treatment effect. Second, their average also achieves the semi-parametric lower bound as an estimate of the average treatment effect. This semiparametric efficiency translates into provable theoretical guarantees on the performance of the optimal estimated policy.\n",
    "\n",
    "\n",
    "#### Step 1: Estimate the doubly robust scores \n",
    "\n",
    "Estimating the $\\hat{\\Gamma}_{i}$ objects as defined above on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimating E[Y|X=x]\n",
    "Y.forest <- regression_forest(df_train[,covariate_names], df_train$Y)\n",
    "Y.hat <- predict(Y.forest)$predictions # OOB predictions!\n",
    "\n",
    "# Estimating E[W|X=x]\n",
    "W.forest <- regression_forest(df_train[,covariate_names], df_train$W)\n",
    "W.hat <- predict(W.forest)$predictions # OOB predictions!\n",
    "\n",
    "# Estimation of E[Y(1) - Y(0)|X=x] completed in previous section\n",
    "## tau.forest <- causal_forest(df_train[,covariate_names], df_train$Y, df_train$W, Y.hat = Y.hat, W.hat = W.hat)\n",
    "## tau.hat.train <- predict(tau.forest)$predictions # OOB predictions!\n",
    "## tau.hat.test <- predict(tau.forest, newdata=df_test[,covariate_names])$predictions\n",
    "\n",
    "# Estimating E[Y|X=x, W=0] and E[Y|X=x, W=1]\n",
    "mu.hat.0 <- Y.hat - W.hat * tau.hat.train\n",
    "mu.hat.1 <- Y.hat + (1 - W.hat) * tau.hat.train\n",
    "\n",
    "# Computing doubly-robust scores\n",
    "resid <- df_train$Y - df_train$W * mu.hat.1 - (1 - df_train$W) * mu.hat.0\n",
    "weights <- (df_train$W - W.hat) / (W.hat * (1 - W.hat))\n",
    "\n",
    "Gamma.hat.train <- tau.hat.train + weights * resid\n",
    "\n",
    "# We subtract the cost defined in the previous section\n",
    "Gamma.hat.train.net <- Gamma.hat.train - cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's do the same for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimating E[Y|X=x] on test set\n",
    "Y.hat.test <- predict(Y.forest, newdata=df_test[,covariate_names])$predictions\n",
    "# Estimating E[W|X=x] on test set\n",
    "W.hat.test <- predict(W.forest, newdata=df_test[,covariate_names])$predictions\n",
    "\n",
    "# Estimating E[Y|X=x, W=0] and E[Y|X=x, W=1]\n",
    "mu.hat.0.test <- Y.hat.test - W.hat.test * tau.hat.test\n",
    "mu.hat.1.test <- Y.hat.test + (1 - W.hat.test) * tau.hat.test\n",
    "\n",
    "# Computing doubly-robust scores\n",
    "resid.test <- df_test$Y - df_test$W * mu.hat.1.test - (1 - df_test$W) * mu.hat.0.test\n",
    "weights.test <- (df_test$W - W.hat.test) / (W.hat.test * (1 - W.hat.test))\n",
    "\n",
    "Gamma.hat.test <- tau.hat.test + weights.test * resid.test\n",
    "Gamma.hat.test.net <- Gamma.hat.test - cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Estimate improvement over random policy\n",
    "\n",
    "Let's evaluate a plug-in policy that assigns treatments as long as they are above our cost threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plug-in policy assignments\n",
    "plugin.assignment.train <- 2*as.numeric(tau.hat.train > cost) - 1\n",
    "plugin.assignment.test <- 2*as.numeric(tau.hat.test > cost) - 1\n",
    "\n",
    "A.pi.train <- plugin.assignment.train*Gamma.hat.train.net\n",
    "A.pi.test <- plugin.assignment.test*Gamma.hat.test.net\n",
    "\n",
    "plugin.perf.train <- describe(A.pi.train)[c(\"mean\", \"se\")]\n",
    "plugin.perf.test <- describe(A.pi.test)[c(\"mean\", \"se\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table class=\"table table-striped table-hover table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n",
       "<caption>Doubly robust estimates of benefit of plug-in over random policy on training and test sets</caption>\n",
       " <thead>\n",
       "  <tr>\n",
       "   <th style=\"text-align:left;\">   </th>\n",
       "   <th style=\"text-align:right;\"> A.hat </th>\n",
       "   <th style=\"text-align:right;\"> se </th>\n",
       "  </tr>\n",
       " </thead>\n",
       "<tbody>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> plugin.perf.train </td>\n",
       "   <td style=\"text-align:right;\"> 0.05370 </td>\n",
       "   <td style=\"text-align:right;\"> 0.01001 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> plugin.perf.test </td>\n",
       "   <td style=\"text-align:right;\"> 0.05748 </td>\n",
       "   <td style=\"text-align:right;\"> 0.01007 </td>\n",
       "  </tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dr.plugin.A.hat <- data.frame(\n",
    "  rbind(plugin.perf.train = plugin.perf.train,\n",
    "        plugin.perf.test = plugin.perf.test))\n",
    "\n",
    "colnames(dr.plugin.A.hat) <- c(\"A.hat\", \"se\")\n",
    "\n",
    "dr.plugin.A.hat %>%\n",
    "  kable(\"html\", digits = 5, caption=\"Doubly robust estimates of benefit of plug-in over random policy on training and test sets\") %>%\n",
    "  kable_styling(bootstrap_options=c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Learning Optimal Policies\n",
    "\n",
    "While the plug-in policy is natural and sensible, it suffers from the disadvantage of not imposing any additional structure on the policy class. In real life applications, there may be several reasons to require that the policy belong to a restricted class of policies $\\Pi$. For example:\n",
    "\n",
    "+ From an ethical standpoint, some variables such as gender or race should not be used to determine the treatment allocation\n",
    "+ For auditing purposes, interpretability and functional form simplicity could be important\n",
    "+ For technical reasons, because complex policies do not have performance guarantees\n",
    "\n",
    "In this section, we will discuss how to learn an optimal policy in a restricted class $\\Pi$. Using the doubly robust scores defined previously, we seek to find a $\\pi \\in \\Pi$ that maximizes the objective function\n",
    "\n",
    "$$\n",
    "\\hat{A}(\\pi) = \\frac{1}{n}\\sum_{i} (2\\pi(X_{i}) - 1)\\hat{\\Gamma}_{i}\n",
    "$$\n",
    "\n",
    "We can transform the maximization criterion above into a classification problem. To see why this is so, note that we can decompose each doubly robust score as\n",
    "\n",
    "$$\\hat{\\Gamma}_i = |\\hat{\\Gamma}_i| \\cdot \\text{sign}(\\hat{\\Gamma}_i)$$\n",
    "\n",
    "Therefore, our optimization problem is equivalent to maximizing the weighted correlation between the (transformed) assignment rule $(2\\pi(X_i)-1) \\in \\{ +1, -1\\}$ and the sign of its estimated effect $sign(\\hat{\\Gamma}_i) \\in \\{ +1, -1\\}$. Note that individuals who respond very strongly to the treatment so that $|\\hat{\\Gamma}_{i}| \\gg 0$ will receive larger weights.\n",
    "\n",
    "The upshot of this is that we can use any classification algorithm to find a desired policy. For example, the code below uses the `evtree` package to fit a globally optimal tree on depth 3.\n",
    "\n",
    "**Important remark** The policy below is was fit on the training set, and will therefore overfit on it, causing our estimate $\\hat{A}(\\pi)$ to be generally be biased upwards on the training set. However, because we held out a test set, that estimate will be valid. \n",
    "\n",
    "<font size=2>\n",
    "It is possible to estimate an optimal policy and evaluate it on the same dataset using cross-fitting, but we do not pursue that in this tutorial. Some extra care would need to be taken when interpreting standard errors (see paper for details).\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataframe\n",
    "df_aug <- df_train\n",
    "\n",
    "# Add sign of gamma (denoted Z) and absolute value of gamma (denoted lambda)\n",
    "df_aug$label <- factor(sign(Gamma.hat.train.net))\n",
    "df_aug$weights <- abs(Gamma.hat.train.net)\n",
    "\n",
    "fmla <- as.formula(paste0(\"label ~ \", paste0(covariate_names, collapse = \" + \")))\n",
    "\n",
    "opt_policy_tree <- evtree::evtree(formula = fmla, \n",
    "                                  data = df_aug,\n",
    "                                  control=evtree.control(maxdepth=3,\n",
    "                                                         minbucket=0.025*100*sum(df_aug$weights),\n",
    "                                                         minsplit=0.075*100*sum(df_aug$weights),\n",
    "                                                         niterations=1000,\n",
    "                                                         ntrees=100),\n",
    "                                  weights=round(100*df_aug$weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted party:\n",
      "[1] root\n",
      "|   [2] sex < 2\n",
      "|   |   [3] indus80 < 472\n",
      "|   |   |   [4] polviews < 4: 1 \n",
      "|   |   |   [5] polviews >= 4: -1 \n",
      "|   |   [6] indus80 >= 472\n",
      "|   |   |   [7] partyid < 6: 1 \n",
      "|   |   |   [8] partyid >= 6: -1 \n",
      "|   [9] sex >= 2\n",
      "|   |   [10] polviews < 4\n",
      "|   |   |   [11] indus80 < 632: -1 \n",
      "|   |   |   [12] indus80 >= 632: 1 \n",
      "|   |   [13] polviews >= 4\n",
      "|   |   |   [14] race < 2: -1 \n",
      "|   |   |   [15] race >= 2: 1 \n",
      "\n",
      "Number of inner nodes:    7\n",
      "Number of terminal nodes: 8"
     ]
    }
   ],
   "source": [
    "# The values of 'n' make no sense. Removing them from the string.\n",
    "s <- capture.output(print(opt_policy_tree))\n",
    "str <- sapply(s[9:length(s)], function(x) gsub(\"\\\\(n = [0-9A-Za-z].*\", \"\", x))\n",
    "cat(paste(str, collapse=\"\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Use the `predict` method to retrieve the best policy assignment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict optimal assignment\n",
    "opt.assignment.train <- as.numeric(as.character(predict(opt_policy_tree, newdata = df_train, type=\"response\")))\n",
    "opt.assignment.test <- as.numeric(as.character(predict(opt_policy_tree, newdata = df_test, type=\"response\")))\n",
    "\n",
    "# Calculate value over random policy\n",
    "opt.A.hat <- data.frame(rbind(\n",
    "  opt.perf.train = describe(opt.assignment.train*Gamma.hat.train.net)[c(\"mean\", \"se\")],\n",
    "  opt.perf.test = describe(opt.assignment.test*Gamma.hat.test.net)[c(\"mean\", \"se\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table class=\"table table-striped table-hover table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;border-bottom: 0;\">\n",
       "<caption>Doubly robust estimated benefit of optimal policy over random policy on training and test sets</caption>\n",
       " <thead>\n",
       "  <tr>\n",
       "   <th style=\"text-align:left;\">   </th>\n",
       "   <th style=\"text-align:right;\"> A.hat </th>\n",
       "   <th style=\"text-align:right;\"> se </th>\n",
       "  </tr>\n",
       " </thead>\n",
       "<tbody>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> opt.perf.train </td>\n",
       "   <td style=\"text-align:right;\"> 0.08549 </td>\n",
       "   <td style=\"text-align:right;\"> 0.00998 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> opt.perf.test </td>\n",
       "   <td style=\"text-align:right;\"> 0.03398 </td>\n",
       "   <td style=\"text-align:right;\"> 0.01009 </td>\n",
       "  </tr>\n",
       "</tbody>\n",
       "<tfoot>\n",
       "<tr><td style=\"padding: 0; \" colspan=\"100%\"><span style=\"font-style: italic;\">Note: </span></td></tr>\n",
       "<tr><td style=\"padding: 0; \" colspan=\"100%\">\n",
       "<sup></sup> Important: This policy was fit on the training set, so the training sample estimate may be biased upwards.</td></tr>\n",
       "</tfoot>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colnames(opt.A.hat) <- c(\"A.hat\", \"se\")\n",
    "opt.A.hat %>%\n",
    "  kable(\"html\", digits = 5, \n",
    "        caption=\"Doubly robust estimated benefit of optimal policy over random policy on training and test sets\") %>%\n",
    "  kable_styling(bootstrap_options=c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width=FALSE) %>%\n",
    "  footnote(general = \"Important: This policy was fit on the training set, so the training sample estimate may be biased upwards.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can also estimate the value of this policy using the first method described in randomized control trial section above. Once again, we remark that the estimates on the training set will be biased upward.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train$pi.dr <-  (opt.assignment.train + 1)/2  # Encoding as {0, 1}\n",
    "\n",
    "# Estimated policy, on the training set\n",
    "y_g1s1 <- df_train[(df_train$W == 1) & (df_train$pi.dr == 1), \"Y\"]\n",
    "y_g1s0 <- df_train[(df_train$W == 0) & (df_train$pi.dr == 1), \"Y\"]\n",
    "y_g0s1 <- df_train[(df_train$W == 1) & (df_train$pi.dr == 0), \"Y\"]\n",
    "y_g0s0 <- df_train[(df_train$W == 0) & (df_train$pi.dr == 0), \"Y\"]\n",
    "\n",
    "ate_g1 <- mean(y_g1s1) - mean(y_g1s0) \n",
    "ate_g0 <- mean(y_g0s1) - mean(y_g0s0)\n",
    "\n",
    "var_ate_g1 <- var(y_g1s1)/length(y_g1s1) + var(y_g1s0)/length(y_g1s0)\n",
    "var_ate_g0 <- var(y_g0s1)/length(y_g0s1) + var(y_g0s0)/length(y_g0s0)\n",
    "\n",
    "q1 <- mean(df_train$pi.dr == 1)\n",
    "q0 <- mean(df_train$pi.dr == 0)\n",
    "\n",
    "# dr policy vs random policy on training set\n",
    "value_train_dr_vs_random_mean <- q1 * ate_g1 - q0 * ate_g0 - (2*q1 - 1)*cost\n",
    "value_train_dr_vs_random_stderr <- sqrt(q1^2 * var_ate_g1 + q0^2 * var_ate_g0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test$pi.dr <-  (opt.assignment.test + 1)/2  # Encoding as {0, 1}\n",
    "\n",
    "# Estimated policy, on the testing set\n",
    "y_g1s1 <- df_test[(df_test$W == 1) & (df_test$pi.dr == 1), \"Y\"]\n",
    "y_g1s0 <- df_test[(df_test$W == 0) & (df_test$pi.dr == 1), \"Y\"]\n",
    "y_g0s1 <- df_test[(df_test$W == 1) & (df_test$pi.dr == 0), \"Y\"]\n",
    "y_g0s0 <- df_test[(df_test$W == 0) & (df_test$pi.dr == 0), \"Y\"]\n",
    "\n",
    "ate_g1 <- mean(y_g1s1) - mean(y_g1s0) \n",
    "ate_g0 <- mean(y_g0s1) - mean(y_g0s0)\n",
    "\n",
    "var_ate_g1 <- var(y_g1s1)/length(y_g1s1) + var(y_g1s0)/length(y_g1s0)\n",
    "var_ate_g0 <- var(y_g0s1)/length(y_g0s1) + var(y_g0s0)/length(y_g0s0)\n",
    "\n",
    "q1 <- mean(df_test$pi.dr == 1)\n",
    "q0 <- mean(df_test$pi.dr == 0)\n",
    "\n",
    "# dr policy vs random policy on testing set\n",
    "value_test_dr_vs_random_mean <- q1 * ate_g1 - q0 * ate_g0 - (2*q1 - 1)*cost\n",
    "value_test_dr_vs_random_stderr <- sqrt(q1^2 * var_ate_g1 + q0^2 * var_ate_g0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table class=\"table table-striped table-hover table-condensed table-responsive\" style=\"width: auto !important; margin-left: auto; margin-right: auto;border-bottom: 0;\">\n",
       "<caption>Sample ATE estimates of benefit of using optimal policy vs random on training and test sets</caption>\n",
       " <thead>\n",
       "  <tr>\n",
       "   <th style=\"text-align:left;\">   </th>\n",
       "   <th style=\"text-align:right;\"> A.hat </th>\n",
       "   <th style=\"text-align:right;\"> se </th>\n",
       "  </tr>\n",
       " </thead>\n",
       "<tbody>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> opt.perf.train </td>\n",
       "   <td style=\"text-align:right;\"> 0.08260 </td>\n",
       "   <td style=\"text-align:right;\"> 0.01010 </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "   <td style=\"text-align:left;\"> opt.perf.test </td>\n",
       "   <td style=\"text-align:right;\"> 0.03467 </td>\n",
       "   <td style=\"text-align:right;\"> 0.01033 </td>\n",
       "  </tr>\n",
       "</tbody>\n",
       "<tfoot>\n",
       "<tr><td style=\"padding: 0; \" colspan=\"100%\"><span style=\"font-style: italic;\">Note: </span></td></tr>\n",
       "<tr><td style=\"padding: 0; \" colspan=\"100%\">\n",
       "<sup></sup> The policy here is not honest, so the training sample estimate may be upward biased.</td></tr>\n",
       "</tfoot>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table <- data.frame(\n",
    "  A.hat=c(value_train_dr_vs_random_mean, value_test_dr_vs_random_mean),\n",
    "  se=c(value_train_dr_vs_random_stderr, value_test_dr_vs_random_stderr))\n",
    "\n",
    "rownames(table) <- c(\"opt.perf.train\", \"opt.perf.test\")\n",
    "table %>%\n",
    "  kable(format=\"html\", digits = 5, caption=\"Sample ATE estimates of benefit of using optimal policy vs random on training and test sets\") %>%\n",
    "  kable_styling(bootstrap_options=c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width=FALSE) %>%\n",
    "  footnote(general = \"The policy here is not honest, so the training sample estimate may be upward biased.\")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
