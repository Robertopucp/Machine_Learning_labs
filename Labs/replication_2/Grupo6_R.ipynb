{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e246670",
   "metadata": {},
   "source": [
    "REPLICATE THE PM1_NOTEBOOK1_PREDICTION_NEWDATA IN R WITH JN BUT RESTRICTED DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3430b20f",
   "metadata": {},
   "source": [
    "# DATA\n",
    "\n",
    "The data set we consider is from the March Supplement of the U.S. Current Population Survey, year 2015. We select white non-hispanic individuals, aged 25 to 64 years, and working more than 35 hours per week during at least 50 weeks of the year. We exclude self-employed workers; individuals living in group quarters; individuals in the military, agricultural or private household sectors; individuals with inconsistent reports on earnings and employment status; individuals with allocated or missing information in any of the variables used in the analysis; and individuals with hourly wage below 3.\n",
    "\n",
    "The variable of interest ùëå is the hourly wage rate constructed as the ratio of the annual earnings to the total number of hours worked, which is constructed in turn as the product of number of weeks worked and the usual number of hours worked per week. In our analysis, we also focus on single (never married) workers. The final sample is of size ùëõ=5150."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cdde6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "load(\"C:/Users/marci/Documentos/GitHub/ECO224/Labs/data/wage2015_subsample_inference.Rdata\")\n",
    "dim(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfd9986",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "str(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268bc58f",
   "metadata": {},
   "source": [
    "The data cointains 5150 observations with 20 variables. According to the instruction, we only consider a subsample of the data :people who didn't go to college, so that is why we support at the variables shs and hsg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb49f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data <- subset(data, shs==1 | hsg==1)\n",
    "dim (data_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1027276",
   "metadata": {},
   "source": [
    "In this case, we can see how many observations had losing. Next, we focus in the construction between the output Y and the matrix Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549ef8b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y <- log(data$wage)\n",
    "n <- length(Y)\n",
    "Z <- data[-which(colnames(data) %in% c(\"wage\",\"lwage\"))]\n",
    "p <- dim(Z)[2]\n",
    "\n",
    "cat(\"Number of observation:\", n, '\\n')\n",
    "cat(\"Number of raw regressors:\", p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0729d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(xtable)\n",
    "options(xtble.floating = FALSE)\n",
    "options(xtable.timestamp = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fc9cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(xtable)\n",
    "Z_subset <- data_1[which(colnames(data) %in% c(\"lwage\", \"sex\", \"shs\",\"hsg\",\"scl\",\"clg\",\"ad\",\"mw\",\"so\",\"we\",\"ne\",\"exp1\"))]\n",
    "table <- matrix(0,12,1)\n",
    "table[1:12,1] <- as.numeric(lapply(Z_subset,mean))\n",
    "rownames(table) <-c(\"Log Wage\", \"Sex\", \"Some High School\",\"High School Graduate\",\"Some College\",\"College Graduate\",\"Advance Degree\",\"Midwest\",\"South\",\"West\",\"Northeast\",\"Experience\")\n",
    "colnames(table) <-c(\"Sample mean\")\n",
    "tab<- xtable(table, digits =2)\n",
    "tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd465bb",
   "metadata": {},
   "source": [
    "E.g., the share of female workers in our sample is ~32% ($sex=1$ if female).\n",
    "\n",
    "Alternatively, we can also print the table as latex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ed2472",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tab, type=\"latex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76289d0b",
   "metadata": {},
   "source": [
    "# PREDICTION QUESTION\n",
    "\n",
    "Now, we will construct a prediction rule for hourly wage  ùëå , which depends linearly on job-relevant characteristics  ùëã :\n",
    "\n",
    "                                ùëå=ùõΩ‚Ä≤ùëã+ùúñ\n",
    "                                \n",
    "Our goals are\n",
    "\n",
    "+Predict wages using various characteristics of workers.\n",
    "\n",
    "+Assess the predictive performance using the (adjusted) sample MSE, the (adjusted) sample  ùëÖ2  and the out-of-sample MSE and  ùëÖ2 .\n",
    "\n",
    "We employ two different specifications for prediction:\n",
    "\n",
    "++Basic Model:  ùëã  consists of a set of raw regressors (e.g. gender, experience, education indicators, occupation and industry indicators, regional indicators).\n",
    "\n",
    "++Flexible Model:  ùëã  consists of all raw regressors from the basic model (without sex) plus transformations (e.g.,  ùëíùë•ùëù2  and  ùëíùë•ùëù3 and  ùëíùë•ùëù4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa007534",
   "metadata": {},
   "outputs": [],
   "source": [
    "#i. Basic model\n",
    "basic <-lwage ~ (sex + exp1 + shs + hsg + scl + clg + mw + so + we + occ2 + ind2)\n",
    "regbasic <- lm(basic, data=data)\n",
    "regbasic #estimated coefficients\n",
    "cat (\"Number of regressors in the basic model:\", length(regbasic$coef),'\\n') #number of regresors in the basic Model\n",
    "\n",
    "#The basic model has 51 regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dffe8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ii.Flexible model\n",
    "flex <- lwage ~ (exp1+exp2+exp3+exp4+shs+hsg+scl+clg+occ2+ind2+mw+so+we)**2\n",
    "regflex <- lm(flex, data=data)\n",
    "regflex #estimaated coefficients\n",
    "cat( \"Number of regressors in the flexible model:\", length(regflex$coef)) # number of regressors in the flexible model\n",
    "#The flexible model has 979 regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ec7a08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Lasso model\n",
    "library(hdm)\n",
    "flex <- lwage ~ (exp1+exp2+exp3+exp4+shs+hsg+scl+clg+occ2+ind2+mw+so+we)**2\n",
    "lassoreg <- rlasso(flex, data=data)\n",
    "sumlasso <- summary(lassoreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82121e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluationg of R2 adjusted(sample) and MSE adjusted(sample)\n",
    "#Assess the predictive performance\n",
    "\n",
    "sumbasic <- summary(regbasic)\n",
    "sumflex <- summary(regflex)\n",
    "\n",
    "#R-squared\n",
    "R2.1 <- sumbasic$r.squared\n",
    "cat(\"R.squared for the basic model:\", R2.1, \"\\n\")\n",
    "R2.adj1 <- sumbasic$adj.r.squared\n",
    "cat(\"adjusted R-squared for the basic model:\", R2.adj1, \"\\n\")\n",
    "\n",
    "R2.2 <- sumflex$r.squared\n",
    "cat(\"R-squared for the flexible model: \", R2.2, \"\\n\")\n",
    "R2.adj2 <- sumflex$adj.r.squared\n",
    "cat(\"adjusted R-squared for the flexible model: \", R2.adj2, \"\\n\")\n",
    "\n",
    "R2.L <- sumlasso$r.squared\n",
    "cat(\"R-squared for the lasso with flexible model: \", R2.L, \"\\n\")\n",
    "R2.adjL <- sumlasso$adj.r.squared\n",
    "cat(\"adjusted R-squared for the flexible model: \", R2.adjL, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51de0118",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the MSE\n",
    "MSE1 <- mean(sumbasic$res^2)\n",
    "cat(\"MSE for the basic model:\", MSE1, \"\\n\")\n",
    "p1 <- sumbasic$df[1] #number of regressors\n",
    "MSE.adj1 <- (n/(n-p1))*MSE1\n",
    "cat(\"adjusted MSE for the basic model:\", MSE.adj1, \"\\n\")\n",
    "\n",
    "MSE2 <- mean(sumflex$res^2)\n",
    "cat(\"MSE for the flexible model:\", MSE2, \"\\n\")\n",
    "p2 <- sumflex$df[1]\n",
    "MSE.adj2 <- (n/(n-p2))*MSE2\n",
    "cat(\"adjusted MSE for the flexible model:\", MSE.adj2, \"\\n\")\n",
    "\n",
    "MSEL <- mean(sumlasso$res^2)\n",
    "cat(\"MSE for the lasso flexible model:\", MSEL, \"\\n\")\n",
    "pL <- length(sumlasso$coef)\n",
    "MSE.adjL <- (n/(n-pL))*MSEL\n",
    "cat(\"adjusted MSE for the lasso flexible model:\", MSE.adjL, \"\\n\")\n",
    "cat(\"adjusted MSE for the partialing out lasso flexible model:\",MSE.adjL2,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e541dd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "library(xtable)\n",
    "table <- matrix(0,3,5)\n",
    "table[1,1:5] <-c(p1,R2.1,MSE1,R2.adj1,MSE.adj1)\n",
    "table[2,1:5] <-c(p2,R2.2,MSE2,R2.adj2,MSE.adj2)\n",
    "table[3,1:5] <-c(pL,R2.L,MSEL,R2.adjL,MSE.adjL)\n",
    "colnames(table)<- c(\"p\",\"$R^2_{sample}$\",\"$MSE_{sample}$\",\"$R^2_{adjusted}$\",\"$MSE_{Adjusted}$\")\n",
    "rownames(table)<- c(\"basic reg\",\"flexible reg\",\"lasso flex\")\n",
    "tab<- xtable(table, digits =c(0,0,2,2,2,2))\n",
    "print(tab,type=\"latex\") #typer=\"latex\" for printing table in latex\n",
    "tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284da5db",
   "metadata": {},
   "source": [
    "Results: The model performs better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24078fd",
   "metadata": {},
   "source": [
    "# DATA SPLITTING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13d3091",
   "metadata": {},
   "source": [
    "Measure the prediction quality of the two models via data splitting:\n",
    "\n",
    "+Randomly split the data into one training sample and one testing sample. Here we just use a simple method (stratified splitting is a more sophiscticated version of splitting that we can consider).\n",
    "\n",
    "+Use the training sample for estimating the parameters of the Basic Model and the Flexible Model.\n",
    "\n",
    "+Use the testing sample for evaluation. Predict the  ùö†ùöäùöêùöé  of every observation in the testing sample based on the estimated parameters in the training sample.\n",
    "\n",
    "+Calculate the Mean Squared Prediction Error  ùëÄùëÜùê∏ùë°ùëíùë†ùë°  based on the testing sample for both prediction models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc16b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data\n",
    "set.seed(1) #to make the results replicable (generating random numbers)\n",
    "random <- sample(1:n, floor(n*4/5))\n",
    "length(random)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39914294",
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw (4/5)*n random numbers from 1 to n without replacing them\n",
    "train <- data[random,] #training sample\n",
    "test <-data[-random,] #testing sample\n",
    "dim(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a088beb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic model\n",
    "#estimating the parameters in the training sample\n",
    "regbasic <- lm(basic, data=train)\n",
    "#calculating the out-of-sample-MSE\n",
    "trainregbasic <- predict(regbasic, newdata=test)\n",
    "\n",
    "y.test <- log(test$wage)\n",
    "MSE.test1 <- sum((y.test-trainregbasic)^2)/length(y.test)\n",
    "R2.test1 <- 1-MSE.test1/var(y.test)\n",
    "\n",
    "cat(\"Test MSE for the basic model:\", MSE.test1, \"\")\n",
    "cat(\"Test R2 for the basic model:\", R2.test1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c41fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flexible model\n",
    "#estimating the parameters\n",
    "#options (warn=-1)\n",
    "regflex <- lm(flex, data=train)\n",
    "\n",
    "#calculating the out-of-sample MSE\n",
    "trainregflex <- predict(regflex, newdata=test)\n",
    "\n",
    "y.test <- log(tes$wage)\n",
    "MSE.test2 <- sum((y.test-trainregflex)^2)/length(y.test)\n",
    "R2.test2 <- 1-MSE.test2/var(y.test)\n",
    "\n",
    "cat(\"Test MSE for the flexible model:\", MSE.test2,\"\")\n",
    "cat(\"Test R2 for the flexible model:\", R2,test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae8441a",
   "metadata": {},
   "source": [
    "In the flexible model, the discrepancy between the  ùëÄùëÜùê∏ùë°ùëíùë†ùë°  and the  ùëÄùëÜùê∏ùë†ùëéùëöùëùùëôùëí  is not large.\n",
    "\n",
    "It is worth to notice that the ùëÄùëÜùê∏ùë°ùëíùë†ùë° vary across different data splits. Hence, it is a good idea average the out-of-sample MSE over different data splits to get valid results.\n",
    "\n",
    "Nevertheless, we observe that, based on the out-of-sample ùëÄùëÜùê∏, the basic model using ols regression performs is about as well (or slightly better) than the flexible model.\n",
    "\n",
    "Next, let us use lasso regression in the flexible model instead of ols regression. Lasso (least absolute shrinkage and selection operator) is a penalized regression method that can be used to reduce the complexity of a regression model when the number of regressors ùëù is relatively large in relation to ùëõ.\n",
    "\n",
    "Note that the out-of-sample ùëÄùëÜùê∏ on the test sample can be computed for any other black-box prediction method as well. Thus, let us finally compare the performance of lasso regression in the flexible model to ols regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e12b4cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# flexible model using lasso\n",
    "\n",
    "# estimating the parameters\n",
    "library(hdm)\n",
    "reglasso <- rlasso(flex, data=train, post=FALSE)\n",
    "\n",
    "# calculating the out-of-sample MSE\n",
    "trainreglasso<- predict(reglasso, newdata=test)\n",
    "MSE.lasso <- sum((y.test-trainreglasso)^2)/length(y.test)\n",
    "R2.lasso<- 1- MSE.lasso/var(y.test)\n",
    "\n",
    "\n",
    "cat(\"Test MSE for the lasso on flexible model: \", MSE.lasso, \" \")\n",
    "\n",
    "cat(\"Test R2 for the lasso flexible model: \", R2.lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570318da",
   "metadata": {},
   "outputs": [],
   "source": [
    "table2 <- matrix(0, 3,2)\n",
    "table2[1,1]   <- MSE.test1\n",
    "table2[2,1]   <- MSE.test2\n",
    "table2[3,1]   <- MSE.lasso\n",
    "table2[1,2]   <- R2.test1\n",
    "table2[2,2]   <- R2.test2\n",
    "table2[3,2]   <- R2.lasso\n",
    "\n",
    "rownames(table2)<- c(\"basic reg\",\"flexible reg\",\"lasso regression\")\n",
    "colnames(table2)<- c(\"$MSE_{test}$\", \"$R^2_{test}$\")\n",
    "tab2 <- xtable(table2, digits =3)\n",
    "tab2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8acf4b",
   "metadata": {},
   "source": [
    "Results: The basic model is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc500b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tab2, type=\"latex\") #type=\"latex\" for printing table in latex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5a101d",
   "metadata": {},
   "source": [
    "TWO CASES OF PARTIALLING-OUT USING LASSO.\n",
    "\n",
    "CASE 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aa77e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(hdm)\n",
    "# For the basic model\n",
    "basic.y <- lwage ~ (exp1 + shs + hsg+ scl + clg + mw + so + we + occ2+ ind2) # Model for Y\n",
    "basic.d <- sex ~ (exp1 + shs + hsg+ scl + clg + mw + so + we + occ2+ ind2) # Modelo for D\n",
    "\n",
    "# Residuals\n",
    "basic_rY <- rlasso(basic.y, data = data)$res\n",
    "basic_rD <- rlasso(basic.d, data = data)$res\n",
    "\n",
    "# regression of Y on D after partialling-out the effect of W\n",
    "basic_partial.fit <- lm(basic_rY ~ basic_rD)\n",
    "basic_partial.est <- summary(basic_partial.fit)$coef[2,1]\n",
    "\n",
    "sum_basiclasso <- summary(basic_partial.fit)\n",
    "\n",
    "cat(\"Coefficient for D via partialling-out\",basic_partial.est)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c829c480",
   "metadata": {},
   "source": [
    "Results: We found differences between the gender gap of basic regressions using lasso and the gender gap regressions using OLS "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c72fb86",
   "metadata": {},
   "source": [
    "CASE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626cd1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(hdm)\n",
    "# For the flexible model\n",
    "flex.y <- lwage ~ (exp1+exp2+exp3+exp4+shs+hsg+scl+clg+occ2+ind2+mw+so+we)**2 # Model for Y\n",
    "flex.d <- sex ~ (exp1+exp2+exp3+exp4+shs+hsg+scl+clg+occ2+ind2+mw+so+we)**2 # Modelo for D\n",
    "\n",
    "# Residuals\n",
    "flex_rY <- rlasso(flex.y, data = data)$res\n",
    "flex_rD <- rlasso(flex.d, data = data)$res\n",
    "\n",
    "# regression of Y on D after partialling-out the effect of W\n",
    "flex_partial.fit <- lm(flex_rY ~ flex_rD)\n",
    "flex_partial.est <- summary(flex_partial.fit)$coef[2,1]\n",
    "\n",
    "sum_flexlasso <- summary(flex_partial.fit)\n",
    "\n",
    "cat(\"Coefficient for D via partialling-out\",flex_partial.est)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bee3e67",
   "metadata": {},
   "source": [
    "Results: We found differences between the gender gap of basic regressions using lasso and the gender gap regressions using OLS."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
