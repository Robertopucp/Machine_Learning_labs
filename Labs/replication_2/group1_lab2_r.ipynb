{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Members:\n",
    "* Stephy Riega - 20171426\n",
    "* Jesus Soto - 20172738\n",
    "* Franco Caceres - 2016615"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019635,
     "end_time": "2021-02-18T19:28:30.110372",
     "exception": false,
     "start_time": "2021-02-18T19:28:30.090737",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. What is data splitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data splitting consists in dividing the data *randomly* in at least two samples, training our models in one and testing their predict capacity in the other one. The first step to evaluate the prediction's performance of the model is data splitting. The proportion represented by each partitioned data varies depending of the researcher, but it is pretty common that the data has a proportion of 80%/20%. You are going to name \"train\" at the first split (which represents  the 80%) and \"test\" (20%) to the other one. It is important to take into account that this data splitting has to be done *randomly*. The second step is to perform the regression or regressions of different models in the training sample and, after that, perform the predict of your dependent variable ($Y_{test-estimated}$) on your test sample using your estimators ($\\beta_{train}$) from the training sample. The third step is to estimate the $R^2$ and $MSE_{OFS}$ of the regressions by calculating the average of the squared difference between the observed ($Y_{test}$) and the estimaded ($Y_{test-estimated}$). With this, you can compared them with $R^2$  and $MSE$ into sample to know if your estimators perform better than in the sample data or which model perform better out of sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Replicate the PM1_Notebook1_Prediction_newdata (R and Python) JN but with restricted data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen, Y  is the hourly wage of a worker and  X  is a vector of worker's characteristics, e.g., education, experience, gender. We focus on how to use job-relevant characteristics, such as education and experience, to best predict wages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019453,
     "end_time": "2021-02-18T19:28:30.188193",
     "exception": false,
     "start_time": "2021-02-18T19:28:30.168740",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019763,
     "end_time": "2021-02-18T19:28:30.227671",
     "exception": false,
     "start_time": "2021-02-18T19:28:30.207908",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The data set we consider is from the March Supplement of the U.S. Current Population Survey, year 2015. We select white non-hispanic individuals, aged 25 to 64 years, and working more than 35 hours per week during at least 50 weeks of the year. We exclude self-employed workers; individuals living in group quarters; individuals in the military, agricultural or private household sectors; individuals with inconsistent reports on earnings and employment status; individuals with allocated or missing information in any of the variables used in the analysis; and individuals with hourly wage below  3 .\n",
    "\n",
    "The variable of interest  Y  is the hourly wage rate constructed as the ratio of the annual earnings to the total number of hours worked, which is constructed in turn as the product of number of weeks worked and the usual number of hours worked per week. In our analysis, we also focus on single (never married) workers. The final sample is of size  **n=5150** ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019808,
     "end_time": "2021-02-18T19:28:30.267083",
     "exception": false,
     "start_time": "2021-02-18T19:28:30.247275",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01983,
     "end_time": "2021-02-18T19:28:30.307189",
     "exception": false,
     "start_time": "2021-02-18T19:28:30.287359",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We start by loading the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T19:28:30.379027Z",
     "iopub.status.busy": "2021-02-18T19:28:30.377044Z",
     "iopub.status.idle": "2021-02-18T19:28:30.530766Z",
     "shell.execute_reply": "2021-02-18T19:28:30.529551Z"
    },
    "papermill": {
     "duration": 0.203333,
     "end_time": "2021-02-18T19:28:30.530976",
     "exception": false,
     "start_time": "2021-02-18T19:28:30.327643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in readChar(con, 5L, useBytes = TRUE):\n",
      "\"cannot open compressed file '../data/wage2015_subsample_inference.Rdata', probable reason 'No such file or directory'\""
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in readChar(con, 5L, useBytes = TRUE): no se puede abrir la conexión\n",
     "output_type": "error",
     "traceback": [
      "Error in readChar(con, 5L, useBytes = TRUE): no se puede abrir la conexión\nTraceback:\n",
      "1. load(\"../data/wage2015_subsample_inference.Rdata\")",
      "2. readChar(con, 5L, useBytes = TRUE)"
     ]
    }
   ],
   "source": [
    "load(\"../data/wage2015_subsample_inference.Rdata\")\n",
    "dim(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a data frame with 5150 observations with 20 variables. However,  **since we want only a subsample of the data that consists of the people who did not go to college**, we restrict the data set using the variables *shs* and *hsg* (which represents the people who ultimately went partially to high school or completed this level of education). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data <-subset(data, shs==1 | hsg==1)\n",
    "\n",
    "dim (data) # less observations (1376) than before\n",
    "head(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020964,
     "end_time": "2021-02-18T19:28:30.716250",
     "exception": false,
     "start_time": "2021-02-18T19:28:30.695286",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We are constructing the output variable $Y$ and the matrix $Z$ which includes the characteristics of workers that are given in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T19:28:30.768255Z",
     "iopub.status.busy": "2021-02-18T19:28:30.766636Z",
     "iopub.status.idle": "2021-02-18T19:28:30.791641Z",
     "shell.execute_reply": "2021-02-18T19:28:30.790356Z"
    },
    "papermill": {
     "duration": 0.054288,
     "end_time": "2021-02-18T19:28:30.791792",
     "exception": false,
     "start_time": "2021-02-18T19:28:30.737504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Y <- log(data$wage)\n",
    "n <- length(Y)\n",
    "Z <- data[-which(colnames(data) %in% c(\"wage\",\"lwage\"))]\n",
    "p <- dim(Z)[2]\n",
    "\n",
    "cat(\"Number of observation:\", n, '\\n')\n",
    "cat( \"Number of raw regressors:\", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023423,
     "end_time": "2021-02-18T19:28:30.838653",
     "exception": false,
     "start_time": "2021-02-18T19:28:30.815230",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "For the outcome variable *wage* and a subset of the raw regressors, we calculate the empirical mean to get familiar with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(xtable)\n",
    "options(xtable.floating = FALSE)\n",
    "options(xtable.timestamp = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T19:28:30.888961Z",
     "iopub.status.busy": "2021-02-18T19:28:30.887455Z",
     "iopub.status.idle": "2021-02-18T19:28:30.944048Z",
     "shell.execute_reply": "2021-02-18T19:28:30.942461Z"
    },
    "papermill": {
     "duration": 0.082765,
     "end_time": "2021-02-18T19:28:30.944279",
     "exception": false,
     "start_time": "2021-02-18T19:28:30.861514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "library(xtable)\n",
    "Z_subset <- data[which(colnames(data) %in% c(\"lwage\",\"sex\",\"shs\",\"hsg\",\"scl\",\"clg\",\"ad\",\"mw\",\"so\",\"we\",\"ne\",\"exp1\"))]\n",
    "table <- matrix(0, 12, 1)\n",
    "table[1:12,1]   <- as.numeric(lapply(Z_subset,mean))\n",
    "rownames(table) <- c(\"Log Wage\",\"Sex\",\"Some High School\",\"High School Graduate\",\"Some College\",\"College Graduate\", \"Advanced Degree\",\"Midwest\",\"South\",\"West\",\"Northeast\",\"Experience\")\n",
    "colnames(table) <- c(\"Sample mean\")\n",
    "tab<- xtable(table, digits = 2)\n",
    "tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022899,
     "end_time": "2021-02-18T19:28:30.992023",
     "exception": false,
     "start_time": "2021-02-18T19:28:30.969124",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "E.g., the share of female workers in our sample is ~32% ($sex=1$ if female)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022996,
     "end_time": "2021-02-18T19:28:31.038176",
     "exception": false,
     "start_time": "2021-02-18T19:28:31.015180",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Alternatively, we can also print the table as latex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T19:28:31.089264Z",
     "iopub.status.busy": "2021-02-18T19:28:31.087626Z",
     "iopub.status.idle": "2021-02-18T19:28:31.107384Z",
     "shell.execute_reply": "2021-02-18T19:28:31.105746Z"
    },
    "papermill": {
     "duration": 0.046315,
     "end_time": "2021-02-18T19:28:31.107521",
     "exception": false,
     "start_time": "2021-02-18T19:28:31.061206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(tab, type=\"latex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will construct a prediction rule for hourly wage $Y$, which depends linearly on job-relevant characteristics $X$:\n",
    "\n",
    "\\begin{equation}\\label{decompose}\n",
    "Y = \\beta'X+ \\epsilon.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we will:\n",
    "\n",
    "* Predict wages  using various characteristics of workers.\n",
    "\n",
    "* Assess the predictive performance using the (adjusted) sample MSE, the (adjusted) sample $R^2$ and the out-of-sample MSE and $R^2$.\n",
    "\n",
    "\n",
    "We employ two different specifications for prediction:\n",
    "\n",
    "\n",
    "1. Basic Model:   $X$ consists of a set of raw regressors (e.g. gender, experience, education indicators,  occupation and industry indicators, regional indicators). That is,  sex + exp1 + shs + hsg+ scl + clg + mw + so + we + occ2+ ind2.\n",
    "\n",
    "\n",
    "2. Flexible Model:  $X$ consists of all raw regressors from the basic model (excepto for sex) plus transformations (e.g., ${exp}^2$, ${exp}^3$ and ${exp}^4$) squared.That is, $(exp1+exp2+exp3+exp4+shs+hsg+scl+clg+occ2+ind2+mw+so+we)^2$\n",
    "\n",
    "\n",
    "Using the **Flexible Model**, enables us to approximate the real relationship by a more complex regression model and therefore to reduce the bias. The **Flexible Model** increases the range of potential shapes of the estimated regression function. In general, flexible models often deliver good prediction accuracy but give models which are harder to interpret. *Also, with flexible models we have the trade off between bias and variance, making it more propense to overfitting.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022935,
     "end_time": "2021-02-18T19:28:31.290982",
     "exception": false,
     "start_time": "2021-02-18T19:28:31.268047",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, let us fit both models to our data by running ordinary least squares (ols):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T19:28:31.342746Z",
     "iopub.status.busy": "2021-02-18T19:28:31.341092Z",
     "iopub.status.idle": "2021-02-18T19:28:31.384766Z",
     "shell.execute_reply": "2021-02-18T19:28:31.383207Z"
    },
    "papermill": {
     "duration": 0.070584,
     "end_time": "2021-02-18T19:28:31.384945",
     "exception": false,
     "start_time": "2021-02-18T19:28:31.314361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. basic model\n",
    "basic <- lwage~ (sex + exp1 + shs + hsg+ scl + clg + mw + so + we +occ2+ind2)\n",
    "regbasic <- lm(basic, data=data)\n",
    "regbasic # estimated coefficients\n",
    "cat( \"Number of regressors in the basic model:\",length(regbasic$coef), '\\n') # number of regressors in the Basic Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023845,
     "end_time": "2021-02-18T19:28:31.433272",
     "exception": false,
     "start_time": "2021-02-18T19:28:31.409427",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### Note that the basic model consists of $51$ regressors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T19:28:31.486360Z",
     "iopub.status.busy": "2021-02-18T19:28:31.484753Z",
     "iopub.status.idle": "2021-02-18T19:28:31.666629Z",
     "shell.execute_reply": "2021-02-18T19:28:31.665355Z"
    },
    "papermill": {
     "duration": 0.209505,
     "end_time": "2021-02-18T19:28:31.666828",
     "exception": false,
     "start_time": "2021-02-18T19:28:31.457323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2. flexible model\n",
    "flex <- lwage ~ (exp1+exp2+exp3+exp4+shs+hsg+scl+clg+occ2+ind2+mw+so+we)**2\n",
    "\n",
    "regflex <- lm(flex, data=data)\n",
    "regflex # estimated coefficients\n",
    "cat( \"Number of regressors in the flexible model:\",length(regflex$coef)) # number of regressors in the Flexible Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the flexible model consists of $979$ regressors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try lasso next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lasso model\n",
    "library(hdm)\n",
    "flex <- lwage ~ (exp1+exp2+exp3+exp4+shs+hsg+scl+clg+occ2+ind2+mw+so+we)**2\n",
    "lassoreg<- rlasso(flex, data=data)\n",
    "\n",
    "sumlasso<- summary(lassoreg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can evaluate the performance of both models based on the (adjusted) $R^2_{sample}$ and the (adjusted) $MSE_{sample}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess the predictive performance\n",
    "\n",
    "sumbasic <- summary(regbasic)\n",
    "sumflex <- summary(regflex)\n",
    "\n",
    "#  R-squared \n",
    "R2.1 <- sumbasic$r.squared\n",
    "cat(\"R-squared for the basic model: \", R2.1, \"\\n\")\n",
    "R2.adj1 <- sumbasic$adj.r.squared\n",
    "cat(\"adjusted R-squared for the basic model: \", R2.adj1, \"\\n\")\n",
    "\n",
    "R2.2 <- sumflex$r.squared\n",
    "cat(\"R-squared for the flexible model: \", R2.2, \"\\n\")\n",
    "R2.adj2 <- sumflex$adj.r.squared\n",
    "cat(\"adjusted R-squared for the flexible model: \", R2.adj2, \"\\n\")\n",
    "\n",
    "R2.L <- sumlasso$r.squared\n",
    "cat(\"R-squared for the lasso with flexible model: \", R2.L, \"\\n\")\n",
    "R2.adjL <- sumlasso$adj.r.squared\n",
    "cat(\"adjusted R-squared for the flexible model: \", R2.adjL, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the MSE\n",
    "MSE1 <- mean(sumbasic$res^2)\n",
    "cat(\"MSE for the basic model: \", MSE1, \"\\n\")\n",
    "p1 <- sumbasic$df[1] # number of regressors\n",
    "MSE.adj1 <- (n/(n-p1))*MSE1\n",
    "cat(\"adjusted MSE for the basic model: \", MSE.adj1, \"\\n\")\n",
    "\n",
    "MSE2 <-mean(sumflex$res^2)\n",
    "cat(\"MSE for the flexible model: \", MSE2, \"\\n\")\n",
    "p2 <- sumflex$df[1]\n",
    "MSE.adj2 <- (n/(n-p2))*MSE2\n",
    "cat(\"adjusted MSE for the flexible model: \", MSE.adj2, \"\\n\")\n",
    "\n",
    "\n",
    "MSEL <-mean(sumlasso$res^2)\n",
    "cat(\"MSE for the lasso flexible model: \", MSEL, \"\\n\")\n",
    "pL <- length(sumlasso$coef)\n",
    "MSE.adjL <- (n/(n-pL))*MSEL\n",
    "cat(\"adjusted MSE for the lasso flexible model: \", MSE.adjL, \"\\n\")\n",
    "cat(\"adjusted MSE for the partialing out lasso flexible model: \", MSE.adjL2, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(xtable)\n",
    "table <- matrix(0, 3, 5)\n",
    "table[1,1:5]   <- c(p1,R2.1,MSE1,R2.adj1,MSE.adj1)\n",
    "table[2,1:5]   <- c(p2,R2.2,MSE2,R2.adj2,MSE.adj2)\n",
    "table[3,1:5]   <- c(pL,R2.L,MSEL,R2.adjL,MSE.adjL)\n",
    "colnames(table)<- c(\"p\",\"$R^2_{sample}$\",\"$MSE_{sample}$\",\"$R^2_{adjusted}$\", \"$MSE_{adjusted}$\")\n",
    "rownames(table)<- c(\"basic reg\",\"flexible reg\", \"lasso flex\")\n",
    "tab<- xtable(table, digits =c(0,0,2,2,2,2))\n",
    "print(tab,type=\"latex\") # type=\"latex\" for printing table in LaTeX\n",
    "tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.03068,
     "end_time": "2021-02-18T19:28:39.045901",
     "exception": false,
     "start_time": "2021-02-18T19:28:39.015221",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Considering all measures above, the flexible model performs slightly better than the other models. \n",
    "\n",
    "One procedure to circumvent this issue is to use **data splitting** that is described and applied in the following."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.03052,
     "end_time": "2021-02-18T19:28:39.107361",
     "exception": false,
     "start_time": "2021-02-18T19:28:39.076841",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Splitting\n",
    "\n",
    "Measure the prediction quality of the two models via data splitting:\n",
    "\n",
    "- Randomly split the data into one training sample and one testing sample. Here we just use a simple method (stratified splitting is a more sophiscticated version of splitting that we can consider).\n",
    "- Use the training sample for estimating the parameters of the Basic Model and the Flexible Model.\n",
    "- Use the testing sample for evaluation. Predict the $\\mathtt{wage}$  of every observation in the testing sample based on the estimated parameters in the training sample.\n",
    "- Calculate the Mean Squared Prediction Error $MSE_{test}$ based on the testing sample for both prediction models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T19:28:39.173592Z",
     "iopub.status.busy": "2021-02-18T19:28:39.172416Z",
     "iopub.status.idle": "2021-02-18T19:28:39.191475Z",
     "shell.execute_reply": "2021-02-18T19:28:39.190390Z"
    },
    "papermill": {
     "duration": 0.053799,
     "end_time": "2021-02-18T19:28:39.191630",
     "exception": false,
     "start_time": "2021-02-18T19:28:39.137831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#splitting the data\n",
    "\n",
    "set.seed(1) # to make the results replicable (generating random numbers)\n",
    "random <- sample(1:n, floor(n*4/5))\n",
    "length(random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw (4/5)*n random numbers from 1 to n without replacing them\n",
    "train <- data[random,] # training sample\n",
    "test <- data[-random,] # testing sample\n",
    "dim(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T19:28:39.261214Z",
     "iopub.status.busy": "2021-02-18T19:28:39.260257Z",
     "iopub.status.idle": "2021-02-18T19:28:39.309792Z",
     "shell.execute_reply": "2021-02-18T19:28:39.306592Z"
    },
    "papermill": {
     "duration": 0.087305,
     "end_time": "2021-02-18T19:28:39.310008",
     "exception": false,
     "start_time": "2021-02-18T19:28:39.222703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# basic model\n",
    "# estimating the parameters in the training sample\n",
    "regbasic <- lm(basic, data=train)\n",
    "# calculating the out-of-sample MSE\n",
    "trainregbasic <- predict(regbasic, newdata=test)\n",
    "\n",
    "y.test <- log(test$wage)\n",
    "MSE.test1 <- sum((y.test-trainregbasic)^2)/length(y.test)\n",
    "R2.test1<- 1- MSE.test1/var(y.test)\n",
    "\n",
    "cat(\"Test MSE for the basic model: \", MSE.test1, \" \")\n",
    "\n",
    "cat(\"Test R2 for the basic model: \", R2.test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.048538,
     "end_time": "2021-02-18T19:28:39.413804",
     "exception": false,
     "start_time": "2021-02-18T19:28:39.365266",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In the basic model, the $MSE_{test}$ is quite closed to the $MSE_{sample}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T19:28:39.481857Z",
     "iopub.status.busy": "2021-02-18T19:28:39.480606Z",
     "iopub.status.idle": "2021-02-18T19:28:39.623819Z",
     "shell.execute_reply": "2021-02-18T19:28:39.621785Z"
    },
    "papermill": {
     "duration": 0.17873,
     "end_time": "2021-02-18T19:28:39.624018",
     "exception": false,
     "start_time": "2021-02-18T19:28:39.445288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# flexible model\n",
    "# estimating the parameters\n",
    "#options(warn=-1)\n",
    "regflex <- lm(flex, data=train)\n",
    "\n",
    "# calculating the out-of-sample MSE\n",
    "trainregflex<- predict(regflex, newdata=test)\n",
    "\n",
    "y.test <- log(test$wage)\n",
    "MSE.test2 <- sum((y.test-trainregflex)^2)/length(y.test)\n",
    "R2.test2<- 1- MSE.test2/var(y.test)\n",
    "\n",
    "cat(\"Test MSE for the flexible model: \", MSE.test2, \" \")\n",
    "\n",
    "cat(\"Test R2 for the flexible model: \", R2.test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.050246,
     "end_time": "2021-02-18T19:28:39.732065",
     "exception": false,
     "start_time": "2021-02-18T19:28:39.681819",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In the flexible model, the discrepancy between the $MSE_{test}$ and the $MSE_{sample}$ is not large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.032619,
     "end_time": "2021-02-18T19:28:39.797362",
     "exception": false,
     "start_time": "2021-02-18T19:28:39.764743",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It is worth to notice that the $MSE_{test}$ vary across different data splits. Hence, it is a good idea average the out-of-sample MSE over different data splits to get valid results.\n",
    "\n",
    "Nevertheless, we observe that, based on the out-of-sample $MSE$, the basic model using ols regression performs is about as well (or slightly better) than the flexible model. \n",
    "\n",
    "\n",
    "Next, let us use lasso regression in the flexible model instead of ols regression. Lasso (*least absolute shrinkage and selection operator*) is a penalized regression method that can be used to reduce the complexity of a regression model when the number of regressors $p$ is relatively large in relation to $n$. \n",
    "\n",
    "Note that the out-of-sample $MSE$ on the test sample can be computed for any other black-box prediction method as well. Thus, let us finally compare the performance of lasso regression in the flexible model to ols regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flexible model using lasso\n",
    "\n",
    "# estimating the parameters\n",
    "library(hdm)\n",
    "reglasso <- rlasso(flex, data=train, post=FALSE)\n",
    "\n",
    "# calculating the out-of-sample MSE\n",
    "trainreglasso<- predict(reglasso, newdata=test)\n",
    "MSE.lasso <- sum((y.test-trainreglasso)^2)/length(y.test)\n",
    "R2.lasso<- 1- MSE.lasso/var(y.test)\n",
    "\n",
    "\n",
    "cat(\"Test MSE for the lasso on flexible model: \", MSE.lasso, \" \")\n",
    "\n",
    "cat(\"Test R2 for the lasso flexible model: \", R2.lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.052309,
     "end_time": "2021-02-18T19:28:41.975337",
     "exception": false,
     "start_time": "2021-02-18T19:28:41.923028",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Finally, let us summarize the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T19:28:42.046887Z",
     "iopub.status.busy": "2021-02-18T19:28:42.045718Z",
     "iopub.status.idle": "2021-02-18T19:28:42.079375Z",
     "shell.execute_reply": "2021-02-18T19:28:42.078267Z"
    },
    "papermill": {
     "duration": 0.070703,
     "end_time": "2021-02-18T19:28:42.079561",
     "exception": false,
     "start_time": "2021-02-18T19:28:42.008858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "table2 <- matrix(0, 3,2)\n",
    "table2[1,1]   <- MSE.test1\n",
    "table2[2,1]   <- MSE.test2\n",
    "table2[3,1]   <- MSE.lasso\n",
    "table2[1,2]   <- R2.test1\n",
    "table2[2,2]   <- R2.test2\n",
    "table2[3,2]   <- R2.lasso\n",
    "\n",
    "rownames(table2)<- c(\"basic reg\",\"flexible reg\",\"lasso regression\")\n",
    "colnames(table2)<- c(\"$MSE_{test}$\", \"$R^2_{test}$\")\n",
    "tab2 <- xtable(table2, digits =3)\n",
    "tab2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see now that the lasso regression is slightly better at predicting the data than was before using OLS. However, we can see that, overall, **the basic model is better at predicting the test set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T19:28:42.152462Z",
     "iopub.status.busy": "2021-02-18T19:28:42.151344Z",
     "iopub.status.idle": "2021-02-18T19:28:42.165928Z",
     "shell.execute_reply": "2021-02-18T19:28:42.164837Z"
    },
    "papermill": {
     "duration": 0.052181,
     "end_time": "2021-02-18T19:28:42.166072",
     "exception": false,
     "start_time": "2021-02-18T19:28:42.113891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(tab2,type=\"latex\") # type=\"latex\" for printing table in LaTeX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. In addition Do two cases of Partialling-Out using lasso. Remember that we want to find the beta associated with sex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Matrix W = 'exp1 + shs + hsg+ scl + clg + mw + so + we + occ2+ ind2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(hdm)\n",
    "# For the basic model\n",
    "basic.y <- lwage ~ (exp1 + shs + hsg+ scl + clg + mw + so + we + occ2+ ind2) # Model for Y\n",
    "basic.d <- sex ~ (exp1 + shs + hsg+ scl + clg + mw + so + we + occ2+ ind2) # Modelo for D\n",
    "\n",
    "# Residuals\n",
    "basic_rY <- rlasso(basic.y, data = data)$res\n",
    "basic_rD <- rlasso(basic.d, data = data)$res\n",
    "\n",
    "# regression of Y on D after partialling-out the effect of W\n",
    "basic_partial.fit <- lm(basic_rY ~ basic_rD)\n",
    "basic_partial.est <- summary(basic_partial.fit)$coef[2,1]\n",
    "\n",
    "sum_basiclasso <- summary(basic_partial.fit)\n",
    "\n",
    "cat(\"Coefficient for D via partialling-out\",basic_partial.est)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of the lasso for partialling-out the basic regressions shows us that the gender gap is of $9.066\\%$, which is different from the $7\\%$ gap found int the basic regression using OLS. Probably because lasso supresses some of the regressors but not all of them, and because partialling out controls for the covariates in the both regressions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Matrix W = '(exp1+exp2+exp3+exp4+shs+hsg+scl+clg+occ2+ind2+mw+so+we)**2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(hdm)\n",
    "# For the flexible model\n",
    "flex.y <- lwage ~ (exp1+exp2+exp3+exp4+shs+hsg+scl+clg+occ2+ind2+mw+so+we)**2 # Model for Y\n",
    "flex.d <- sex ~ (exp1+exp2+exp3+exp4+shs+hsg+scl+clg+occ2+ind2+mw+so+we)**2 # Modelo for D\n",
    "\n",
    "# Residuals\n",
    "flex_rY <- rlasso(flex.y, data = data)$res\n",
    "flex_rD <- rlasso(flex.d, data = data)$res\n",
    "\n",
    "# regression of Y on D after partialling-out the effect of W\n",
    "flex_partial.fit <- lm(flex_rY ~ flex_rD)\n",
    "flex_partial.est <- summary(flex_partial.fit)$coef[2,1]\n",
    "\n",
    "sum_flexlasso <- summary(flex_partial.fit)\n",
    "\n",
    "cat(\"Coefficient for D via partialling-out\",flex_partial.est)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of the lasso for partialling-out the basic regressions shows us that the gender gap is of $8.14\\%$, which is different from the $7\\%$ gap found int the basic regression using OLS but **pretty similar to the $9.066\\%$ found on the basic regression model with partialling-out.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 15.121246,
   "end_time": "2021-02-18T19:28:42.309027",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-02-18T19:28:27.187781",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
