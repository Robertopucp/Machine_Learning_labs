## Report 6 : Causal Diagrams and the Identification of Causal Effects

### Student: Diego Alonso Gómez (20171738)

In this chapter, the authors explore the ways of inferring such relationships from a combination of data and qualitative causal assumptions that are deemed plausible in a given domain. Por lo que they describe a number of cause-effect relationships with the aim of clarify the divisions of the most common assumptions, and to show how are constructed causal inferences from the combination of assumptions, experiments and data. 

After some introductory statements, the chapter establish its proposed options of how to deal with the next problem: "Since counterfactuals are not observable, and since judgments about conditional independence of counterfactuals are not readily assertable from common scientific knowledge, the question has remained open: What criterion should one use to decide which variables are appropriate for adjustment?". To overcome this "bache" and facilitate the drawing of quantitative causal inferences (from a combination of qualitative causal assumptions and
nonexperimental observations), the chapters mentions two criterions.

The first one would the Back-Door Criterion, which basicaly is a a graphical test that can be applied directly to the causal diagram in order to test if a set $Z \subseteq V$ of variables is sufficient for identifying $P( y | \hat x )$.

And the second one would be the Front-Door Criterion, which shows how concomitants that are affected by the treatment can be used to facilitate causal inference. For that, they not only mention its definition, but also the "Front-Door Adjustment":
$$
        P(y | \hat x) = \sum_{z}P(z | x) \sum_{x} P(y | x^´, z) P(x^´) 
$$


Finally, something that should also be mentioned is what the author says in the 3.6.4 Section ("Relations to Robins G-estimation"). It is mentioned that among the investigations conducted in the potential-outcome framework, the one closest in spirit to the structural analysis is Robins’s work on “causally interpreted structured tree graphs”. Besides, Robins was the first to realize the potential of Neyman’s counterfactual notation Y(x) as a general mathematical language for causal inference, and he used it to extend Rubin’s model to studies with direct and indirect effects and time-varying treatments, concomitants, and outcomes. After some math development, he arrived to an expression he called the “G-computation algorithm formula":
$$
     P(y | g =x) = \sum_{l_{k}}P(y|\bar l_{k},\bar x_{k}) \prod_{k=1}^{K} p(l_k | \bar l_{k-1} ,\bar x_{k-1} ) 
$$

From my perspective, this expression --and the structural framework of Robins and the chapter's author-- means moving from the vocabulary of independent counterfactuals to processes and mechanism, where human knowledge is encoded. In doing so, Robins' research has shown that the condition of ignorability is necessary to adequately handle time-varying treatment problems.