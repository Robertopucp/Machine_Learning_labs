# Seventh Report

> **Name**:     Eusebio Evangelista, Eljaer Edfrance

> **Code**:      20155658

> **Article**:     “Estimating Treatment Effects with Causal     Forests: An Application”

> **Author**:    Athey, Susan, & Wager, Stefan. (2019)

Nowadays, the use of linear, logistic regressions, decision trees, neural networks and so on have become very popular and useful due to great advances in computational and statistical matters. Many of these models have made advances in medicine, statistics, economics, sociology, psychology and many other fields. Thus, it is essential to make every each model  as effective as possible in order to improve future findings in the different fields of science. One of those methods used in order to make them more effective is causal forests, which in the empirical field -so far- has reported well predictions. Causal forests are a causal inference learning method that are an extension of Random Forests. In random forests, the data is repeatedly split in order to minimize prediction error of an outcome variable. Causal forests are built similarly, except that instead of minimizing prediction error, data is split in order to maximize the difference across splits in the relationship between an outcome variable and a “treatment” variable. In this case, we are going to analyze a case where the database is The National Study of Learning Mindsets, which has information about students of the public schools of the United States to evaluate the nudge (develop the mentality in student achievement) as intervention. This is found in the article by Susan Athey & Stefan Wager entitled "Estimation of the effects of treatment with causal forests: an application", which we will analyze below.

First of all, I will begin by stating the goal of the authors' research. The authors try to answer the question: Was the effect of the intervention moderated by the levels of school achievement -the nudge to develop the mindset- (measured by the student's test score and college trainning for students) or by the mean School-level of fixed mindset reported before randomization?

Secondly, I will highlight the strengths and weaknesses of the article's approach to answer the research question.

For one thing, one of the main strengths of the article is that it uses cluster robust causal forests to eliminate, on the one hand, heteroscedasticity (possible correlations between different students from the same school) through robustness; and, on the other hand, it uses clustering to reduce the variance and detect and eliminate heterogeneity in the effect of the intervention. The authors did it with the aim of having better estimations.

In addition, another of the main strengths of the article is that it assumes that there are sample selection problems. That is, some students with a higher expectation of success are more likely to receive the treatment. Or, for example, that there is considerable heterogeneity between schools (some have leadership teams and implemented the intervention better than others or that there is a more receptive student culture treatment). Therefore, it is an observed study rather than a random one. And that for better identification of the causal effects they assume unconfoundedness instead of conditional randomization with covariate to analyze the hidden confounders.

Morover, another of the main strengths of the article is that it compares the results of the robust and non-robust causal forests without cluster with that of the robust and non-robust causal forests with cluster before and after treatment, specifically clustering students by school. The results were that, for example, in the causal forest of students without cluster by school the confidence interval for the effect of the average treatment is now almost half than before the treatment and, for example, the sample variance increases in the non-causal forests clustered. Or , for example, there are prediction gains when using cluster non-robust forests; However, when using cluster robust forests, those gains in terms of prediction disappear, due to idiosyncratic school effects, that is, inherent effect for each school. Those comparisons are relevant since it tests different methods and compares results to have less and less biased effects.

On the other hand, one of the weaknesses of the article is that each school assumes the same weight in the treatment; however, in reality this does not happen and the inference must follow the goals of the author. For example, when there are observations pooled in unequal sizes, the aim of the inference must be defined since it could give us a spurious inference. Another example is, if we want to fit a model that accurately reflects the heterogeneity in our available sample of 76 schools and if we want it, for example, to also generalize to students from other schools. So, should we give more weight in our analysis to the schools in which we observe more students? My point is that it is necessary to analyze what objectives the authors seek to achieve with the inference according to the assumption of giving equal weight to all schools, since these cannot be wrong.

Thirdly, the causal forests in this article had the challenge of approaching an observational study -and not randomized- in addition to cluster results at the school level, because they wanted to see the effect of the intervention -the nudge to develop mentality-. In this sense, the contribution of the article is that the approach that the author adopts can be interpreted as an adjustment to a functional model of random effects, where each group has its own main function and treatment effect, and the expectation is defined about the distribution of the treatment effect functions by cluster. This is because the authors highlight the need to know how to work with clustered observations when modeling treatment heterogeneity. And because the traditional approach captures the effects of the cluster through "fixed effects" or "random effects" models in data panels, this article contributes to providing an alternative response.

Finally, since one of the weaknesses of the article is that the authors assume the same weight to each school in the treatment; however, in reality this does not happen and the inference must accommodate the objectives sought. Well, a valuable step to follow is to give it different weights or balance those samples through the different techniques that exist, such as smote, undersampling or undersampling. I would recommend using the smote which is the most used. Furthermore, it would be of considerable importance to establish pros and cons of the approach -with empirical studies- on the heterogeneous estimation of the effect of treatment on clustered data.