# Title: Hedonic prices and quality adjusted price indices powered by AI
# Report 10
## Name: Morales López Erik Brandon

* This paper is very interesting, because the authors developed empirical model using *deep learning* (DL), which is another methodology from the A.I and different from the *Supervised Machine Learning* (ML), in order to measure the changes in costumers welfare and estimate the hedonic price. Also, this paper not include what other previous research treat concerning to *supervised learning* (ML) and its models worked in this course. The authors are focusing in neural networks and to achieve it, they use a specific multitask-neural net to produce the estimated hedonic price function to later compare it with data from Amazon store. After all mentioned in this part, they realized that their models based on deep learning have a high predictive accuracy which allowed them to build the hidonic prices in a range of years and therefore the neural net worked good enough for customer welfare. In the next lines, I am going to focus in the most important parts from this paper and how the model based on *deep learning* make a good performance in this empirical research. 

* Firstly, I am going to introduce the problem that the authors want to solve, which I mean prices and the costumers welfare and the possible methodology to solve it. The authors mention the hedonic prices were created by Andrew Court and Zvi Griliches in 1939 and 1961, respectively in order to address the problem with the input and output prices data. According to the mentioned befored, the theory suggest if the representation which is a algorithm of certain product and the product´s feature, so we are able to approximate to the price. In other words, we only work with input data and with these data we are able to get an approximation of result. In that sense, the instering part of this the authors try to exchange the text information and images to numerical data. The purpose of it, all input data which are convert in numerical data will work with deep learning models called **ELMO** o **BERT** in the case of the text information and **Restnet50** for images. Moreover, the authors add new elements they consider necessary which are hedonic indices from Fisher (HFPI), (GEKS) and (GHFPI). I understand they use all these elements to try to perform the objective that the authors want to reach. 

* Secondly, another important concept is the neural network known(NN) on the field of *Deep Learning*. This models are too important, because they build certain structures taking only the input data in order to predict the output value, which in this paper are text and images features from the number of hidden layers that will be taken into considerations for the construction of the *neural network*(NN), but in this case the authors just take 3 hidden layers **m=3**. In that sense, we have 3 columns on the neural network: the first column contains all input features, the second one, we have the layer of the neurons and all the neurons are connected with the input data with which the connections represents the coefficients and in the third column contains the outputs which are connected with the rest of the model, too. In addition to above, to calculate the estimates, the authors need a certain algorithm for the optimization, which is known as gradient-descent. In this case, they are using the *Adam´s algorithm* to predict the prices on this study. So, understanding the above the authors are going to trying to convert the product features from the images, the product title and the description as numerical vectors, also they need to follow all the step mentioned to build the neural network and deploy tthe model. In the next lines, I am going to explain on the results from the neural network. 

* Finally, in this section, I will focus on the result from model based on *Deep Learning*. To achive this objective, the paper´s author propose to use the Amazon´s store data to make a better prediction on the hedonic prices, also this study cover a part of period around the 2013-2018. In the result we can see that R2 perform a good accurancy around the 80% until 90%. In addition to above, the confidence intervals and the point estimate are 95% efficients for hedonic prices with and the mayority of the coefficients are highly significant. To conclude this part of the summary, I wold like to mention the authors are using a kind of neural network to work with text which are **ELMO** OR **BERT**, in the case of the images they use **Restnet50**. This is too important, because it can help with the final performance of the model which is good enough. For it, they mentioned the modeld built response for the hedonic price and the costumer welfare. 

* In conclusion, the most important on this paper is that the authors develop models of hedonic prices with the purpose to measure in the customers welfare. To achieve this task, they use another A.I methodology different from the *Supervised Machine Learning* (ML), known as *deep learning* and specifically the neural network(NN). For it, the input data are represented by text description and images to estimate the hedonic price. After that, the authors apply the models in the Amazon´s store data to understand with better precision the hedonic prices. In the end, they noticed the neural network deployed previously, has a better accurancy in which case it help a lot in customers welfare. 


