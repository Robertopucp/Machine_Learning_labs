# Report  5  --> Estimation and inference of heterogeneous treatment effects using random forests

> **Name**: Diego Alonso Gómez (20171738)


Currently, random forest use has become very popular and useful for university fields such as  medicine, economics, sociology, etc. That due to great advances in computational and statistical matters, which have allows to use this technique with enough data to grant consistent estimations. However, there have been some problems with that: a) the fear that researchers will iteratively search for subgroups with high treatment levels, and then report only the results for subgroups with extreme effects, thus highlighting heterogeneity that may be purely spurious. Although there have been developed some solutions alternatives to deal with it, such procedural restrictions can make it difficult to discover strong but unexpected treatment effect heterogeneity. 

Therefore, in this article I consider that the authors' research question is the next one: ¿Is it possible to develop a powerful, nonparametric method for heterogeneous treatment effect estimation that yields valid asymptotic confidence intervals for the true underlying treatment effect? And the authors' answer is yes.

Next, I would say that one of the article's strengths to answer this question are two: a) it constructs the forest causal tree in a way that have proven to be effective under certain limitations, and allowing a researcher to keep the positives aspects from it; and b) the authors establish that the estimator obtained should be consistent with an asymptotically normal sampling distribution so that the researcher can use it to test the hypothesis tested and establish valid confidence intervals, for which they performed simulation experiments that obtained that causal forests have a lower mean square error than K-NN matching.

On the other hand, the weaknesses of the article —from my perspective— are the next ones: a)the authors arbitrary chose simulations in the experiments, so, from my point of view, there are not following an appropiate scientific approach; b) they don't explain the optimal scale of the subsample size $s_n$ to minimize the mean square error of the random forests tehcnique they are proposing; and finally c) they do not explain how to choose the appropriate procedure for data partitioning.

That being said, the main contribution of this article —from my perspective— is the formulation of an asymptotic normality theory that allows to do statistical inferences using random forest predictions, mainstream theory from statistics and machine learning, and empirical examples And another one is the extension to causal forests proposed by the authors.

Finally, important challenge or steps to be addresed in future works would be the following: a) to design purely random methods -and not manually chosen simulations to establish whether to use double sample forests or propensity forests; b) develop an specific way to determine the optimal scale of the subsample size $s_n$ to minimize the mean square error of the random forests tehcnique proposed by the authors; and c) design division rules that can automatically choose which characteristic of the training data should be splitted in order to reduce bias and allow trees to focus on characteristic values ​​of greater importance. 