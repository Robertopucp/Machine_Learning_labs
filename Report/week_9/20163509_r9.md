## <p style='text-align: justify;'> **Report N°9 - Double/debiased machine learning for treatment and structural parameters** 
### Author: VICTOR CHERNOZHUKOV, DENIS CHETVERIKOV, MERT DEMIRER, ESTHER DUFLO, CHRISTIAN HANSEN, WHITNEY NEWEY AND JAMES ROBINS
### Student : Gianfranco Soria Alosilla (20163509)
---
<p style='text-align: justify;'>This article seeks to address the problem of estimation and inference of the low-dimensional parameter theta in the presence of other high-dimensional parameters. They present an estimation model, which they develop extensively (mathematics), posing various theorems and warning of limitations. This method is called double ML and compares its results with other estimation and inference methods: regression trees, random forest, neural networks, etc. In order to show the benefits of this presented method, as well as to check if the results are consistent with other models. The main objective of the article is to provide a general and simple procedure to estimate and make inferences about theta that are formally valid in complex environments. Said environment refers to two problems: the impact of the regularization bias and the over-adjustment in the estimation of the theta parameter. The author points out that two steps must be followed: the Neyman orthogonal moments and a cross fit that provides an efficient way of dividing the data. It is verified that the double ML provides point estimators that are concentrated in a neighborhood of the true values of the parameters, are almost unbiased and are distributed as a normal. These last two features are very useful and interesting. On the other hand, the authors point out that the results will be efficient if the likelihood function is high and the restriction of the parameters is finite-dimensional.

<p style='text-align: justify;'>The article ends with the empirical application of three examples: The effects of Q4 on the duration of unemployment, for this they use the Pennsylvania survey; the effect on 401 (k) eligibility and the effect on various financial assets; and, the most interesting example, estimating the effect of institutions on growth. For the latter, he follows and uses Acemoğlu's results as a point of comparison. For each of these examples he does not find contradictory results and they follow some economic intuition. In addition, it validates results found by other authors. Although they are similar results, it is important to note that those found using this method are more robust and efficient.

<p style='text-align: justify;'>The positive points of this article are: contribution of a simpler estimation method and contribution with the (almost) complete mathematical development of the model. It also presents some interesting theorems. On the other hand, it turns out to be very extensive in the mathematics it presents and some could be classified as "hard". It requires a solid knowledge to fully understand, so this article could not be described as "simple". This is contrary to the author's explicit aim of presenting a simple method. In order to have better clarity, the author presents three examples, but if they are not carefully reviewed, they may continue to confuse the reader. One contribution that could have made the article stand out, and perhaps be the next line of research, would have been to present examples where the results are contradictory with other models and to evaluate the causes of this. Also, the method shown should be more widely disseminated to test for greater constraints or conditions that may not have been identified. The article opens a new interesting line of research.

<p style='text-align: justify;'>In short, it is a good article to generate some ideas and research possibilities. The extensive mathematical development has a positive and a negative contribution. You would expect a sequence of articles to be generated exploring this method.