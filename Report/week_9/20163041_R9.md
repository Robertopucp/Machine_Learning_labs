# Title: Double/ Debiased machine learning for treatment and structural parametrics.
# Report 9
## Names: Morales López Erik Brandon

* The present investigation made by CHERNOZHUKOV and others address the problem of inference in certain parameters of high under **"n"** dimensions. In that sense, the reading makes use of the statistical methods of machine learning (ML) called *Double Machine Learning*, because they are the most suitable for this type of problems and, above all, they are adaptable in cases where the high dimension is presented. However, it is important to take into account the bias and overfitting of the parametric model that is being developed. To do this, the author makes use of the *Neyman* statistics method to solve the aforementioned problem. For this, it is necessary to use double machine learning to be able to estimate parameters traditionally created by supervised learning, in addition to allowing a specific number of parameters to be concentrated for their confidence intervals. Here are some important ideas about the  double machine learning as a way to extend the methods used in supervised learning, such as *types regressions*, *Random Forest*, *decision trees* and more.

* Firstly, lets to strat to explain the sample size under a certain parameter of treatment effect parameter. In that sense, what the researchers want to develop is estimate certain number of inferences in complex situations related to the high-dimensional. For example, the authors deploy a Linear Regression which **"p"** is the dimension under the all dimension from the original data. To capture that preview feature, what the modern models from Machine Learning do is model the p dimension as increasing with the sample. In addition, it is important to consider the bias in order to solve the problems caused by the **θ** estimators. In that case, one of the method to solve it is following the orthogonal. All I mentioned before is important, because there are parts of this research which explain with more details it, also incluide the neyman orthogonal method. 

* Secondly, I´m going to focus in certain examples proposesed in this lecture which are oriented to the DML method. In that sense, the author work with the eligibility and participation effect by the *plan 401*. The main idea in this section with the DML is the performance of DML into the partially linear model and reduce the impact of score in the interactive model. The interesting of these is eliminate the bias throught the random assignment taking a set variables. For it, it is necessary to consinder **100** partitions in order to use in median method for making a statical summary. In the end, the author had noticed the estimations use more observations than the double fitting and that sense, that estimations are adjusted pertectly to the model, which it can show it in the final results. Also, if anyone use the orthogonality method, the results would be similar to the model. 

* Another example can be estimating the effects of institutions on economic growth, but taking the DML. The author mentions a problem on it, which is if any institution is able to generate higher incomes. To solve it, the author proposes **100** partitions of his sample and extract the coefficients mean and the standar errors in order to see the variability using only the median. 