# Double/debiased machine learning for treatment and structural parameters

## Chernozhukov V., Chetverikov D., Demirer M., Duflo E., Hansen C., Newey W. and Robins J.

### Student: Claudia Vivas 

The problem that this article addresses is related to the classical semi-parametric estimation framework, where we are interested in the estimation of a low-dimensional parameter $\theta_0$ (typically the causal or treatment effect parameter) in the presence of high-dimensional nuisance parameters $\eta_0$. The use of machine learning methods to estimate the high-dimensional nuisance parameters ($\eta_0$) regularizes or reduce the bias and overfitting of its estimation, but these methods generate a heavy bias in estimators of $\theta_0$. In this sense, the authors state that the bias on the estimation of $\theta_0$ can be removed using two tools: Neyman-orthogonal moments/scores and cross-fitting. Thus, the article proposes double/debiased machine learning methods which bring point estimators that concentrate in a $N^-1/2$-neighbourhood of the true parameter values and are approximately unbiased and normally distributed; and permit the construction of confidence intervals. In this sence, the research question is: Â¿Are the DML  methods be able to remove the bias and overfitting of the estimation of $\theta_0$ (parameter of interest: causal parameter or treatment effect parameter)? 

To answer this question, first, the main problem and some principal definitions, such as Neyman orthogonality and cross-fitting, are reviewed, once the context is well understood, the following sections develop the orthonality definition, the general theory of DML and its theoretical results, and empirical applications for DML estimation to confirm the robustness of the results. Also, it is important to note that the main contribution of this article is to propose a general and simple procedure for estimating and to perform inference on $\theta_0$ for high-dimensional settings.

An advantage is that in the introduction the authors summarize the problem identified, which allows a better understanding of the following sections. Another advantage of this article is that it extensively develops the theoretical tools (neyman orthogonality and DML estimators) to justify its proposal, however, personally this detailed theoretical analysis is difficult to understand. Finally, another advantage is that three empirical economic applications are developed, such as the effect of unemployment insurance bonus on unemployment duration, the effect of 401 (k) eligibility and participation on net financial assets and the effect of institutions on economic growth, which complement the general theory developed for the DML using inference for average treatment effects (ATEs) and average treatment effects on the treated (ATTEs) under unconfoundedness; local average treatment effects (LATEs). This exercise generates robust results, despite the ML method used, the results are consistent. Nevertheless, one this disadvantage, that has nothing to do with the approach for the research, is the complexy of the notation. One interesting next step could be to compare diffent machine learning methods to find out which one performs better. 